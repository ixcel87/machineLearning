{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7084e65-dfc7-4c05-b896-2bbca2d1c2f0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-17 09:58:22.012562: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-07-17 09:58:22.107041: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-07-17 09:58:22.862229: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-17 09:58:27.504133: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import xgboost as xgb\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from scikeras.wrappers import KerasRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0bd88793-cc13-4e08-965c-34f68aa27c56",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "\n",
    "train_df = pd.read_csv('../data/train.csv')\n",
    "test_df = pd.read_csv('../data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80d6f7ea-0fe7-41d0-a43a-6b11b1cd62bc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# make copy to add price back to the newly encoded df\n",
    "\n",
    "train_df_copy = train_df.copy()\n",
    "test_df_copy = test_df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e317926-ea65-4b81-818e-5e21c7e30bcc",
   "metadata": {},
   "source": [
    "# Inspect the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8bd0dc5c-3197-4239-b667-2f972606c243",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((54273, 13), (36183, 12))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "753aa7cb-0508-4a6e-91bd-af85dcb3d9b2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>brand</th>\n",
       "      <th>model</th>\n",
       "      <th>model_year</th>\n",
       "      <th>milage</th>\n",
       "      <th>fuel_type</th>\n",
       "      <th>engine</th>\n",
       "      <th>transmission</th>\n",
       "      <th>ext_col</th>\n",
       "      <th>int_col</th>\n",
       "      <th>accident</th>\n",
       "      <th>clean_title</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Ford</td>\n",
       "      <td>F-150 Lariat</td>\n",
       "      <td>2018</td>\n",
       "      <td>74349</td>\n",
       "      <td>Gasoline</td>\n",
       "      <td>375.0HP 3.5L V6 Cylinder Engine Gasoline Fuel</td>\n",
       "      <td>10-Speed A/T</td>\n",
       "      <td>Blue</td>\n",
       "      <td>Gray</td>\n",
       "      <td>None reported</td>\n",
       "      <td>Yes</td>\n",
       "      <td>11000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>BMW</td>\n",
       "      <td>335 i</td>\n",
       "      <td>2007</td>\n",
       "      <td>80000</td>\n",
       "      <td>Gasoline</td>\n",
       "      <td>300.0HP 3.0L Straight 6 Cylinder Engine Gasoli...</td>\n",
       "      <td>6-Speed M/T</td>\n",
       "      <td>Black</td>\n",
       "      <td>Black</td>\n",
       "      <td>None reported</td>\n",
       "      <td>Yes</td>\n",
       "      <td>8250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Jaguar</td>\n",
       "      <td>XF Luxury</td>\n",
       "      <td>2009</td>\n",
       "      <td>91491</td>\n",
       "      <td>Gasoline</td>\n",
       "      <td>300.0HP 4.2L 8 Cylinder Engine Gasoline Fuel</td>\n",
       "      <td>6-Speed A/T</td>\n",
       "      <td>Purple</td>\n",
       "      <td>Beige</td>\n",
       "      <td>None reported</td>\n",
       "      <td>Yes</td>\n",
       "      <td>15000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id   brand         model  model_year  milage fuel_type  \\\n",
       "0   0    Ford  F-150 Lariat        2018   74349  Gasoline   \n",
       "1   1     BMW         335 i        2007   80000  Gasoline   \n",
       "2   2  Jaguar     XF Luxury        2009   91491  Gasoline   \n",
       "\n",
       "                                              engine  transmission ext_col  \\\n",
       "0      375.0HP 3.5L V6 Cylinder Engine Gasoline Fuel  10-Speed A/T    Blue   \n",
       "1  300.0HP 3.0L Straight 6 Cylinder Engine Gasoli...   6-Speed M/T   Black   \n",
       "2       300.0HP 4.2L 8 Cylinder Engine Gasoline Fuel   6-Speed A/T  Purple   \n",
       "\n",
       "  int_col       accident clean_title  price  \n",
       "0    Gray  None reported         Yes  11000  \n",
       "1   Black  None reported         Yes   8250  \n",
       "2   Beige  None reported         Yes  15000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab84dd14-4ed1-424b-a84b-7d2a99871c8f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>brand</th>\n",
       "      <th>model</th>\n",
       "      <th>model_year</th>\n",
       "      <th>milage</th>\n",
       "      <th>fuel_type</th>\n",
       "      <th>engine</th>\n",
       "      <th>transmission</th>\n",
       "      <th>ext_col</th>\n",
       "      <th>int_col</th>\n",
       "      <th>accident</th>\n",
       "      <th>clean_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>54273</td>\n",
       "      <td>Mercedes-Benz</td>\n",
       "      <td>E-Class E 350</td>\n",
       "      <td>2014</td>\n",
       "      <td>73000</td>\n",
       "      <td>Gasoline</td>\n",
       "      <td>302.0HP 3.5L V6 Cylinder Engine Gasoline Fuel</td>\n",
       "      <td>A/T</td>\n",
       "      <td>White</td>\n",
       "      <td>Beige</td>\n",
       "      <td>None reported</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>54274</td>\n",
       "      <td>Lexus</td>\n",
       "      <td>RX 350 Base</td>\n",
       "      <td>2015</td>\n",
       "      <td>128032</td>\n",
       "      <td>Gasoline</td>\n",
       "      <td>275.0HP 3.5L V6 Cylinder Engine Gasoline Fuel</td>\n",
       "      <td>8-Speed A/T</td>\n",
       "      <td>Silver</td>\n",
       "      <td>Black</td>\n",
       "      <td>None reported</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>54275</td>\n",
       "      <td>Mercedes-Benz</td>\n",
       "      <td>C-Class C 300</td>\n",
       "      <td>2015</td>\n",
       "      <td>51983</td>\n",
       "      <td>Gasoline</td>\n",
       "      <td>241.0HP 2.0L 4 Cylinder Engine Gasoline Fuel</td>\n",
       "      <td>7-Speed A/T</td>\n",
       "      <td>Blue</td>\n",
       "      <td>White</td>\n",
       "      <td>None reported</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id          brand          model  model_year  milage fuel_type  \\\n",
       "0  54273  Mercedes-Benz  E-Class E 350        2014   73000  Gasoline   \n",
       "1  54274          Lexus    RX 350 Base        2015  128032  Gasoline   \n",
       "2  54275  Mercedes-Benz  C-Class C 300        2015   51983  Gasoline   \n",
       "\n",
       "                                          engine transmission ext_col int_col  \\\n",
       "0  302.0HP 3.5L V6 Cylinder Engine Gasoline Fuel          A/T   White   Beige   \n",
       "1  275.0HP 3.5L V6 Cylinder Engine Gasoline Fuel  8-Speed A/T  Silver   Black   \n",
       "2   241.0HP 2.0L 4 Cylinder Engine Gasoline Fuel  7-Speed A/T    Blue   White   \n",
       "\n",
       "        accident clean_title  \n",
       "0  None reported         Yes  \n",
       "1  None reported         Yes  \n",
       "2  None reported         Yes  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f7075c51-e9c3-4189-8ea9-c80700cd9a00",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 54273 entries, 0 to 54272\n",
      "Data columns (total 13 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   id            54273 non-null  int64 \n",
      " 1   brand         54273 non-null  object\n",
      " 2   model         54273 non-null  object\n",
      " 3   model_year    54273 non-null  int64 \n",
      " 4   milage        54273 non-null  int64 \n",
      " 5   fuel_type     54273 non-null  object\n",
      " 6   engine        54273 non-null  object\n",
      " 7   transmission  54273 non-null  object\n",
      " 8   ext_col       54273 non-null  object\n",
      " 9   int_col       54273 non-null  object\n",
      " 10  accident      54273 non-null  object\n",
      " 11  clean_title   54273 non-null  object\n",
      " 12  price         54273 non-null  int64 \n",
      "dtypes: int64(4), object(9)\n",
      "memory usage: 5.4+ MB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9b0d6079-4adb-4921-843c-e687e27f0271",
   "metadata": {},
   "source": [
    "There is no missing data in the training set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c0be5f-86e2-495d-82b7-703f6ea1df60",
   "metadata": {},
   "source": [
    "# Drop columns you don't want to be encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "767a274a-8384-4f34-a01b-c31f41ba11b7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# dropping the price so that train_df & test_df both have the same cols\n",
    "\n",
    "train_df.drop(columns= ['id', 'price'], inplace=True)\n",
    "test_df.drop(columns=['id'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "887c072f-dba2-4ea0-992f-bb16038a2819",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((54273, 11), (36183, 11))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaff9f33-c7f5-4274-b6f3-efc0ecf13cf3",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Identify both object and non-object columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "58ee8c9a-542e-4c0b-a8c2-8516f504f9bc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Identify object columns and non-object columns\n",
    "\n",
    "object_cols = train_df.select_dtypes(include=['object']).columns\n",
    "non_object_cols = train_df.select_dtypes(exclude=['object']).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "186e14b2-3522-4be6-bf7b-bbd6c8716312",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Index(['brand', 'model', 'fuel_type', 'engine', 'transmission', 'ext_col',\n",
       "        'int_col', 'accident', 'clean_title'],\n",
       "       dtype='object'),\n",
       " Index(['model_year', 'milage'], dtype='object'))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "object_cols, non_object_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "678b5ef3-b31d-4171-85a1-44211c96b552",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Separate non-object columns\n",
    "\n",
    "train_non_object = train_df[non_object_cols]\n",
    "test_non_object = test_df[non_object_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f7f2df3c-9d26-413d-ad85-1602eb86da8b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_year</th>\n",
       "      <th>milage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018</td>\n",
       "      <td>74349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2007</td>\n",
       "      <td>80000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2009</td>\n",
       "      <td>91491</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   model_year  milage\n",
       "0        2018   74349\n",
       "1        2007   80000\n",
       "2        2009   91491"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_non_object.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8e4a293f-d7c0-4db6-a215-2812eef626f9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_year</th>\n",
       "      <th>milage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014</td>\n",
       "      <td>73000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015</td>\n",
       "      <td>128032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015</td>\n",
       "      <td>51983</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   model_year  milage\n",
       "0        2014   73000\n",
       "1        2015  128032\n",
       "2        2015   51983"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_non_object.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8ec33178-7c21-4b9f-aac1-cab46e6e7a6f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Ensure both datasets have the same columns\n",
    "\n",
    "missing_cols = set(train_df.columns) - set(test_df.columns)\n",
    "for col in missing_cols:\n",
    "    test_df[col] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f3ead3d-4a1e-43ef-a996-7ef38d43a532",
   "metadata": {},
   "source": [
    "# Start encoding process\n",
    "- Encoding all object columns in both training and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0a6c8482-4194-4753-a1d5-5b5be367f130",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialize the OneHotEncoder with sparse output\n",
    "\n",
    "encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3704f217-c5bc-4f73-b2cb-3defc9b41913",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>OneHotEncoder(handle_unknown=&#x27;ignore&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;OneHotEncoder<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.preprocessing.OneHotEncoder.html\">?<span>Documentation for OneHotEncoder</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>OneHotEncoder(handle_unknown=&#x27;ignore&#x27;)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "OneHotEncoder(handle_unknown='ignore')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the data\n",
    "\n",
    "encoder.fit(train_df[object_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "183258d2-11d1-4d2c-9efc-b5ccac11d01f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# transform the data\n",
    "\n",
    "train_encoded = encoder.transform(train_df[object_cols])\n",
    "test_encoded = encoder.transform(test_df[object_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "931016ac-1e1d-4557-ba82-4e672fb49889",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(scipy.sparse._csr.csr_matrix, scipy.sparse._csr.csr_matrix)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the types, ensure that they are sparse matrices\n",
    "\n",
    "type(train_encoded), type(test_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "99fc7e35-e90b-4068-a185-60071d0a28d5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['brand_Acura', 'brand_Alfa', 'brand_Aston', ...,\n",
       "       'accident_At least 1 accident or damage reported',\n",
       "       'accident_None reported', 'clean_title_Yes'], dtype=object)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check a few of the new encoded features\n",
    "\n",
    "encoder.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "586d95e1-99be-4856-8b12-3c689cb4e939",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# new df containing the encoded object cols for the train_df\n",
    "\n",
    "train_one_hot_encoded_frame = pd.DataFrame.sparse.from_spmatrix(train_encoded, columns=encoder.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "23f25a85-3f0d-4a07-88e4-2783e60635d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# new df containing the encoded object cols for the test_df\n",
    "\n",
    "test_one_hot_encoded_frame = pd.DataFrame.sparse.from_spmatrix(test_encoded, columns=encoder.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9dc08d98-5f11-4ffd-8557-c6bc9612a649",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>brand_Acura</th>\n",
       "      <th>brand_Alfa</th>\n",
       "      <th>brand_Aston</th>\n",
       "      <th>brand_Audi</th>\n",
       "      <th>brand_BMW</th>\n",
       "      <th>brand_Bentley</th>\n",
       "      <th>brand_Bugatti</th>\n",
       "      <th>brand_Buick</th>\n",
       "      <th>brand_Cadillac</th>\n",
       "      <th>brand_Chevrolet</th>\n",
       "      <th>...</th>\n",
       "      <th>int_col_Very Light Cashmere</th>\n",
       "      <th>int_col_Walnut</th>\n",
       "      <th>int_col_Whisper Beige</th>\n",
       "      <th>int_col_White</th>\n",
       "      <th>int_col_White / Brown</th>\n",
       "      <th>int_col_Yellow</th>\n",
       "      <th>int_col_–</th>\n",
       "      <th>accident_At least 1 accident or damage reported</th>\n",
       "      <th>accident_None reported</th>\n",
       "      <th>clean_title_Yes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 3381 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   brand_Acura  brand_Alfa  brand_Aston  brand_Audi  brand_BMW  brand_Bentley  \\\n",
       "0          0.0         0.0          0.0         0.0        0.0            0.0   \n",
       "1          0.0         0.0          0.0         0.0        1.0            0.0   \n",
       "2          0.0         0.0          0.0         0.0        0.0            0.0   \n",
       "\n",
       "   brand_Bugatti  brand_Buick  brand_Cadillac  brand_Chevrolet  ...  \\\n",
       "0            0.0          0.0             0.0              0.0  ...   \n",
       "1            0.0          0.0             0.0              0.0  ...   \n",
       "2            0.0          0.0             0.0              0.0  ...   \n",
       "\n",
       "   int_col_Very Light Cashmere  int_col_Walnut  int_col_Whisper Beige  \\\n",
       "0                          0.0             0.0                    0.0   \n",
       "1                          0.0             0.0                    0.0   \n",
       "2                          0.0             0.0                    0.0   \n",
       "\n",
       "   int_col_White  int_col_White / Brown  int_col_Yellow  int_col_–  \\\n",
       "0            0.0                    0.0             0.0        0.0   \n",
       "1            0.0                    0.0             0.0        0.0   \n",
       "2            0.0                    0.0             0.0        0.0   \n",
       "\n",
       "   accident_At least 1 accident or damage reported  accident_None reported  \\\n",
       "0                                              0.0                     1.0   \n",
       "1                                              0.0                     1.0   \n",
       "2                                              0.0                     1.0   \n",
       "\n",
       "   clean_title_Yes  \n",
       "0              1.0  \n",
       "1              1.0  \n",
       "2              1.0  \n",
       "\n",
       "[3 rows x 3381 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_one_hot_encoded_frame.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "39c14534-7f90-4cad-bed6-36e845a0bdd9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>brand_Acura</th>\n",
       "      <th>brand_Alfa</th>\n",
       "      <th>brand_Aston</th>\n",
       "      <th>brand_Audi</th>\n",
       "      <th>brand_BMW</th>\n",
       "      <th>brand_Bentley</th>\n",
       "      <th>brand_Bugatti</th>\n",
       "      <th>brand_Buick</th>\n",
       "      <th>brand_Cadillac</th>\n",
       "      <th>brand_Chevrolet</th>\n",
       "      <th>...</th>\n",
       "      <th>int_col_Very Light Cashmere</th>\n",
       "      <th>int_col_Walnut</th>\n",
       "      <th>int_col_Whisper Beige</th>\n",
       "      <th>int_col_White</th>\n",
       "      <th>int_col_White / Brown</th>\n",
       "      <th>int_col_Yellow</th>\n",
       "      <th>int_col_–</th>\n",
       "      <th>accident_At least 1 accident or damage reported</th>\n",
       "      <th>accident_None reported</th>\n",
       "      <th>clean_title_Yes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 3381 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   brand_Acura  brand_Alfa  brand_Aston  brand_Audi  brand_BMW  brand_Bentley  \\\n",
       "0          0.0         0.0          0.0         0.0        0.0            0.0   \n",
       "1          0.0         0.0          0.0         0.0        0.0            0.0   \n",
       "2          0.0         0.0          0.0         0.0        0.0            0.0   \n",
       "\n",
       "   brand_Bugatti  brand_Buick  brand_Cadillac  brand_Chevrolet  ...  \\\n",
       "0            0.0          0.0             0.0              0.0  ...   \n",
       "1            0.0          0.0             0.0              0.0  ...   \n",
       "2            0.0          0.0             0.0              0.0  ...   \n",
       "\n",
       "   int_col_Very Light Cashmere  int_col_Walnut  int_col_Whisper Beige  \\\n",
       "0                          0.0             0.0                    0.0   \n",
       "1                          0.0             0.0                    0.0   \n",
       "2                          0.0             0.0                    0.0   \n",
       "\n",
       "   int_col_White  int_col_White / Brown  int_col_Yellow  int_col_–  \\\n",
       "0            0.0                    0.0             0.0        0.0   \n",
       "1            0.0                    0.0             0.0        0.0   \n",
       "2            1.0                    0.0             0.0        0.0   \n",
       "\n",
       "   accident_At least 1 accident or damage reported  accident_None reported  \\\n",
       "0                                              0.0                     1.0   \n",
       "1                                              0.0                     1.0   \n",
       "2                                              0.0                     1.0   \n",
       "\n",
       "   clean_title_Yes  \n",
       "0              1.0  \n",
       "1              1.0  \n",
       "2              1.0  \n",
       "\n",
       "[3 rows x 3381 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_one_hot_encoded_frame.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "936affe7-1e8c-4add-bf3b-10f05deac540",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((54273, 3381), (36183, 3381))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ensure that the both newly created object cols (encoded) dfs have the same rows\n",
    "\n",
    "train_one_hot_encoded_frame.shape, test_one_hot_encoded_frame.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ceab24c-8edb-4638-974b-1bf8a4aeb4a5",
   "metadata": {},
   "source": [
    "## Combine both dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0279a2aa-4943-4ec3-a101-1bbb40d675ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Concatenate the non-object columns with the encoded object columns\n",
    "\n",
    "train_data_final = pd.concat([train_non_object.reset_index(drop=True), train_one_hot_encoded_frame], axis=1)\n",
    "test_data_final = pd.concat([test_non_object.reset_index(drop=True), test_one_hot_encoded_frame], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5ddc6a8c-dab8-4f45-8dcd-6f5e53881d4c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((54273, 3383), (36183, 3383))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_final.shape, test_data_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3d1e28dc-29fc-447b-a7ed-43e0a0be40a7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_year</th>\n",
       "      <th>milage</th>\n",
       "      <th>brand_Acura</th>\n",
       "      <th>brand_Alfa</th>\n",
       "      <th>brand_Aston</th>\n",
       "      <th>brand_Audi</th>\n",
       "      <th>brand_BMW</th>\n",
       "      <th>brand_Bentley</th>\n",
       "      <th>brand_Bugatti</th>\n",
       "      <th>brand_Buick</th>\n",
       "      <th>...</th>\n",
       "      <th>int_col_Very Light Cashmere</th>\n",
       "      <th>int_col_Walnut</th>\n",
       "      <th>int_col_Whisper Beige</th>\n",
       "      <th>int_col_White</th>\n",
       "      <th>int_col_White / Brown</th>\n",
       "      <th>int_col_Yellow</th>\n",
       "      <th>int_col_–</th>\n",
       "      <th>accident_At least 1 accident or damage reported</th>\n",
       "      <th>accident_None reported</th>\n",
       "      <th>clean_title_Yes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018</td>\n",
       "      <td>74349</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2007</td>\n",
       "      <td>80000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2009</td>\n",
       "      <td>91491</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 3383 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   model_year  milage  brand_Acura  brand_Alfa  brand_Aston  brand_Audi  \\\n",
       "0        2018   74349          0.0         0.0          0.0         0.0   \n",
       "1        2007   80000          0.0         0.0          0.0         0.0   \n",
       "2        2009   91491          0.0         0.0          0.0         0.0   \n",
       "\n",
       "   brand_BMW  brand_Bentley  brand_Bugatti  brand_Buick  ...  \\\n",
       "0        0.0            0.0            0.0          0.0  ...   \n",
       "1        1.0            0.0            0.0          0.0  ...   \n",
       "2        0.0            0.0            0.0          0.0  ...   \n",
       "\n",
       "   int_col_Very Light Cashmere  int_col_Walnut  int_col_Whisper Beige  \\\n",
       "0                          0.0             0.0                    0.0   \n",
       "1                          0.0             0.0                    0.0   \n",
       "2                          0.0             0.0                    0.0   \n",
       "\n",
       "   int_col_White  int_col_White / Brown  int_col_Yellow  int_col_–  \\\n",
       "0            0.0                    0.0             0.0        0.0   \n",
       "1            0.0                    0.0             0.0        0.0   \n",
       "2            0.0                    0.0             0.0        0.0   \n",
       "\n",
       "   accident_At least 1 accident or damage reported  accident_None reported  \\\n",
       "0                                              0.0                     1.0   \n",
       "1                                              0.0                     1.0   \n",
       "2                                              0.0                     1.0   \n",
       "\n",
       "   clean_title_Yes  \n",
       "0              1.0  \n",
       "1              1.0  \n",
       "2              1.0  \n",
       "\n",
       "[3 rows x 3383 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_final.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "752a23f2-ac45-4e60-b145-64cb64860f84",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_year</th>\n",
       "      <th>milage</th>\n",
       "      <th>brand_Acura</th>\n",
       "      <th>brand_Alfa</th>\n",
       "      <th>brand_Aston</th>\n",
       "      <th>brand_Audi</th>\n",
       "      <th>brand_BMW</th>\n",
       "      <th>brand_Bentley</th>\n",
       "      <th>brand_Bugatti</th>\n",
       "      <th>brand_Buick</th>\n",
       "      <th>...</th>\n",
       "      <th>int_col_Very Light Cashmere</th>\n",
       "      <th>int_col_Walnut</th>\n",
       "      <th>int_col_Whisper Beige</th>\n",
       "      <th>int_col_White</th>\n",
       "      <th>int_col_White / Brown</th>\n",
       "      <th>int_col_Yellow</th>\n",
       "      <th>int_col_–</th>\n",
       "      <th>accident_At least 1 accident or damage reported</th>\n",
       "      <th>accident_None reported</th>\n",
       "      <th>clean_title_Yes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014</td>\n",
       "      <td>73000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015</td>\n",
       "      <td>128032</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015</td>\n",
       "      <td>51983</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 3383 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   model_year  milage  brand_Acura  brand_Alfa  brand_Aston  brand_Audi  \\\n",
       "0        2014   73000          0.0         0.0          0.0         0.0   \n",
       "1        2015  128032          0.0         0.0          0.0         0.0   \n",
       "2        2015   51983          0.0         0.0          0.0         0.0   \n",
       "\n",
       "   brand_BMW  brand_Bentley  brand_Bugatti  brand_Buick  ...  \\\n",
       "0        0.0            0.0            0.0          0.0  ...   \n",
       "1        0.0            0.0            0.0          0.0  ...   \n",
       "2        0.0            0.0            0.0          0.0  ...   \n",
       "\n",
       "   int_col_Very Light Cashmere  int_col_Walnut  int_col_Whisper Beige  \\\n",
       "0                          0.0             0.0                    0.0   \n",
       "1                          0.0             0.0                    0.0   \n",
       "2                          0.0             0.0                    0.0   \n",
       "\n",
       "   int_col_White  int_col_White / Brown  int_col_Yellow  int_col_–  \\\n",
       "0            0.0                    0.0             0.0        0.0   \n",
       "1            0.0                    0.0             0.0        0.0   \n",
       "2            1.0                    0.0             0.0        0.0   \n",
       "\n",
       "   accident_At least 1 accident or damage reported  accident_None reported  \\\n",
       "0                                              0.0                     1.0   \n",
       "1                                              0.0                     1.0   \n",
       "2                                              0.0                     1.0   \n",
       "\n",
       "   clean_title_Yes  \n",
       "0              1.0  \n",
       "1              1.0  \n",
       "2              1.0  \n",
       "\n",
       "[3 rows x 3383 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_final.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5085229-59e0-4f7d-b07b-37f35efc415b",
   "metadata": {},
   "source": [
    "# test/train split and setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1b3833f9-0104-4856-852d-4eafb3febfa1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# need to add 'Price' back to the train_data_final\n",
    "\n",
    "train_data_final = pd.concat([train_data_final.reset_index(drop=True), train_df_copy['price']], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bb985e7a-f84a-4ee0-a553-598c8919f982",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(54273, 3384)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a6360b0a-0ab5-480a-8100-12dd3fc23ec5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_year</th>\n",
       "      <th>milage</th>\n",
       "      <th>brand_Acura</th>\n",
       "      <th>brand_Alfa</th>\n",
       "      <th>brand_Aston</th>\n",
       "      <th>brand_Audi</th>\n",
       "      <th>brand_BMW</th>\n",
       "      <th>brand_Bentley</th>\n",
       "      <th>brand_Bugatti</th>\n",
       "      <th>brand_Buick</th>\n",
       "      <th>...</th>\n",
       "      <th>int_col_Walnut</th>\n",
       "      <th>int_col_Whisper Beige</th>\n",
       "      <th>int_col_White</th>\n",
       "      <th>int_col_White / Brown</th>\n",
       "      <th>int_col_Yellow</th>\n",
       "      <th>int_col_–</th>\n",
       "      <th>accident_At least 1 accident or damage reported</th>\n",
       "      <th>accident_None reported</th>\n",
       "      <th>clean_title_Yes</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018</td>\n",
       "      <td>74349</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2007</td>\n",
       "      <td>80000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2009</td>\n",
       "      <td>91491</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 3384 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   model_year  milage  brand_Acura  brand_Alfa  brand_Aston  brand_Audi  \\\n",
       "0        2018   74349          0.0         0.0          0.0         0.0   \n",
       "1        2007   80000          0.0         0.0          0.0         0.0   \n",
       "2        2009   91491          0.0         0.0          0.0         0.0   \n",
       "\n",
       "   brand_BMW  brand_Bentley  brand_Bugatti  brand_Buick  ...  int_col_Walnut  \\\n",
       "0        0.0            0.0            0.0          0.0  ...             0.0   \n",
       "1        1.0            0.0            0.0          0.0  ...             0.0   \n",
       "2        0.0            0.0            0.0          0.0  ...             0.0   \n",
       "\n",
       "   int_col_Whisper Beige  int_col_White  int_col_White / Brown  \\\n",
       "0                    0.0            0.0                    0.0   \n",
       "1                    0.0            0.0                    0.0   \n",
       "2                    0.0            0.0                    0.0   \n",
       "\n",
       "   int_col_Yellow  int_col_–  accident_At least 1 accident or damage reported  \\\n",
       "0             0.0        0.0                                              0.0   \n",
       "1             0.0        0.0                                              0.0   \n",
       "2             0.0        0.0                                              0.0   \n",
       "\n",
       "   accident_None reported  clean_title_Yes  price  \n",
       "0                     1.0              1.0  11000  \n",
       "1                     1.0              1.0   8250  \n",
       "2                     1.0              1.0  15000  \n",
       "\n",
       "[3 rows x 3384 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_final.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "509ea8d8-bb66-419c-9914-cb6ecb9bba61",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# test/train split\n",
    "\n",
    "X = train_data_final.drop(columns= ['price'])\n",
    "y = train_data_final['price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c3818041-cf87-4392-b336-f1e2cc8a7566",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "306a10e7-c168-478d-ab32-44500328b892",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((54273, 3383), (54273,))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bfbb0df1-333e-464e-908a-a9bb28a3f77c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((43418, 3383), (10855, 3383), (43418,), (10855,))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a805ee8-a0d3-4c93-bb09-40a2818d7d40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6df3260f-f507-43e2-9f5f-1483d102fa59",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Helper functions to print out R2, MSE and MAE scores from below models\n",
    "- make_results => takes in a model name and returns metrics\n",
    "- get_test_scores => creates a nice table with my results/metrics\n",
    "\n",
    "## Mean Absolute Error (MAE) - The average of the absolute differences between predicted values and actual values.\n",
    "- Useful for understanding the average error in predictions.\n",
    "## Mean Squared Error (MSE) - The average of the squared differences between predicted values and actual values.\n",
    "- Useful for penalizing larger errors more heavily. Sensitive to outliers.\n",
    "## R-Squared (R2) - Measures how well the regression line from the model approximates the real data points.\n",
    "- Measures how well the model explains variability of the dependent variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ba4c41d-9be0-42f1-a868-786e0fa17827",
   "metadata": {
    "tags": []
   },
   "source": [
    "## function: make_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0e843094-be5f-413f-982e-aeca3860dbb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_results(model_name:str, model_object, metric:str):\n",
    "    '''\n",
    "    Arguments:\n",
    "    model_name (string): user labeled the model\n",
    "    model_object: a fit GridSearchCV object\n",
    "    metric (string): neg_mean_absolute_error, neg_mean_squared_error or r2\n",
    "\n",
    "    Returns a pandas df with the neg_mean_absolute_error, neg_mean_squared_error and r2 scores\n",
    "    for the model with the best mean 'metric' score across all validation folds.\n",
    "    '''\n",
    "\n",
    "    # Create dictionary that maps input metric to actual metric name in GridSearchCV\n",
    "    metric_dict = {'neg_mean_absolute_error': 'mean_test_neg_mean_absolute_error',\n",
    "                 'neg_mean_squared_error': 'mean_test_neg_mean_squared_error',\n",
    "                 'r2': 'mean_test_r2',\n",
    "                 }\n",
    "\n",
    "    # Get all the results from the CV and put them in a df\n",
    "    cv_results = pd.DataFrame(model_object.cv_results_)\n",
    "\n",
    "    # Isolate the row of the df with the max(metric) score\n",
    "    best_estimator_results = cv_results.iloc[cv_results[metric_dict[metric]].idxmax(), :]\n",
    "\n",
    "    # Extract neg_mean_absolute_error, neg_mean_squared_error, and r2 score from that row\n",
    "    neg_mean_absolute_error = best_estimator_results.mean_test_neg_mean_absolute_error\n",
    "    neg_mean_squared_error = best_estimator_results.mean_test_neg_mean_squared_error\n",
    "    r2 = best_estimator_results.mean_test_r2\n",
    "\n",
    "    # Create table of results\n",
    "    table = pd.DataFrame({'model': [model_name],\n",
    "                        'neg_mean_absolute_error': [neg_mean_absolute_error],\n",
    "                        'neg_mean_squared_error': [neg_mean_squared_error],\n",
    "                        'r2': [r2],\n",
    "                        },\n",
    "                       )\n",
    "\n",
    "    return table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e3ff13-0849-412b-b4eb-11743a7df646",
   "metadata": {},
   "source": [
    "## function: get_test_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6cf87f4b-3701-4779-889e-48e5dd8e36d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_scores(model_name:str, preds, y_test_data):\n",
    "    '''\n",
    "    Generate a table of test scores.\n",
    "\n",
    "    In:\n",
    "    model_name (string): how the model will be named in the output table\n",
    "    preds: numpy array of test predictions\n",
    "    y_test_data: numpy array of y_test data\n",
    "\n",
    "    Out:\n",
    "    table: a pandas df of neg_mean_absolute_error, neg_mean_squared_error and r2 scores for your model\n",
    "    '''\n",
    "    negative_mean_absolute_error = mean_absolute_error(y_test_data, preds)\n",
    "    negative_mean_squared_error = mean_squared_error(y_test_data, preds)\n",
    "    r2 = r2_score(y_test_data, preds)\n",
    "\n",
    "    table = pd.DataFrame({'model': [model_name],\n",
    "                        'neg_mean_absolute_error': [negative_mean_absolute_error],\n",
    "                        'neg_mean_squared_error': [negative_mean_squared_error],\n",
    "                        'r2': [r2]\n",
    "                        })\n",
    "\n",
    "    return table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b8dc8d-69a3-4a87-8cc7-f7994dadbc93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0bfa232c-b584-4ba8-a997-62a45b5b76d3",
   "metadata": {},
   "source": [
    "# LinearRegression and GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f0f928a2-7f66-42fb-a6ab-599ef68502d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate linear regression model\n",
    "lr = LinearRegression()\n",
    "\n",
    "# Create a dictionary of hyperparameters to tune\n",
    "cv_params = {'fit_intercept': [False],\n",
    "             'positive': [True]             \n",
    "}\n",
    "\n",
    "# Define a set of scoring metrics to capture\n",
    "scoring = ['neg_mean_absolute_error', 'neg_mean_squared_error', 'r2']\n",
    "\n",
    "lr1 = GridSearchCV(lr, cv_params, scoring=scoring, cv=4, refit='neg_mean_absolute_error', n_jobs=-1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c2ef1d01-31af-42c7-9f75-5c313865625a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/sdb1/2ndHome/anaconda3/envs/kaggle/lib/python3.10/site-packages/sklearn/utils/validation.py:877: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "/mnt/sdb1/2ndHome/anaconda3/envs/kaggle/lib/python3.10/site-packages/sklearn/utils/validation.py:877: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "/mnt/sdb1/2ndHome/anaconda3/envs/kaggle/lib/python3.10/site-packages/sklearn/utils/validation.py:877: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "/mnt/sdb1/2ndHome/anaconda3/envs/kaggle/lib/python3.10/site-packages/sklearn/utils/validation.py:877: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "/mnt/sdb1/2ndHome/anaconda3/envs/kaggle/lib/python3.10/site-packages/sklearn/utils/validation.py:877: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "/mnt/sdb1/2ndHome/anaconda3/envs/kaggle/lib/python3.10/site-packages/sklearn/utils/validation.py:877: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "/mnt/sdb1/2ndHome/anaconda3/envs/kaggle/lib/python3.10/site-packages/sklearn/utils/validation.py:877: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "/mnt/sdb1/2ndHome/anaconda3/envs/kaggle/lib/python3.10/site-packages/sklearn/utils/validation.py:877: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "/mnt/sdb1/2ndHome/anaconda3/envs/kaggle/lib/python3.10/site-packages/sklearn/utils/validation.py:877: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8min 10s, sys: 2.82 s, total: 8min 12s\n",
      "Wall time: 26min 39s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=4, estimator=LinearRegression(), n_jobs=-1,\n",
       "             param_grid={&#x27;fit_intercept&#x27;: [False], &#x27;positive&#x27;: [True]},\n",
       "             refit=&#x27;neg_mean_absolute_error&#x27;,\n",
       "             scoring=[&#x27;neg_mean_absolute_error&#x27;, &#x27;neg_mean_squared_error&#x27;,\n",
       "                      &#x27;r2&#x27;],\n",
       "             verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;GridSearchCV<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.model_selection.GridSearchCV.html\">?<span>Documentation for GridSearchCV</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>GridSearchCV(cv=4, estimator=LinearRegression(), n_jobs=-1,\n",
       "             param_grid={&#x27;fit_intercept&#x27;: [False], &#x27;positive&#x27;: [True]},\n",
       "             refit=&#x27;neg_mean_absolute_error&#x27;,\n",
       "             scoring=[&#x27;neg_mean_absolute_error&#x27;, &#x27;neg_mean_squared_error&#x27;,\n",
       "                      &#x27;r2&#x27;],\n",
       "             verbose=1)</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">best_estimator_: LinearRegression</label><div class=\"sk-toggleable__content fitted\"><pre>LinearRegression(fit_intercept=False, positive=True)</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;LinearRegression<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.linear_model.LinearRegression.html\">?<span>Documentation for LinearRegression</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>LinearRegression(fit_intercept=False, positive=True)</pre></div> </div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=4, estimator=LinearRegression(), n_jobs=-1,\n",
       "             param_grid={'fit_intercept': [False], 'positive': [True]},\n",
       "             refit='neg_mean_absolute_error',\n",
       "             scoring=['neg_mean_absolute_error', 'neg_mean_squared_error',\n",
       "                      'r2'],\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "lr1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "96d88ca0-b211-4bc2-9176-9bfb2646d9f2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-19924.29408944604"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Examine best score\n",
    "\n",
    "lr1.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b575f840-4547-4f44-b6b0-b1d730701241",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_intercept': False, 'positive': True}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Obtain best parameters\n",
    "\n",
    "lr1.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7714939b-9fb0-449a-9da3-966d9328e839",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>neg_mean_absolute_error</th>\n",
       "      <th>neg_mean_squared_error</th>\n",
       "      <th>r2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LR CV</td>\n",
       "      <td>-19924.294089</td>\n",
       "      <td>-5.036322e+09</td>\n",
       "      <td>0.012942</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   model  neg_mean_absolute_error  neg_mean_squared_error        r2\n",
       "0  LR CV            -19924.294089           -5.036322e+09  0.012942"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Call 'make_results()' on the GridSearch object\n",
    "\n",
    "results = make_results('LR CV', lr1, 'neg_mean_absolute_error')\n",
    "# results = pd.concat([results, results], axis=0)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "66d0ef3e-5177-4f84-9ce5-7ecba2aad315",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/sdb1/2ndHome/anaconda3/envs/kaggle/lib/python3.10/site-packages/sklearn/utils/validation.py:877: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Get scores on test data\n",
    "\n",
    "lr_preds = lr1.best_estimator_.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f64f8fd1-e19c-4bc2-9410-27b5c6a0fa71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>neg_mean_absolute_error</th>\n",
       "      <th>neg_mean_squared_error</th>\n",
       "      <th>r2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LR CV</td>\n",
       "      <td>-19924.294089</td>\n",
       "      <td>-5.036322e+09</td>\n",
       "      <td>0.012942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LR test</td>\n",
       "      <td>20031.098488</td>\n",
       "      <td>5.680592e+09</td>\n",
       "      <td>0.040122</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     model  neg_mean_absolute_error  neg_mean_squared_error        r2\n",
       "0    LR CV            -19924.294089           -5.036322e+09  0.012942\n",
       "0  LR test             20031.098488            5.680592e+09  0.040122"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get scores on test data\n",
    "\n",
    "lr_test_scores = get_test_scores('LR test', lr_preds, y_test)\n",
    "results = pd.concat([results, lr_test_scores], axis=0)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "febf9979-20a8-437f-a33d-c4f3668401d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e587664c-000c-4fe1-9640-f7dae4bb4b13",
   "metadata": {},
   "source": [
    "# RandomForestRegressor and GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "31f7b3ab-9527-4bc9-ab86-63bc1cd5df7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate random forest classifier\n",
    "rfr = RandomForestRegressor()\n",
    "\n",
    "# Create a dictionary of hyperparameters to tune\n",
    "cv_params = {'max_depth': [5],\n",
    "             'min_samples_split': [10],\n",
    "             'n_estimators': [50]\n",
    "}\n",
    "\n",
    "# Define a set of scoring metrics to capture\n",
    "scoring = ['neg_mean_absolute_error', 'neg_mean_squared_error', 'r2']\n",
    "\n",
    "# Instantiate the GridSearchCV object\n",
    "rf1 = GridSearchCV(rfr, cv_params, scoring=scoring, cv=4, refit='neg_mean_absolute_error', n_jobs=-1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "65658d67-f15e-4c3c-b6c6-680e417e1959",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/sdb1/2ndHome/anaconda3/envs/kaggle/lib/python3.10/site-packages/sklearn/utils/validation.py:877: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "/mnt/sdb1/2ndHome/anaconda3/envs/kaggle/lib/python3.10/site-packages/sklearn/utils/validation.py:877: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "/mnt/sdb1/2ndHome/anaconda3/envs/kaggle/lib/python3.10/site-packages/sklearn/utils/validation.py:877: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "/mnt/sdb1/2ndHome/anaconda3/envs/kaggle/lib/python3.10/site-packages/sklearn/utils/validation.py:877: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "/mnt/sdb1/2ndHome/anaconda3/envs/kaggle/lib/python3.10/site-packages/sklearn/utils/validation.py:877: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "/mnt/sdb1/2ndHome/anaconda3/envs/kaggle/lib/python3.10/site-packages/sklearn/utils/validation.py:877: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "/mnt/sdb1/2ndHome/anaconda3/envs/kaggle/lib/python3.10/site-packages/sklearn/utils/validation.py:877: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "/mnt/sdb1/2ndHome/anaconda3/envs/kaggle/lib/python3.10/site-packages/sklearn/utils/validation.py:877: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "/mnt/sdb1/2ndHome/anaconda3/envs/kaggle/lib/python3.10/site-packages/sklearn/utils/validation.py:877: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 7s, sys: 586 ms, total: 1min 8s\n",
      "Wall time: 2min 17s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-3 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-3 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-3 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-3 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-3 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-3 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=4, estimator=RandomForestRegressor(), n_jobs=-1,\n",
       "             param_grid={&#x27;max_depth&#x27;: [5], &#x27;min_samples_split&#x27;: [10],\n",
       "                         &#x27;n_estimators&#x27;: [50]},\n",
       "             refit=&#x27;neg_mean_absolute_error&#x27;,\n",
       "             scoring=[&#x27;neg_mean_absolute_error&#x27;, &#x27;neg_mean_squared_error&#x27;,\n",
       "                      &#x27;r2&#x27;],\n",
       "             verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;GridSearchCV<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.model_selection.GridSearchCV.html\">?<span>Documentation for GridSearchCV</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>GridSearchCV(cv=4, estimator=RandomForestRegressor(), n_jobs=-1,\n",
       "             param_grid={&#x27;max_depth&#x27;: [5], &#x27;min_samples_split&#x27;: [10],\n",
       "                         &#x27;n_estimators&#x27;: [50]},\n",
       "             refit=&#x27;neg_mean_absolute_error&#x27;,\n",
       "             scoring=[&#x27;neg_mean_absolute_error&#x27;, &#x27;neg_mean_squared_error&#x27;,\n",
       "                      &#x27;r2&#x27;],\n",
       "             verbose=1)</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">best_estimator_: RandomForestRegressor</label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestRegressor(max_depth=5, min_samples_split=10, n_estimators=50)</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;RandomForestRegressor<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.ensemble.RandomForestRegressor.html\">?<span>Documentation for RandomForestRegressor</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestRegressor(max_depth=5, min_samples_split=10, n_estimators=50)</pre></div> </div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=4, estimator=RandomForestRegressor(), n_jobs=-1,\n",
       "             param_grid={'max_depth': [5], 'min_samples_split': [10],\n",
       "                         'n_estimators': [50]},\n",
       "             refit='neg_mean_absolute_error',\n",
       "             scoring=['neg_mean_absolute_error', 'neg_mean_squared_error',\n",
       "                      'r2'],\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "rf1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2f6492fb-d5bf-4f5b-a74f-b4e7ed7f8b31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-19412.829282254956"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Examine best score\n",
    "\n",
    "rf1.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7e127d0f-fce9-4fbb-afc9-3c0e4c12a35c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 5, 'min_samples_split': 10, 'n_estimators': 50}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Obtain best parameters\n",
    "\n",
    "rf1.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a2e46e27-7ca4-4b41-9ca2-e31e411e4ed7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>neg_mean_absolute_error</th>\n",
       "      <th>neg_mean_squared_error</th>\n",
       "      <th>r2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LR CV</td>\n",
       "      <td>-19924.294089</td>\n",
       "      <td>-5.036322e+09</td>\n",
       "      <td>0.012942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LR test</td>\n",
       "      <td>20031.098488</td>\n",
       "      <td>5.680592e+09</td>\n",
       "      <td>0.040122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RF CV</td>\n",
       "      <td>-19412.829282</td>\n",
       "      <td>-4.900808e+09</td>\n",
       "      <td>0.048282</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     model  neg_mean_absolute_error  neg_mean_squared_error        r2\n",
       "0    LR CV            -19924.294089           -5.036322e+09  0.012942\n",
       "0  LR test             20031.098488            5.680592e+09  0.040122\n",
       "0    RF CV            -19412.829282           -4.900808e+09  0.048282"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Call 'make_results()' on the GridSearch object\n",
    "\n",
    "rf_cv_results = make_results('RF CV', rf1, 'neg_mean_absolute_error')\n",
    "results = pd.concat([results, rf_cv_results], axis=0)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "bc0add6e-08c6-4920-b42a-b3cd1222e8d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/sdb1/2ndHome/anaconda3/envs/kaggle/lib/python3.10/site-packages/sklearn/utils/validation.py:877: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Get scores on test data\n",
    "\n",
    "rf_preds = rf1.best_estimator_.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "04dd588c-f11a-453d-a73e-d697492a267e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>neg_mean_absolute_error</th>\n",
       "      <th>neg_mean_squared_error</th>\n",
       "      <th>r2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LR CV</td>\n",
       "      <td>-19924.294089</td>\n",
       "      <td>-5.036322e+09</td>\n",
       "      <td>0.012942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LR test</td>\n",
       "      <td>20031.098488</td>\n",
       "      <td>5.680592e+09</td>\n",
       "      <td>0.040122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RF CV</td>\n",
       "      <td>-19412.829282</td>\n",
       "      <td>-4.900808e+09</td>\n",
       "      <td>0.048282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RF test</td>\n",
       "      <td>19291.191762</td>\n",
       "      <td>5.535498e+09</td>\n",
       "      <td>0.064639</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     model  neg_mean_absolute_error  neg_mean_squared_error        r2\n",
       "0    LR CV            -19924.294089           -5.036322e+09  0.012942\n",
       "0  LR test             20031.098488            5.680592e+09  0.040122\n",
       "0    RF CV            -19412.829282           -4.900808e+09  0.048282\n",
       "0  RF test             19291.191762            5.535498e+09  0.064639"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get scores on test data\n",
    "\n",
    "rf_test_scores = get_test_scores('RF test', rf_preds, y_test)\n",
    "results = pd.concat([results, rf_test_scores], axis=0)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e1fcda-ff31-478f-bdf1-f340e8fe43c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "63cfd1b4-6a26-41c8-a671-3eb70c0474dc",
   "metadata": {},
   "source": [
    "# XGBoost and GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2d69b5c9-2029-4227-b1fe-6bfffecbb989",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the XGBoost classifier\n",
    "xgb = xgb.XGBRegressor(objective='reg:squarederror', random_state=25)\n",
    "\n",
    "# Create a dictionary of hyperparameters to tune\n",
    "cv_params = {'learning_rate': [0.2],\n",
    "             'max_depth': [3],\n",
    "             'n_estimators': [50]\n",
    "             }\n",
    "\n",
    "# Define a set of scoring metrics to capture\n",
    "scoring = ['neg_mean_absolute_error', 'neg_mean_squared_error', 'r2']\n",
    "\n",
    "# Instantiate the GridSearchCV object\n",
    "xgb1 = GridSearchCV(xgb, cv_params, scoring=scoring, cv=4, refit='neg_mean_absolute_error', n_jobs=-1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "637e2ab8-c882-44a9-b3a3-0c92bb89a9b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "CPU times: user 48.1 s, sys: 1.96 s, total: 50 s\n",
      "Wall time: 29.5 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-4 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-4 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-4 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-4 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-4 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-4 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-4 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-4 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-4 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=4,\n",
       "             estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                    callbacks=None, colsample_bylevel=None,\n",
       "                                    colsample_bynode=None,\n",
       "                                    colsample_bytree=None, device=None,\n",
       "                                    early_stopping_rounds=None,\n",
       "                                    enable_categorical=False, eval_metric=None,\n",
       "                                    feature_types=None, gamma=None,\n",
       "                                    grow_policy=None, importance_type=None,\n",
       "                                    interaction_constraints=None,\n",
       "                                    learning_rate=None, m...\n",
       "                                    max_depth=None, max_leaves=None,\n",
       "                                    min_child_weight=None, missing=nan,\n",
       "                                    monotone_constraints=None,\n",
       "                                    multi_strategy=None, n_estimators=None,\n",
       "                                    n_jobs=None, num_parallel_tree=None,\n",
       "                                    random_state=25, ...),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;learning_rate&#x27;: [0.2], &#x27;max_depth&#x27;: [3],\n",
       "                         &#x27;n_estimators&#x27;: [50]},\n",
       "             refit=&#x27;neg_mean_absolute_error&#x27;,\n",
       "             scoring=[&#x27;neg_mean_absolute_error&#x27;, &#x27;neg_mean_squared_error&#x27;,\n",
       "                      &#x27;r2&#x27;],\n",
       "             verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;GridSearchCV<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.model_selection.GridSearchCV.html\">?<span>Documentation for GridSearchCV</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>GridSearchCV(cv=4,\n",
       "             estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                    callbacks=None, colsample_bylevel=None,\n",
       "                                    colsample_bynode=None,\n",
       "                                    colsample_bytree=None, device=None,\n",
       "                                    early_stopping_rounds=None,\n",
       "                                    enable_categorical=False, eval_metric=None,\n",
       "                                    feature_types=None, gamma=None,\n",
       "                                    grow_policy=None, importance_type=None,\n",
       "                                    interaction_constraints=None,\n",
       "                                    learning_rate=None, m...\n",
       "                                    max_depth=None, max_leaves=None,\n",
       "                                    min_child_weight=None, missing=nan,\n",
       "                                    monotone_constraints=None,\n",
       "                                    multi_strategy=None, n_estimators=None,\n",
       "                                    n_jobs=None, num_parallel_tree=None,\n",
       "                                    random_state=25, ...),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;learning_rate&#x27;: [0.2], &#x27;max_depth&#x27;: [3],\n",
       "                         &#x27;n_estimators&#x27;: [50]},\n",
       "             refit=&#x27;neg_mean_absolute_error&#x27;,\n",
       "             scoring=[&#x27;neg_mean_absolute_error&#x27;, &#x27;neg_mean_squared_error&#x27;,\n",
       "                      &#x27;r2&#x27;],\n",
       "             verbose=1)</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">best_estimator_: XGBRegressor</label><div class=\"sk-toggleable__content fitted\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=0.2, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=3, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=50, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=25, ...)</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">XGBRegressor</label><div class=\"sk-toggleable__content fitted\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=0.2, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=3, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=50, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=25, ...)</pre></div> </div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=4,\n",
       "             estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                    callbacks=None, colsample_bylevel=None,\n",
       "                                    colsample_bynode=None,\n",
       "                                    colsample_bytree=None, device=None,\n",
       "                                    early_stopping_rounds=None,\n",
       "                                    enable_categorical=False, eval_metric=None,\n",
       "                                    feature_types=None, gamma=None,\n",
       "                                    grow_policy=None, importance_type=None,\n",
       "                                    interaction_constraints=None,\n",
       "                                    learning_rate=None, m...\n",
       "                                    max_depth=None, max_leaves=None,\n",
       "                                    min_child_weight=None, missing=nan,\n",
       "                                    monotone_constraints=None,\n",
       "                                    multi_strategy=None, n_estimators=None,\n",
       "                                    n_jobs=None, num_parallel_tree=None,\n",
       "                                    random_state=25, ...),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'learning_rate': [0.2], 'max_depth': [3],\n",
       "                         'n_estimators': [50]},\n",
       "             refit='neg_mean_absolute_error',\n",
       "             scoring=['neg_mean_absolute_error', 'neg_mean_squared_error',\n",
       "                      'r2'],\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "xgb1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8aca3b18-c5c4-4882-bbc5-4430e3e8b318",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-18400.682969972717"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Examine best score\n",
    "xgb1.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "318e1529-0742-4795-94f3-bf02df9ea305",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.2, 'max_depth': 3, 'n_estimators': 50}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Examine best parameters\n",
    "xgb1.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9032af71-6f9e-4b09-b2aa-4d7c57ced316",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>neg_mean_absolute_error</th>\n",
       "      <th>neg_mean_squared_error</th>\n",
       "      <th>r2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LR CV</td>\n",
       "      <td>-19924.294089</td>\n",
       "      <td>-5.036322e+09</td>\n",
       "      <td>0.012942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LR test</td>\n",
       "      <td>20031.098488</td>\n",
       "      <td>5.680592e+09</td>\n",
       "      <td>0.040122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RF CV</td>\n",
       "      <td>-19412.829282</td>\n",
       "      <td>-4.900808e+09</td>\n",
       "      <td>0.048282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RF test</td>\n",
       "      <td>19291.191762</td>\n",
       "      <td>5.535498e+09</td>\n",
       "      <td>0.064639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGB CV</td>\n",
       "      <td>-18400.682970</td>\n",
       "      <td>-4.886125e+09</td>\n",
       "      <td>0.044883</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     model  neg_mean_absolute_error  neg_mean_squared_error        r2\n",
       "0    LR CV            -19924.294089           -5.036322e+09  0.012942\n",
       "0  LR test             20031.098488            5.680592e+09  0.040122\n",
       "0    RF CV            -19412.829282           -4.900808e+09  0.048282\n",
       "0  RF test             19291.191762            5.535498e+09  0.064639\n",
       "0   XGB CV            -18400.682970           -4.886125e+09  0.044883"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Call make_results() on the GridSearch object\n",
    "\n",
    "xgb1_cv_results = make_results('XGB CV', xgb1, 'neg_mean_absolute_error')\n",
    "results = pd.concat([results, xgb1_cv_results], axis=0)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "045eef98-6f54-4996-a18a-06b2d5cb797a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get scores on test data\n",
    "\n",
    "xgb_preds = xgb1.best_estimator_.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "076853a6-ff2f-486a-9936-43442b6a8354",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>neg_mean_absolute_error</th>\n",
       "      <th>neg_mean_squared_error</th>\n",
       "      <th>r2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LR CV</td>\n",
       "      <td>-19924.294089</td>\n",
       "      <td>-5.036322e+09</td>\n",
       "      <td>0.012942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LR test</td>\n",
       "      <td>20031.098488</td>\n",
       "      <td>5.680592e+09</td>\n",
       "      <td>0.040122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RF CV</td>\n",
       "      <td>-19412.829282</td>\n",
       "      <td>-4.900808e+09</td>\n",
       "      <td>0.048282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RF test</td>\n",
       "      <td>19291.191762</td>\n",
       "      <td>5.535498e+09</td>\n",
       "      <td>0.064639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGB CV</td>\n",
       "      <td>-18400.682970</td>\n",
       "      <td>-4.886125e+09</td>\n",
       "      <td>0.044883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGB test</td>\n",
       "      <td>18564.635809</td>\n",
       "      <td>5.531917e+09</td>\n",
       "      <td>0.065244</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      model  neg_mean_absolute_error  neg_mean_squared_error        r2\n",
       "0     LR CV            -19924.294089           -5.036322e+09  0.012942\n",
       "0   LR test             20031.098488            5.680592e+09  0.040122\n",
       "0     RF CV            -19412.829282           -4.900808e+09  0.048282\n",
       "0   RF test             19291.191762            5.535498e+09  0.064639\n",
       "0    XGB CV            -18400.682970           -4.886125e+09  0.044883\n",
       "0  XGB test             18564.635809            5.531917e+09  0.065244"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get scores on test data\n",
    "\n",
    "xgb_test_scores = get_test_scores('XGB test', xgb_preds, y_test)\n",
    "results = pd.concat([results, xgb_test_scores], axis=0)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0213dd-361c-4ad6-b431-a9cc2f3480c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "41fe3960-6872-4185-9254-0a4a9c81291f",
   "metadata": {},
   "source": [
    "# DecisionTreeClassifier and GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6839dce1-6435-4ab0-a750-c11a5591c1dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate random forest classifier\n",
    "dtc = DecisionTreeRegressor()\n",
    "\n",
    "# Create a dictionary of hyperparameters to tune\n",
    "cv_params = {'max_depth': [5],\n",
    "             'min_samples_split': [10],\n",
    "             'min_samples_leaf': [10]\n",
    "             }\n",
    "\n",
    "# Define a set of scoring metrics to capture\n",
    "scoring = ['neg_mean_absolute_error', 'neg_mean_squared_error', 'r2']\n",
    "\n",
    "# Instantiate the GridSearchCV object\n",
    "dtc1 = GridSearchCV(dtc, cv_params, scoring=scoring, cv=4, refit='neg_mean_absolute_error', n_jobs=-1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "cfe9b1a9-5fbe-4acb-92e0-82ea52c93032",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/sdb1/2ndHome/anaconda3/envs/kaggle/lib/python3.10/site-packages/sklearn/utils/validation.py:877: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "/mnt/sdb1/2ndHome/anaconda3/envs/kaggle/lib/python3.10/site-packages/sklearn/utils/validation.py:877: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "/mnt/sdb1/2ndHome/anaconda3/envs/kaggle/lib/python3.10/site-packages/sklearn/utils/validation.py:877: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "/mnt/sdb1/2ndHome/anaconda3/envs/kaggle/lib/python3.10/site-packages/sklearn/utils/validation.py:877: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "/mnt/sdb1/2ndHome/anaconda3/envs/kaggle/lib/python3.10/site-packages/sklearn/utils/validation.py:877: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "/mnt/sdb1/2ndHome/anaconda3/envs/kaggle/lib/python3.10/site-packages/sklearn/utils/validation.py:877: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "/mnt/sdb1/2ndHome/anaconda3/envs/kaggle/lib/python3.10/site-packages/sklearn/utils/validation.py:877: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "/mnt/sdb1/2ndHome/anaconda3/envs/kaggle/lib/python3.10/site-packages/sklearn/utils/validation.py:877: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "/mnt/sdb1/2ndHome/anaconda3/envs/kaggle/lib/python3.10/site-packages/sklearn/utils/validation.py:877: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.63 s, sys: 241 ms, total: 2.87 s\n",
      "Wall time: 8.83 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-5 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-5 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-5 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-5 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-5 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-5 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-5 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-5 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-5 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-5 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-5 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-5 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=4, estimator=DecisionTreeRegressor(), n_jobs=-1,\n",
       "             param_grid={&#x27;max_depth&#x27;: [5], &#x27;min_samples_leaf&#x27;: [10],\n",
       "                         &#x27;min_samples_split&#x27;: [10]},\n",
       "             refit=&#x27;neg_mean_absolute_error&#x27;,\n",
       "             scoring=[&#x27;neg_mean_absolute_error&#x27;, &#x27;neg_mean_squared_error&#x27;,\n",
       "                      &#x27;r2&#x27;],\n",
       "             verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;GridSearchCV<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.model_selection.GridSearchCV.html\">?<span>Documentation for GridSearchCV</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>GridSearchCV(cv=4, estimator=DecisionTreeRegressor(), n_jobs=-1,\n",
       "             param_grid={&#x27;max_depth&#x27;: [5], &#x27;min_samples_leaf&#x27;: [10],\n",
       "                         &#x27;min_samples_split&#x27;: [10]},\n",
       "             refit=&#x27;neg_mean_absolute_error&#x27;,\n",
       "             scoring=[&#x27;neg_mean_absolute_error&#x27;, &#x27;neg_mean_squared_error&#x27;,\n",
       "                      &#x27;r2&#x27;],\n",
       "             verbose=1)</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">best_estimator_: DecisionTreeRegressor</label><div class=\"sk-toggleable__content fitted\"><pre>DecisionTreeRegressor(max_depth=5, min_samples_leaf=10, min_samples_split=10)</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;DecisionTreeRegressor<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.tree.DecisionTreeRegressor.html\">?<span>Documentation for DecisionTreeRegressor</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>DecisionTreeRegressor(max_depth=5, min_samples_leaf=10, min_samples_split=10)</pre></div> </div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=4, estimator=DecisionTreeRegressor(), n_jobs=-1,\n",
       "             param_grid={'max_depth': [5], 'min_samples_leaf': [10],\n",
       "                         'min_samples_split': [10]},\n",
       "             refit='neg_mean_absolute_error',\n",
       "             scoring=['neg_mean_absolute_error', 'neg_mean_squared_error',\n",
       "                      'r2'],\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "dtc1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "502f53e4-12fa-4ab3-a1c5-21928b63ef2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-19348.23736822779"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Examine best score\n",
    "\n",
    "dtc1.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "0cedc21b-84ef-4fe1-b16d-9253e2c2345c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 5, 'min_samples_leaf': 10, 'min_samples_split': 10}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Examine best parameters\n",
    "\n",
    "dtc1.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "37182344-bc7f-4080-97eb-4f8622e58f8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>neg_mean_absolute_error</th>\n",
       "      <th>neg_mean_squared_error</th>\n",
       "      <th>r2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LR CV</td>\n",
       "      <td>-19924.294089</td>\n",
       "      <td>-5.036322e+09</td>\n",
       "      <td>0.012942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LR test</td>\n",
       "      <td>20031.098488</td>\n",
       "      <td>5.680592e+09</td>\n",
       "      <td>0.040122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RF CV</td>\n",
       "      <td>-19412.829282</td>\n",
       "      <td>-4.900808e+09</td>\n",
       "      <td>0.048282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RF test</td>\n",
       "      <td>19291.191762</td>\n",
       "      <td>5.535498e+09</td>\n",
       "      <td>0.064639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGB CV</td>\n",
       "      <td>-18400.682970</td>\n",
       "      <td>-4.886125e+09</td>\n",
       "      <td>0.044883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGB test</td>\n",
       "      <td>18564.635809</td>\n",
       "      <td>5.531917e+09</td>\n",
       "      <td>0.065244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DTC CV</td>\n",
       "      <td>-19348.237368</td>\n",
       "      <td>-4.829772e+09</td>\n",
       "      <td>0.060186</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      model  neg_mean_absolute_error  neg_mean_squared_error        r2\n",
       "0     LR CV            -19924.294089           -5.036322e+09  0.012942\n",
       "0   LR test             20031.098488            5.680592e+09  0.040122\n",
       "0     RF CV            -19412.829282           -4.900808e+09  0.048282\n",
       "0   RF test             19291.191762            5.535498e+09  0.064639\n",
       "0    XGB CV            -18400.682970           -4.886125e+09  0.044883\n",
       "0  XGB test             18564.635809            5.531917e+09  0.065244\n",
       "0    DTC CV            -19348.237368           -4.829772e+09  0.060186"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Call 'make_results()' on the GridSearch object\n",
    "\n",
    "dtv_cv_results = make_results('DTC CV', dtc1, 'neg_mean_absolute_error')\n",
    "results = pd.concat([results, dtv_cv_results], axis=0)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b9318637-d11b-4a6d-9a9a-3d55bc5eb3ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/sdb1/2ndHome/anaconda3/envs/kaggle/lib/python3.10/site-packages/sklearn/utils/validation.py:877: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Get scores on test data\n",
    "\n",
    "dtc_preds = dtc1.best_estimator_.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b295334b-df8a-4c90-9242-4fb479e31f2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>neg_mean_absolute_error</th>\n",
       "      <th>neg_mean_squared_error</th>\n",
       "      <th>r2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LR CV</td>\n",
       "      <td>-19924.294089</td>\n",
       "      <td>-5.036322e+09</td>\n",
       "      <td>0.012942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LR test</td>\n",
       "      <td>20031.098488</td>\n",
       "      <td>5.680592e+09</td>\n",
       "      <td>0.040122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RF CV</td>\n",
       "      <td>-19412.829282</td>\n",
       "      <td>-4.900808e+09</td>\n",
       "      <td>0.048282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RF test</td>\n",
       "      <td>19291.191762</td>\n",
       "      <td>5.535498e+09</td>\n",
       "      <td>0.064639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGB CV</td>\n",
       "      <td>-18400.682970</td>\n",
       "      <td>-4.886125e+09</td>\n",
       "      <td>0.044883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGB test</td>\n",
       "      <td>18564.635809</td>\n",
       "      <td>5.531917e+09</td>\n",
       "      <td>0.065244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DTC CV</td>\n",
       "      <td>-19348.237368</td>\n",
       "      <td>-4.829772e+09</td>\n",
       "      <td>0.060186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DTC test</td>\n",
       "      <td>19451.246515</td>\n",
       "      <td>5.511835e+09</td>\n",
       "      <td>0.068638</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      model  neg_mean_absolute_error  neg_mean_squared_error        r2\n",
       "0     LR CV            -19924.294089           -5.036322e+09  0.012942\n",
       "0   LR test             20031.098488            5.680592e+09  0.040122\n",
       "0     RF CV            -19412.829282           -4.900808e+09  0.048282\n",
       "0   RF test             19291.191762            5.535498e+09  0.064639\n",
       "0    XGB CV            -18400.682970           -4.886125e+09  0.044883\n",
       "0  XGB test             18564.635809            5.531917e+09  0.065244\n",
       "0    DTC CV            -19348.237368           -4.829772e+09  0.060186\n",
       "0  DTC test             19451.246515            5.511835e+09  0.068638"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get scores on test data\n",
    "\n",
    "dtc_test_scores = get_test_scores('DTC test', dtc_preds, y_test)\n",
    "results = pd.concat([results, dtc_test_scores], axis=0)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef59e87-1331-4d10-a735-01444cfd4fbe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "88f0e44d-01c3-433a-a198-2fd12c017a5d",
   "metadata": {},
   "source": [
    "# Tensorflow and GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a80700-20fa-4763-89d6-c16f70a27ca9",
   "metadata": {},
   "source": [
    "## NeuralNetwork Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "250ded47-d8a6-4e75-9135-59c8b444dd4e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Convert sparse matrices to dense tensors\n",
    "\n",
    "X_train_array = X_train.values\n",
    "X_test_array = X_test.values\n",
    "y_train_array = y_train.values\n",
    "y_test_array = y_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f469cb67-cff8-425f-abcf-c366ab0d8ca1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3383"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the number of features\n",
    "\n",
    "input_dim = X_train_array.shape[1]\n",
    "input_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "1b418bc3-b2a3-4e2e-b5fe-aef9b6dd4809",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the model\n",
    "\n",
    "def create_model(optimizer='adam', learning_rate=1e-3):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(10, input_dim=input_dim, activation='relu'))\n",
    "    model.add(Dense(10, activation='relu'))\n",
    "    model.add(Dense(1, activation='linear'))\n",
    "    model.compile(loss='mean_squared_error', optimizer=optimizer, metrics=['mae'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "7eb91645-7b63-4873-bb95-59d6d85bb4a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Wrap the model using the KerasRegressor\n",
    "# Needed to allow compatibility between the Tensorflow object and scikit-learn's GridSearchCV\n",
    "\n",
    "tf_model = KerasRegressor(build_fn=create_model, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d9c3af08-6b17-45b1-8042-b13cabe258b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a dictionary of hyperparameters to tune\n",
    "cv_params = {'batch_size': [32],\n",
    "             'epochs': [200, 300]\n",
    "            }\n",
    "\n",
    "# Define a set of scoring metrics to capture\n",
    "scoring = ['neg_mean_absolute_error', 'neg_mean_squared_error', 'r2']\n",
    "\n",
    "# Instantiate the GridSearchCV object\n",
    "tf_model1 = GridSearchCV(tf_model, cv_params, scoring=scoring, cv=4, refit='neg_mean_absolute_error', n_jobs=-1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "54afa714-d5ad-4955-992f-54c8f67701c2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 2 candidates, totalling 8 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-17 10:28:20.117908: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-07-17 10:28:20.117908: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-07-17 10:28:20.117909: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-07-17 10:28:20.117911: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-07-17 10:28:20.120942: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-07-17 10:28:20.120944: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-07-17 10:28:20.120944: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-07-17 10:28:20.120950: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-07-17 10:28:20.158761: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-17 10:28:20.158761: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-17 10:28:20.158761: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-17 10:28:20.158761: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-17 10:28:20.359664: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-07-17 10:28:20.359664: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-07-17 10:28:20.363031: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-07-17 10:28:20.363032: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-07-17 10:28:20.369857: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-07-17 10:28:20.369857: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-07-17 10:28:20.373183: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-07-17 10:28:20.373185: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-07-17 10:28:20.407745: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-17 10:28:20.407745: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-17 10:28:20.419054: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-17 10:28:20.419239: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-17 10:28:20.874048: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-07-17 10:28:20.874048: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-07-17 10:28:20.874048: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-07-17 10:28:20.874063: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-07-17 10:28:21.215302: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-07-17 10:28:21.215302: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-07-17 10:28:21.220581: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-07-17 10:28:21.230489: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/mnt/sdb1/2ndHome/anaconda3/envs/kaggle/lib/python3.10/site-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/mnt/sdb1/2ndHome/anaconda3/envs/kaggle/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/mnt/sdb1/2ndHome/anaconda3/envs/kaggle/lib/python3.10/site-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/mnt/sdb1/2ndHome/anaconda3/envs/kaggle/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/mnt/sdb1/2ndHome/anaconda3/envs/kaggle/lib/python3.10/site-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/mnt/sdb1/2ndHome/anaconda3/envs/kaggle/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/mnt/sdb1/2ndHome/anaconda3/envs/kaggle/lib/python3.10/site-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/mnt/sdb1/2ndHome/anaconda3/envs/kaggle/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/mnt/sdb1/2ndHome/anaconda3/envs/kaggle/lib/python3.10/site-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/mnt/sdb1/2ndHome/anaconda3/envs/kaggle/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/mnt/sdb1/2ndHome/anaconda3/envs/kaggle/lib/python3.10/site-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/mnt/sdb1/2ndHome/anaconda3/envs/kaggle/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/mnt/sdb1/2ndHome/anaconda3/envs/kaggle/lib/python3.10/site-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/mnt/sdb1/2ndHome/anaconda3/envs/kaggle/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "2024-07-17 10:28:26.387449: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 440656048 exceeds 10% of free system memory.\n",
      "2024-07-17 10:28:26.594323: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 440656048 exceeds 10% of free system memory.\n",
      "2024-07-17 10:28:26.720554: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 440642516 exceeds 10% of free system memory.\n",
      "/mnt/sdb1/2ndHome/anaconda3/envs/kaggle/lib/python3.10/site-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/mnt/sdb1/2ndHome/anaconda3/envs/kaggle/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "2024-07-17 10:28:26.878965: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 440642516 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "Epoch 1/300\n",
      "Epoch 1/300\n",
      "Epoch 1/300\n",
      "\u001b[1m 541/1018\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 7673294336.0000 - mae: 35248.5977"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-17 10:28:29.706738: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 440642516 exceeds 10% of free system memory.\n",
      "2024-07-17 10:28:29.865575: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 440656048 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 849/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6805466112.0000 - mae: 35114.5938Epoch 1/200\n",
      "\u001b[1m 851/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7402331136.0000 - mae: 34596.7930"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-17 10:28:30.389258: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 440656048 exceeds 10% of free system memory.\n",
      "2024-07-17 10:28:30.427077: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 440642516 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 871/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7380293632.0000 - mae: 34559.0312Epoch 1/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 5468774912.0000 - mae: 34310.6172\n",
      "Epoch 2/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 6157713920.0000 - mae: 34014.8711\n",
      "Epoch 2/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 6627950080.0000 - mae: 34764.5312\n",
      "Epoch 2/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 7224775168.0000 - mae: 34327.4688\n",
      "Epoch 2/300\n",
      "\u001b[1m  46/1018\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 5191720448.0000 - mae: 31615.9219  04.47Epoch 1/200\n",
      "Epoch 1/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 6782364672.0000 - mae: 27036.158284\n",
      "Epoch 3/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 6361067008.0000 - mae: 30900.4766\n",
      "Epoch 3/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 933us/step - loss: 5898264576.0000 - mae: 32535.9863\n",
      "Epoch 2/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 4754428416.0000 - mae: 37977.8945\n",
      "Epoch 2/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4822508032.0000 - mae: 20075.6426\n",
      "Epoch 3/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 4705704960.0000 - mae: 19384.4609\n",
      "Epoch 4/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 6216552960.0000 - mae: 22777.0234\n",
      "Epoch 4/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 6433743360.0000 - mae: 34114.6836\n",
      "Epoch 2/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 5166943744.0000 - mae: 29069.0547\n",
      "Epoch 3/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 6977614848.0000 - mae: 33529.4258\n",
      "\u001b[1m 516/1018\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 5367694848.0000 - mae: 38778.1289Epoch 2/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 5590610944.0000 - mae: 30030.8340\n",
      "Epoch 3/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 5441475072.0000 - mae: 38812.3438\n",
      "Epoch 3/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 3839780864.0000 - mae: 19271.9414\n",
      "Epoch 4/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 6915035136.0000 - mae: 20905.4707\n",
      "Epoch 5/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 3853292032.0000 - mae: 19130.1875\n",
      "Epoch 4/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 4966948864.0000 - mae: 31292.4883\n",
      "Epoch 3/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 5298188288.0000 - mae: 38428.2891\n",
      "Epoch 4/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 4388441600.0000 - mae: 20235.2402\n",
      "\u001b[1m 789/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6549346816.0000 - mae: 19425.0918Epoch 4/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 4596825088.0000 - mae: 20082.3730\n",
      "Epoch 5/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 6107754496.0000 - mae: 19369.4219\n",
      "Epoch 5/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 4361705472.0000 - mae: 19679.2695\n",
      "Epoch 3/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 4971428352.0000 - mae: 19851.9648\n",
      "Epoch 6/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 4647094784.0000 - mae: 19500.8652\n",
      "Epoch 5/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 4840288256.0000 - mae: 25343.6270\n",
      "Epoch 4/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4098285312.0000 - mae: 19321.1328\n",
      "\u001b[1m 935/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5561936896.0000 - mae: 38441.0703Epoch 5/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 5598983680.0000 - mae: 38467.8594\n",
      "Epoch 5/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4649625600.0000 - mae: 19624.6934\n",
      "Epoch 6/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 5024597504.0000 - mae: 20430.9590\n",
      "\u001b[1m 248/1018\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 5829515264.0000 - mae: 21099.2520Epoch 7/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 5392549376.0000 - mae: 20376.9980\n",
      "Epoch 4/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 5118868992.0000 - mae: 20040.6582\n",
      "Epoch 6/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 6138362880.0000 - mae: 38814.9688\n",
      "Epoch 6/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 5858554368.0000 - mae: 20305.5039\n",
      "Epoch 6/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 5851001856.0000 - mae: 20682.5566\n",
      "Epoch 6/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 4364864000.0000 - mae: 20542.1328\n",
      "Epoch 8/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4241562368.0000 - mae: 18933.8086\n",
      "\u001b[1m 992/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5293903872.0000 - mae: 20274.8418Epoch 7/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 5278268928.0000 - mae: 20255.8848\n",
      "Epoch 7/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 7454249984.0000 - mae: 39021.5312\n",
      "Epoch 7/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 4072903936.0000 - mae: 18939.4355\n",
      "Epoch 5/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 5625105408.0000 - mae: 20383.2852\n",
      "Epoch 5/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4193736448.0000 - mae: 19555.9570\n",
      "Epoch 7/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 4613355008.0000 - mae: 19316.2090\n",
      "\u001b[1m 934/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4078108416.0000 - mae: 19715.4746Epoch 8/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 4178297344.0000 - mae: 19777.2773\n",
      "Epoch 9/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 3494506240.0000 - mae: 19027.1191\n",
      "Epoch 8/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 8243086336.0000 - mae: 39932.6641\n",
      "Epoch 8/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 4869381120.0000 - mae: 20056.5977\n",
      "Epoch 8/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 3773542400.0000 - mae: 19325.3125\n",
      "Epoch 7/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 6943602688.0000 - mae: 21201.0195\n",
      "Epoch 6/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 5503232512.0000 - mae: 19763.7285\n",
      "Epoch 9/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 7556103168.0000 - mae: 21398.7188\n",
      "Epoch 8/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 5259767296.0000 - mae: 38360.3555\n",
      "Epoch 9/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 4371396096.0000 - mae: 19614.1445\n",
      "Epoch 6/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 4812746752.0000 - mae: 19882.3574\n",
      "\u001b[1m 437/1018\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 2853530112.0000 - mae: 19010.9219Epoch 9/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 4342114304.0000 - mae: 19496.8867\n",
      "Epoch 9/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 5110163968.0000 - mae: 20014.2539\n",
      "Epoch 7/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 5850382848.0000 - mae: 20141.9219\n",
      "Epoch 7/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 4534779392.0000 - mae: 19802.4023\n",
      "\u001b[1m 514/1018\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3981793792.0000 - mae: 19664.1934Epoch 10/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 3628620288.0000 - mae: 19154.1465\n",
      "Epoch 9/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4423912960.0000 - mae: 19390.0293\n",
      "Epoch 10/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 4439206912.0000 - mae: 19428.5430\n",
      "Epoch 10/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 6519651328.0000 - mae: 38924.2266\n",
      "Epoch 10/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 4411044352.0000 - mae: 19795.0430\n",
      "Epoch 10/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 5224142336.0000 - mae: 19775.8281\n",
      "Epoch 8/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 4115214592.0000 - mae: 19287.9941\n",
      "Epoch 11/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 5095283200.0000 - mae: 20211.1270\n",
      "Epoch 8/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 4571187200.0000 - mae: 19867.5234\n",
      "Epoch 10/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 4266655744.0000 - mae: 19559.5703\n",
      "Epoch 11/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 5482449408.0000 - mae: 20311.0430\n",
      "Epoch 11/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 5697607680.0000 - mae: 20383.5957\n",
      "Epoch 9/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 5615932928.0000 - mae: 20569.5879\n",
      "Epoch 12/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4254157824.0000 - mae: 19647.6016\n",
      "Epoch 11/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 3831356416.0000 - mae: 19158.8965\n",
      "Epoch 11/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 4134778112.0000 - mae: 19373.9805\n",
      "Epoch 9/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 7010002432.0000 - mae: 39321.7930\n",
      "Epoch 11/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 3835614208.0000 - mae: 19423.1035\n",
      "Epoch 12/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 6416628224.0000 - mae: 20878.0156\n",
      "Epoch 10/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4141397504.0000 - mae: 19053.6152\n",
      "Epoch 12/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 4142223616.0000 - mae: 19902.6074\n",
      "Epoch 12/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 2899778304.0000 - mae: 19081.5020\n",
      "Epoch 10/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 3843867648.0000 - mae: 19057.3613\n",
      "Epoch 13/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 5188757504.0000 - mae: 20206.5137\n",
      "\u001b[1m 842/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5335217664.0000 - mae: 19962.0898Epoch 11/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 4597557760.0000 - mae: 19933.9609\n",
      "Epoch 13/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 6714310656.0000 - mae: 21258.3555\n",
      "Epoch 13/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 5256871936.0000 - mae: 19934.4004\n",
      "Epoch 11/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 4824547328.0000 - mae: 19697.8555\n",
      "Epoch 13/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 4178690048.0000 - mae: 18868.1191\n",
      "Epoch 14/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 3927572992.0000 - mae: 19071.1289\n",
      "Epoch 12/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 5816747008.0000 - mae: 38903.2930\n",
      "Epoch 12/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4725326336.0000 - mae: 19649.0703\n",
      "Epoch 14/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4336738816.0000 - mae: 19459.8066\n",
      "Epoch 12/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 7480179200.0000 - mae: 21434.4668\n",
      "Epoch 14/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 5973120000.0000 - mae: 20813.9043\n",
      "Epoch 12/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4902693376.0000 - mae: 19862.7363\n",
      "Epoch 15/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4666693632.0000 - mae: 20506.5488\n",
      "Epoch 13/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4396659712.0000 - mae: 19475.0098\n",
      "Epoch 15/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 4436181504.0000 - mae: 19198.9746\n",
      "Epoch 13/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 4748549120.0000 - mae: 20063.7891\n",
      "Epoch 14/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 5000115712.0000 - mae: 20313.4180\n",
      "Epoch 15/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 5236485120.0000 - mae: 19916.3340\n",
      "Epoch 13/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 5155173888.0000 - mae: 38558.9336\n",
      "Epoch 13/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 4348770816.0000 - mae: 19157.9004\n",
      "Epoch 16/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 4588912640.0000 - mae: 19955.3848\n",
      "\u001b[1m 964/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4191845120.0000 - mae: 19315.0137Epoch 14/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4225806592.0000 - mae: 19339.8828\n",
      "Epoch 16/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4996872704.0000 - mae: 19369.7305\n",
      "Epoch 15/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4729190400.0000 - mae: 20187.2227\n",
      "Epoch 14/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 4797980672.0000 - mae: 19970.5449\n",
      "Epoch 14/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 4719908352.0000 - mae: 19600.9531\n",
      "Epoch 17/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 5786558976.0000 - mae: 20215.7305\n",
      "\u001b[1m 737/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4646029312.0000 - mae: 20171.2500Epoch 15/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 5515950592.0000 - mae: 20553.4941\n",
      "Epoch 16/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 5690380288.0000 - mae: 20222.0410\n",
      "Epoch 15/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 4761199616.0000 - mae: 20121.0645\n",
      "Epoch 17/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 4229622784.0000 - mae: 19879.4180\n",
      "Epoch 16/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 3225073152.0000 - mae: 18642.7520\n",
      "Epoch 15/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 5195299840.0000 - mae: 20168.2012\n",
      "Epoch 16/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 3832374528.0000 - mae: 19079.6836\n",
      "Epoch 18/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 6980886528.0000 - mae: 39392.54699\n",
      "Epoch 14/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 5199547904.0000 - mae: 20022.9414\n",
      "Epoch 17/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 4990117376.0000 - mae: 19816.6543\n",
      "Epoch 18/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 4805844992.0000 - mae: 19136.5234\n",
      "Epoch 16/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 5723620352.0000 - mae: 20534.0527\n",
      "Epoch 17/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 3308697600.0000 - mae: 19126.3906\n",
      "\u001b[1m 378/1018\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 6649000448.0000 - mae: 20322.3887Epoch 19/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 5704839168.0000 - mae: 20192.5703\n",
      "Epoch 17/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 5390547968.0000 - mae: 38728.1328\n",
      "Epoch 15/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 4816858112.0000 - mae: 19708.3145\n",
      "Epoch 16/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 6078816256.0000 - mae: 20375.8105\n",
      "Epoch 17/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 6007630848.0000 - mae: 20321.3496\n",
      "Epoch 19/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 3543108864.0000 - mae: 19540.3379\n",
      "Epoch 18/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 4109650176.0000 - mae: 19776.6582\n",
      "Epoch 18/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 4580801024.0000 - mae: 20136.9629\n",
      "Epoch 20/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 5604820992.0000 - mae: 20298.9316\n",
      "\u001b[1m  71/1018\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 2400306944.0000 - mae: 19596.8652Epoch 18/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 6694245376.0000 - mae: 38646.3203\n",
      "Epoch 16/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 5526333952.0000 - mae: 20288.6035\n",
      "Epoch 18/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 3990268416.0000 - mae: 19414.5801\n",
      "Epoch 19/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 4820946432.0000 - mae: 19370.14063\n",
      "Epoch 20/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 5108144128.0000 - mae: 38559.7969\n",
      "\u001b[1m 126/1018\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 2753529344.0000 - mae: 19306.0039Epoch 17/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 3776716800.0000 - mae: 19394.4316\n",
      "Epoch 17/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 4642831360.0000 - mae: 19390.7090\n",
      "Epoch 21/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 5962154496.0000 - mae: 20255.0391\n",
      "Epoch 18/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 5130085376.0000 - mae: 20170.2266\n",
      "Epoch 19/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 4176784384.0000 - mae: 19815.5508\n",
      "Epoch 19/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 5127479808.0000 - mae: 20225.8594\n",
      "Epoch 21/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 5096800256.0000 - mae: 19917.6367\n",
      "Epoch 20/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 5433959936.0000 - mae: 38533.1484\n",
      "Epoch 18/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 4870874112.0000 - mae: 20118.3281\n",
      "Epoch 19/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 5369259520.0000 - mae: 20188.4609\n",
      "\u001b[1m 584/1018\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 8047646720.0000 - mae: 21803.7402Epoch 19/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4048699648.0000 - mae: 19154.5215\n",
      "Epoch 22/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 6855710208.0000 - mae: 21224.7832\n",
      "Epoch 20/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 4347539456.0000 - mae: 19419.1367\n",
      "Epoch 21/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 3503601664.0000 - mae: 18876.4336\n",
      "Epoch 20/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 5184603648.0000 - mae: 19652.9180\n",
      "Epoch 22/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 5424379392.0000 - mae: 38877.3750\n",
      "Epoch 19/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 5699730432.0000 - mae: 20673.3555\n",
      "Epoch 20/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 6136049152.0000 - mae: 20876.3242\n",
      "Epoch 20/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 6255209472.0000 - mae: 20956.2832\n",
      "Epoch 21/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 5046496256.0000 - mae: 20174.3418\n",
      "Epoch 23/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 3986554624.0000 - mae: 19650.0859\n",
      "Epoch 22/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4775889408.0000 - mae: 19921.2500\n",
      "Epoch 21/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4534135808.0000 - mae: 19416.7129\n",
      "\u001b[1m 577/1018\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 6285006336.0000 - mae: 20672.8359Epoch 24/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 6023113728.0000 - mae: 20519.4824\n",
      "\u001b[1m 580/1018\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 7742374912.0000 - mae: 21512.8379Epoch 21/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 5928511488.0000 - mae: 20485.3887\n",
      "\u001b[1m 126/1018\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 6889917440.0000 - mae: 20933.7793Epoch 21/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 4466377728.0000 - mae: 19804.2520\n",
      "Epoch 22/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 6677144576.0000 - mae: 21008.0254\n",
      "Epoch 23/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 6273512960.0000 - mae: 39281.3203\n",
      "Epoch 20/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 4919157248.0000 - mae: 19676.8711\n",
      "\u001b[1m 993/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5689129472.0000 - mae: 20048.5977Epoch 22/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 5149083648.0000 - mae: 20084.0488\n",
      "Epoch 25/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 5663586304.0000 - mae: 20036.9277\n",
      "Epoch 23/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 4194358016.0000 - mae: 19339.1152\n",
      "Epoch 22/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 5309809664.0000 - mae: 20297.1973\n",
      "Epoch 22/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 5410669568.0000 - mae: 20553.0723\n",
      "Epoch 23/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 3666278912.0000 - mae: 18639.8906\n",
      "Epoch 24/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4781049856.0000 - mae: 19720.1992\n",
      "Epoch 26/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 5640974336.0000 - mae: 38697.9219\n",
      "Epoch 21/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 3496757760.0000 - mae: 19083.2305\n",
      "Epoch 23/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 4351419392.0000 - mae: 19875.9570\n",
      "Epoch 24/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 4101242368.0000 - mae: 19153.8418\n",
      "Epoch 25/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4500216320.0000 - mae: 19968.4551\n",
      "Epoch 27/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 5830781440.0000 - mae: 38776.4414\n",
      "Epoch 22/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 3261665024.0000 - mae: 19038.7617\n",
      "Epoch 24/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 5825923072.0000 - mae: 19868.1113\n",
      "\u001b[1m1007/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4591478784.0000 - mae: 19532.3828Epoch 26/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 4592582144.0000 - mae: 19535.7578\n",
      "\u001b[1m 503/1018\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 4245433600.0000 - mae: 37741.2656Epoch 25/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 5289988096.0000 - mae: 20080.1445\n",
      "Epoch 23/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 4803860992.0000 - mae: 19589.8125\n",
      "Epoch 23/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 5228532224.0000 - mae: 20267.6484\n",
      "Epoch 24/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 6073858048.0000 - mae: 20237.5020\n",
      "Epoch 28/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 5109366272.0000 - mae: 38222.7109\n",
      "\u001b[1m 768/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5379452928.0000 - mae: 20263.8105Epoch 23/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 5024186368.0000 - mae: 20032.0488\n",
      "Epoch 25/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 6457399808.0000 - mae: 20056.2578\n",
      "Epoch 27/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 5655993856.0000 - mae: 20327.5312\n",
      "Epoch 26/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 4857914880.0000 - mae: 20031.9453\n",
      "\u001b[1m 912/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4676262400.0000 - mae: 19935.2578Epoch 24/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 4734200832.0000 - mae: 19971.5020\n",
      "Epoch 25/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 3674675456.0000 - mae: 19104.0898\n",
      "Epoch 28/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 5763426816.0000 - mae: 20179.4941\n",
      "Epoch 29/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 6355840000.0000 - mae: 20447.8242\n",
      "Epoch 27/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 4593852416.0000 - mae: 19419.0273\n",
      "Epoch 26/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 5915234304.0000 - mae: 20633.4590\n",
      "Epoch 24/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 6267195392.0000 - mae: 38823.7734\n",
      "Epoch 24/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 5426337792.0000 - mae: 20147.9277\n",
      "Epoch 25/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 4921634816.0000 - mae: 19946.6230\n",
      "Epoch 30/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 5047938048.0000 - mae: 19900.7480\n",
      "Epoch 29/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 4192451584.0000 - mae: 19585.3398\n",
      "Epoch 28/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 4511634944.0000 - mae: 19357.3477\n",
      "\u001b[1m   1/1018\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m38s\u001b[0m 37ms/step - loss: 5538935808.0000 - mae: 27263.9395Epoch 27/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4536476672.0000 - mae: 19654.8184\n",
      "Epoch 25/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 8046820864.0000 - mae: 21640.8906\n",
      "Epoch 26/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 4136559360.0000 - mae: 19581.1152\n",
      "Epoch 31/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 5177073664.0000 - mae: 20343.3770\n",
      "Epoch 29/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4586289152.0000 - mae: 19737.4219\n",
      "Epoch 32/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 5709648896.0000 - mae: 39420.3242\n",
      "Epoch 25/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 4257801984.0000 - mae: 19240.4219\n",
      "Epoch 26/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 5085779456.0000 - mae: 20292.9043\n",
      "Epoch 26/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 4776024576.0000 - mae: 19746.8359\n",
      "\u001b[1m 354/1018\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3969964288.0000 - mae: 19798.5469Epoch 27/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 4792412160.0000 - mae: 19617.0391\n",
      "Epoch 30/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 4264611840.0000 - mae: 19577.3398\n",
      "Epoch 30/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 4532805632.0000 - mae: 19624.8301\n",
      "Epoch 33/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 3760338944.0000 - mae: 19107.6973\n",
      "Epoch 28/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 5545617920.0000 - mae: 20751.0801\n",
      "Epoch 27/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 6212047872.0000 - mae: 39070.0430\n",
      "Epoch 26/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 4072010752.0000 - mae: 19063.8105\n",
      "Epoch 27/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 5728228864.0000 - mae: 20806.2480\n",
      "Epoch 28/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 4027760640.0000 - mae: 19294.6699\n",
      "Epoch 31/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 5226426368.0000 - mae: 20085.0176\n",
      "Epoch 29/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4125893376.0000 - mae: 19311.8184\n",
      "Epoch 34/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 6302580224.0000 - mae: 39165.8477\n",
      "Epoch 27/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 4437615104.0000 - mae: 20044.4277\n",
      "Epoch 29/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 6612710400.0000 - mae: 21045.4062\n",
      "Epoch 31/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 4343798272.0000 - mae: 19405.1797\n",
      "Epoch 28/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 3674582528.0000 - mae: 18892.6543\n",
      "Epoch 30/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 3847602432.0000 - mae: 19652.0488\n",
      "Epoch 35/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 4794353152.0000 - mae: 20403.8008\n",
      "Epoch 30/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 5676642816.0000 - mae: 20468.3398\n",
      "Epoch 28/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 6233102336.0000 - mae: 38730.0039 0\n",
      "Epoch 28/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 4050436608.0000 - mae: 19206.1602\n",
      "Epoch 32/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 5740376576.0000 - mae: 20156.7031\n",
      "Epoch 29/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 6163154432.0000 - mae: 20935.3145\n",
      "Epoch 31/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 7131406848.0000 - mae: 21026.9805\n",
      "Epoch 29/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 6609924608.0000 - mae: 38930.6445\n",
      "Epoch 29/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 4453836800.0000 - mae: 19832.3828\n",
      "Epoch 33/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 2940509184.0000 - mae: 18639.2676\n",
      "Epoch 31/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 5476003328.0000 - mae: 20304.3066\n",
      "Epoch 32/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 3947747328.0000 - mae: 19633.8711\n",
      "Epoch 30/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 5322500608.0000 - mae: 20210.1816\n",
      "Epoch 32/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 6633515520.0000 - mae: 20983.5312\n",
      "Epoch 36/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 4357108224.0000 - mae: 19362.8066\n",
      "Epoch 30/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 5465474048.0000 - mae: 38761.7188\n",
      "Epoch 30/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 5554401792.0000 - mae: 20922.7559\n",
      "\u001b[1m  33/1018\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 2054381824.0000 - mae: 20450.3320Epoch 32/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 5403439616.0000 - mae: 20654.4023\n",
      "Epoch 33/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 4541352960.0000 - mae: 20083.6777\n",
      "Epoch 31/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 5498021376.0000 - mae: 38419.1289\n",
      "Epoch 31/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 4922457088.0000 - mae: 20026.9609\n",
      "Epoch 31/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 5313995776.0000 - mae: 19830.2559\n",
      "Epoch 34/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 4410583552.0000 - mae: 19924.2441\n",
      "Epoch 33/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 4264087808.0000 - mae: 19496.4414\n",
      "Epoch 37/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 4290366720.0000 - mae: 19410.0020\n",
      "Epoch 33/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 5462005760.0000 - mae: 20265.1504\n",
      "Epoch 34/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 6426784256.0000 - mae: 38907.9492\n",
      "Epoch 32/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 4080062464.0000 - mae: 19882.4688\n",
      "Epoch 32/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 3305603328.0000 - mae: 18858.6738\n",
      "Epoch 32/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 5722671104.0000 - mae: 20175.2793\n",
      "Epoch 34/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 4527158272.0000 - mae: 20095.9746\n",
      "\u001b[1m 463/1018\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 6488227840.0000 - mae: 19971.8086Epoch 35/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 5443308032.0000 - mae: 38326.0391\n",
      "Epoch 33/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 5497934336.0000 - mae: 20375.7441\n",
      "Epoch 38/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 4104976896.0000 - mae: 19666.7930\n",
      "Epoch 34/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 5426699776.0000 - mae: 19712.4375\n",
      "Epoch 33/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 5035351552.0000 - mae: 20331.6582\n",
      "Epoch 33/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 6132996608.0000 - mae: 38924.4219\n",
      "Epoch 34/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 4403138560.0000 - mae: 19473.7363 \n",
      "Epoch 35/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 6799631360.0000 - mae: 20340.0449\n",
      "Epoch 34/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 3638770944.0000 - mae: 19160.1094\n",
      "Epoch 34/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 5310522880.0000 - mae: 20273.2129\n",
      "Epoch 36/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 6960472576.0000 - mae: 38721.4688\n",
      "Epoch 35/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 3387197952.0000 - mae: 19146.0801\n",
      "\u001b[1m 664/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3120346880.0000 - mae: 18581.3867Epoch 35/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 3157094656.0000 - mae: 18674.2578\n",
      "Epoch 36/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 4765002240.0000 - mae: 19942.8301\n",
      "Epoch 39/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 3333075200.0000 - mae: 18696.2559\n",
      "Epoch 35/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 3963594752.0000 - mae: 19375.5410\n",
      "Epoch 35/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 5833068032.0000 - mae: 38923.4609\n",
      "Epoch 36/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 4317607936.0000 - mae: 19630.3262\n",
      "Epoch 35/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 4999113216.0000 - mae: 20531.0234\n",
      "Epoch 37/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 4091386368.0000 - mae: 19229.8066\n",
      "Epoch 36/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 4508096000.0000 - mae: 19302.7754\n",
      "Epoch 37/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 4693029376.0000 - mae: 19914.3125\n",
      "Epoch 36/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 5366798848.0000 - mae: 19912.1836\n",
      "Epoch 40/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4049154816.0000 - mae: 19500.9414\n",
      "Epoch 36/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4334624256.0000 - mae: 19531.5840\n",
      "Epoch 36/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4208316160.0000 - mae: 19945.0000\n",
      "Epoch 38/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 5117569024.0000 - mae: 20135.7012\n",
      "\u001b[1m 978/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4631283200.0000 - mae: 19801.1055Epoch 38/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4651892736.0000 - mae: 19805.6270\n",
      "Epoch 37/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 5675646464.0000 - mae: 20171.9082\n",
      "Epoch 37/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 3961777920.0000 - mae: 19273.4004\n",
      "Epoch 41/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 5269824000.0000 - mae: 38698.1055\n",
      "Epoch 37/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 4482168832.0000 - mae: 19400.6602\n",
      "Epoch 37/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 4923818496.0000 - mae: 20287.0352\n",
      "\u001b[1m 978/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4611954176.0000 - mae: 19633.7559Epoch 39/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 4615906816.0000 - mae: 19640.8125\n",
      "Epoch 37/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 3814770176.0000 - mae: 19039.4238\n",
      "Epoch 39/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 4894953984.0000 - mae: 19839.7871\n",
      "Epoch 38/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 4843771392.0000 - mae: 19729.2539\n",
      "Epoch 42/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 4241320704.0000 - mae: 19573.2715\n",
      "Epoch 38/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 6255195136.0000 - mae: 39045.9609\n",
      "Epoch 38/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 3368561152.0000 - mae: 18672.3516\n",
      "Epoch 40/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 3829188608.0000 - mae: 19331.7363\n",
      "Epoch 38/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 5012981248.0000 - mae: 20240.8848\n",
      "Epoch 40/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 5097573888.0000 - mae: 19649.5215\n",
      "Epoch 39/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 7455169536.0000 - mae: 21146.3828\n",
      "Epoch 39/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 3880995840.0000 - mae: 19393.5000\n",
      "Epoch 38/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 3556222208.0000 - mae: 18596.4785\n",
      "Epoch 39/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 5062731776.0000 - mae: 19879.4844\n",
      "Epoch 41/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 4823360000.0000 - mae: 19791.0820\n",
      "Epoch 43/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 5585845248.0000 - mae: 20479.1113\n",
      "Epoch 40/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 4155411712.0000 - mae: 19579.3125\n",
      "Epoch 39/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 4652538368.0000 - mae: 19067.4746\n",
      "Epoch 40/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4655468544.0000 - mae: 19630.4824\n",
      "Epoch 40/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 5949703680.0000 - mae: 38687.9492\n",
      "Epoch 39/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4268712960.0000 - mae: 19801.0312\n",
      "Epoch 44/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 5655129600.0000 - mae: 20717.8398\n",
      "Epoch 41/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4475398656.0000 - mae: 19728.8301\n",
      "Epoch 41/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4302424064.0000 - mae: 19963.6914\n",
      "Epoch 41/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 3800562944.0000 - mae: 19125.8301\n",
      "Epoch 41/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 3809872896.0000 - mae: 18438.3125\n",
      "Epoch 42/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 5507607040.0000 - mae: 38610.4141\n",
      "\u001b[1m 827/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5388371456.0000 - mae: 19787.2129Epoch 40/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 4882892288.0000 - mae: 19883.2402\n",
      "Epoch 45/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 5347460096.0000 - mae: 19861.1797\n",
      "Epoch 42/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 6202554368.0000 - mae: 20328.6562\n",
      "\u001b[1m 335/1018\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 2445214208.0000 - mae: 18429.7363Epoch 42/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 4373089792.0000 - mae: 19576.6504\n",
      "Epoch 40/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 3311068416.0000 - mae: 18716.2715\n",
      "Epoch 42/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 5245485056.0000 - mae: 20172.2539\n",
      "Epoch 42/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 6490695168.0000 - mae: 38727.4883\n",
      "Epoch 41/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 4341550080.0000 - mae: 19322.0781\n",
      "Epoch 46/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 5612718080.0000 - mae: 20257.5059\n",
      "Epoch 43/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 4843681792.0000 - mae: 19892.7812\n",
      "Epoch 43/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 4952007168.0000 - mae: 20139.2266\n",
      "Epoch 41/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 4159317760.0000 - mae: 19495.2539\n",
      "Epoch 43/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 4645740032.0000 - mae: 20229.5391\n",
      "\u001b[1m 831/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6618873344.0000 - mae: 20803.8867Epoch 43/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4495179776.0000 - mae: 19349.4297\n",
      "Epoch 44/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4317054976.0000 - mae: 19302.6914\n",
      "\u001b[1m 405/1018\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7624133120.0000 - mae: 40086.5156Epoch 44/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 6316733440.0000 - mae: 20647.4199\n",
      "Epoch 47/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4149576192.0000 - mae: 19419.2637\n",
      "Epoch 42/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 5450759680.0000 - mae: 20669.6797\n",
      "Epoch 43/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 6524342784.0000 - mae: 39155.7539\n",
      "Epoch 42/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 3987982848.0000 - mae: 19147.9590\n",
      "Epoch 48/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 5992088576.0000 - mae: 20401.0645\n",
      "Epoch 45/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 5478553600.0000 - mae: 20368.6992\n",
      "Epoch 44/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 4880612352.0000 - mae: 19874.3125\n",
      "Epoch 45/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 4367996416.0000 - mae: 19707.4785\n",
      "Epoch 43/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 3760857088.0000 - mae: 18811.0996\n",
      "Epoch 44/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 4525233152.0000 - mae: 19317.8477\n",
      "\u001b[1m 553/1018\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3133339904.0000 - mae: 18566.2402Epoch 44/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 5335396864.0000 - mae: 38658.4219\n",
      "Epoch 43/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 5020051968.0000 - mae: 20441.9746\n",
      "Epoch 44/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 4218452224.0000 - mae: 19003.1973\n",
      "Epoch 49/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 5164659200.0000 - mae: 19528.7852\n",
      "Epoch 46/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 5910692864.0000 - mae: 20624.1484\n",
      "Epoch 45/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 3987630848.0000 - mae: 19200.8125\n",
      "Epoch 46/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 989us/step - loss: 4641144320.0000 - mae: 19899.8301\n",
      "Epoch 50/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 3293301504.0000 - mae: 18653.8086\n",
      "Epoch 45/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 4998764544.0000 - mae: 19787.9375\n",
      "Epoch 45/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 6840962048.0000 - mae: 20770.3066\n",
      "Epoch 45/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 3964303872.0000 - mae: 18796.5762\n",
      "Epoch 46/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4200418560.0000 - mae: 19360.7578\n",
      "Epoch 51/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 8050582016.0000 - mae: 39571.1094\n",
      "Epoch 44/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 4904518144.0000 - mae: 20046.4590\n",
      "Epoch 46/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 3526296832.0000 - mae: 18795.9219\n",
      "Epoch 47/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 3555960576.0000 - mae: 19180.2246\n",
      "Epoch 47/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 6216545792.0000 - mae: 20881.9062\n",
      "\u001b[1m 431/1018\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 6443378688.0000 - mae: 20995.1152Epoch 46/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 6302707712.0000 - mae: 20399.7637\n",
      "Epoch 46/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 4610360320.0000 - mae: 19815.1797\n",
      "Epoch 47/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 5568462848.0000 - mae: 38797.4531\n",
      "\u001b[1m 441/1018\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 8062251008.0000 - mae: 21765.0254Epoch 45/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 4160140288.0000 - mae: 19585.1992\n",
      "Epoch 52/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 5834059264.0000 - mae: 20443.7285\n",
      "Epoch 48/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 6540118528.0000 - mae: 20770.3008\n",
      "Epoch 48/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 7516312064.0000 - mae: 39769.5273\n",
      "Epoch 46/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 3590794240.0000 - mae: 19254.1211\n",
      "Epoch 48/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 3731308544.0000 - mae: 19079.2031\n",
      "Epoch 47/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4146068224.0000 - mae: 19577.5352\n",
      "Epoch 53/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 6727391232.0000 - mae: 20850.9570\n",
      "\u001b[1m 861/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4515368448.0000 - mae: 19431.8438Epoch 48/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 5475623424.0000 - mae: 20792.9824\n",
      "Epoch 49/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 4571062784.0000 - mae: 19455.4453\n",
      "Epoch 47/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 3675740416.0000 - mae: 19041.8750\n",
      "Epoch 49/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 4657035264.0000 - mae: 20377.8574\n",
      "\u001b[1m 729/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7727257088.0000 - mae: 39358.5312Epoch 47/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 7215364608.0000 - mae: 39183.3984\n",
      "Epoch 47/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 3910538752.0000 - mae: 19581.8223\n",
      "Epoch 54/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 5474861568.0000 - mae: 20268.6953\n",
      "Epoch 49/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 3814079232.0000 - mae: 19288.8887\n",
      "Epoch 49/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 3735885568.0000 - mae: 19438.1758\n",
      "Epoch 50/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 2899854080.0000 - mae: 18299.6680\n",
      "\u001b[1m  71/1018\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 1030073984.0000 - mae: 17463.9766Epoch 50/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 5349031424.0000 - mae: 20438.3125\n",
      "Epoch 48/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 3715495424.0000 - mae: 19396.1562\n",
      "Epoch 50/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 5640078848.0000 - mae: 38744.9102\n",
      "Epoch 48/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 4316590080.0000 - mae: 19411.4824\n",
      "Epoch 48/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 5267701760.0000 - mae: 19820.5781\n",
      "Epoch 50/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 5380392448.0000 - mae: 20042.6816\n",
      "Epoch 51/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 4198659072.0000 - mae: 19436.3887\n",
      "\u001b[1m 555/1018\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 7601993728.0000 - mae: 40025.9141Epoch 55/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 3306341120.0000 - mae: 18825.0488\n",
      "Epoch 51/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 4240636416.0000 - mae: 19598.7129\n",
      "Epoch 49/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 6960221184.0000 - mae: 39592.8047\n",
      "Epoch 49/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 4971375104.0000 - mae: 19814.0020\n",
      "Epoch 50/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 5952091648.0000 - mae: 19720.9805\n",
      "Epoch 52/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 4349753344.0000 - mae: 19719.5742\n",
      "\u001b[1m 274/1018\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 4735791104.0000 - mae: 38252.2812Epoch 51/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 4560247296.0000 - mae: 19523.0742\n",
      "\u001b[1m 673/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4286271488.0000 - mae: 19269.9141Epoch 52/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 5461991424.0000 - mae: 20245.9570\n",
      "Epoch 51/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 4826575360.0000 - mae: 38076.9766\n",
      "Epoch 50/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 4242675712.0000 - mae: 19246.1289\n",
      "\u001b[1m 111/1018\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 1541868288.0000 - mae: 16968.1152Epoch 49/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4357025792.0000 - mae: 19377.2812\n",
      "Epoch 53/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 3177483008.0000 - mae: 18982.8242\n",
      "Epoch 51/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 4317610496.0000 - mae: 19978.1445\n",
      "\u001b[1m 871/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4263153664.0000 - mae: 19763.2227Epoch 52/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 4369631232.0000 - mae: 19796.7637\n",
      "\u001b[1m 830/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4881470976.0000 - mae: 19895.3730Epoch 56/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 5880745984.0000 - mae: 38639.2266\n",
      "Epoch 51/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 4755776000.0000 - mae: 19791.8535\n",
      "Epoch 53/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 6159071232.0000 - mae: 20493.9414\n",
      "Epoch 54/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 3534634496.0000 - mae: 18881.9043\n",
      "Epoch 52/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4170793728.0000 - mae: 19252.6621\n",
      "Epoch 53/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 3392092672.0000 - mae: 19049.4707\n",
      "Epoch 54/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 5708131840.0000 - mae: 20673.5156\n",
      "Epoch 53/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 3629229568.0000 - mae: 19198.6465\n",
      "Epoch 50/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 6341262848.0000 - mae: 38949.9727\n",
      "Epoch 52/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 4967410688.0000 - mae: 19840.7559\n",
      "\u001b[1m   1/1018\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m29s\u001b[0m 29ms/step - loss: 1633835520.0000 - mae: 35141.4375Epoch 55/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 3458512640.0000 - mae: 19167.4043\n",
      "Epoch 52/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 6084247040.0000 - mae: 20710.2070\n",
      "\u001b[1m 613/1018\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 5078420480.0000 - mae: 19650.4023Epoch 57/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4959205888.0000 - mae: 19428.3750\n",
      "Epoch 55/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 4796598272.0000 - mae: 19596.9941\n",
      "\u001b[1m 489/1018\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6631912960.0000 - mae: 19760.0684Epoch 54/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 5225384448.0000 - mae: 20560.8887\n",
      "Epoch 58/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 5036338176.0000 - mae: 20150.8184\n",
      "Epoch 53/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 5480369152.0000 - mae: 19570.2500\n",
      "Epoch 56/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 6093267968.0000 - mae: 38785.2812\n",
      "Epoch 53/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 6827643904.0000 - mae: 20696.5645\n",
      "Epoch 56/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 3720742656.0000 - mae: 19190.0000\n",
      "Epoch 55/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 5482301440.0000 - mae: 19968.0508\n",
      "Epoch 54/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 3868783104.0000 - mae: 19472.55275\n",
      "Epoch 59/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4268877568.0000 - mae: 19307.1113\n",
      "\u001b[1m  19/1018\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 5459330048.0000 - mae: 41845.5859  Epoch 57/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 3350530560.0000 - mae: 18546.9785\n",
      "Epoch 51/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 3481508864.0000 - mae: 19203.6172\n",
      "Epoch 54/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 4477987840.0000 - mae: 19376.0332\n",
      "Epoch 57/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 3652536832.0000 - mae: 18915.0820\n",
      "Epoch 58/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 5854418432.0000 - mae: 20258.8770\n",
      "Epoch 55/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 6765299712.0000 - mae: 21241.7324\n",
      "Epoch 56/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4765871616.0000 - mae: 19853.5645\n",
      "Epoch 55/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 4764980736.0000 - mae: 20023.3770\n",
      "\u001b[1m 969/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6456970752.0000 - mae: 39510.6602Epoch 60/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 6436882432.0000 - mae: 39474.5898\n",
      "Epoch 54/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 5406175744.0000 - mae: 19769.4512\n",
      "Epoch 59/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 4619174912.0000 - mae: 19355.3652\n",
      "Epoch 52/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4525140480.0000 - mae: 38193.2461\n",
      "Epoch 55/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 6619091456.0000 - mae: 20760.8965\n",
      "Epoch 56/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 6063727616.0000 - mae: 20936.3340\n",
      "\u001b[1m 998/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5213193216.0000 - mae: 20240.8438Epoch 58/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 5203178496.0000 - mae: 20232.0469\n",
      "Epoch 61/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 3854694656.0000 - mae: 19301.0898\n",
      "Epoch 56/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4209755392.0000 - mae: 19462.2871\n",
      "Epoch 60/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 6454474240.0000 - mae: 38524.2891\n",
      "Epoch 56/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 5496542720.0000 - mae: 19888.2422\n",
      "Epoch 57/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 5158509568.0000 - mae: 38077.8672\n",
      "Epoch 57/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4838221312.0000 - mae: 19322.0000\n",
      "Epoch 59/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 3851761664.0000 - mae: 19672.8848\n",
      "Epoch 57/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 4389224960.0000 - mae: 19066.9785\n",
      "Epoch 53/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 4214842368.0000 - mae: 19592.6094\n",
      "Epoch 61/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 4941919744.0000 - mae: 19713.3750\n",
      "Epoch 57/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 5833606656.0000 - mae: 20312.3574\n",
      "\u001b[1m 580/1018\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 5158767616.0000 - mae: 38087.4844Epoch 60/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 4845273600.0000 - mae: 20498.3652\n",
      "Epoch 58/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 5705547264.0000 - mae: 20253.6777\n",
      "Epoch 62/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 3774104576.0000 - mae: 19605.1426\n",
      "Epoch 58/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 6496646144.0000 - mae: 20493.3906\n",
      "Epoch 54/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 5651565056.0000 - mae: 38368.7227\n",
      "Epoch 58/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 5053959680.0000 - mae: 20208.5820\n",
      "Epoch 63/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 5822511104.0000 - mae: 38568.0234\n",
      "Epoch 59/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 4215538176.0000 - mae: 19291.7207\n",
      "Epoch 61/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 5079627776.0000 - mae: 20289.9277\n",
      "Epoch 58/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 6012496384.0000 - mae: 20861.5430\n",
      "Epoch 59/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 3507195392.0000 - mae: 19257.1836\n",
      "Epoch 62/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 4370438656.0000 - mae: 19094.6758\n",
      "Epoch 59/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 4784752640.0000 - mae: 19887.3613\n",
      "Epoch 62/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 3658796800.0000 - mae: 19046.0664\n",
      "Epoch 64/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 4539987456.0000 - mae: 19623.3789\n",
      "Epoch 55/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 6359290368.0000 - mae: 38806.2578\n",
      "Epoch 60/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 8083591168.0000 - mae: 21784.0371\n",
      "Epoch 59/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 4591435776.0000 - mae: 19949.8125\n",
      "Epoch 60/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4619657728.0000 - mae: 19632.2500\n",
      "Epoch 60/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 5988635648.0000 - mae: 20041.1797\n",
      "Epoch 63/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4448167424.0000 - mae: 19677.8848\n",
      "Epoch 63/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 5925872640.0000 - mae: 38544.031290\n",
      "Epoch 61/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 7023458304.0000 - mae: 39178.5312\n",
      "Epoch 62/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 3234255616.0000 - mae: 18721.7754\n",
      "Epoch 64/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 5929039360.0000 - mae: 20082.7188\n",
      "Epoch 61/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 5775218688.0000 - mae: 20411.6133\n",
      "\u001b[1m 265/1018\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 6461157376.0000 - mae: 21056.7344Epoch 64/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 4320489472.0000 - mae: 19479.3145\n",
      "Epoch 65/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 3559029760.0000 - mae: 19183.8242\n",
      "Epoch 56/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 5882046464.0000 - mae: 20259.6133\n",
      "Epoch 60/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 6237688320.0000 - mae: 38362.2539\n",
      "Epoch 63/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 4820723200.0000 - mae: 20019.6191\n",
      "Epoch 65/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 6096499712.0000 - mae: 20798.7227\n",
      "Epoch 61/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 5338210304.0000 - mae: 20629.5215\n",
      "Epoch 62/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 4865363456.0000 - mae: 19823.5273\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 3650971136.0000 - mae: 19207.8789\n",
      "\u001b[1m 619/1018\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4441701888.0000 - mae: 19465.2031Epoch 57/300\n",
      "Epoch 66/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 4733400064.0000 - mae: 19666.3750\n",
      "Epoch 65/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 3795044608.0000 - mae: 19280.9238\n",
      "Epoch 61/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 6306629632.0000 - mae: 38316.9414\n",
      "Epoch 64/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4683597312.0000 - mae: 19492.3730\n",
      "Epoch 58/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 4848389632.0000 - mae: 19676.5137\n",
      "Epoch 62/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 4379630592.0000 - mae: 19464.8809\n",
      "Epoch 67/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 5844806656.0000 - mae: 38373.8359\n",
      "\u001b[1m 905/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3150248960.0000 - mae: 18526.1641Epoch 65/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 3262500352.0000 - mae: 18611.4062\n",
      "Epoch 66/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 3641058304.0000 - mae: 19208.4219\n",
      "Epoch 62/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 4974009856.0000 - mae: 19903.9414\n",
      "\u001b[1m 529/1018\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 7338370560.0000 - mae: 40106.5586Epoch 66/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 4239055104.0000 - mae: 19169.7812\n",
      "Epoch 59/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 4296519168.0000 - mae: 19547.6191\n",
      "\u001b[1m 391/1018\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 4603449344.0000 - mae: 20008.9590Epoch 63/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 5429012992.0000 - mae: 19935.6660\n",
      "Epoch 63/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 6979613184.0000 - mae: 39596.1523\n",
      "\u001b[1m 798/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4378678784.0000 - mae: 19675.8418Epoch 66/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 2976663040.0000 - mae: 19101.0000\n",
      "Epoch 67/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 4447561216.0000 - mae: 19683.4941\n",
      "Epoch 63/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 5241571328.0000 - mae: 19929.8438\n",
      "Epoch 68/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 5678932992.0000 - mae: 19998.1465\n",
      "\u001b[1m 992/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6848495616.0000 - mae: 20815.9766Epoch 60/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 6806156288.0000 - mae: 20794.5410\n",
      "Epoch 67/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 5103581696.0000 - mae: 20181.2891\n",
      "Epoch 64/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 6544962560.0000 - mae: 20616.0605\n",
      "Epoch 64/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 5477241856.0000 - mae: 19793.4531\n",
      "Epoch 64/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 3936153344.0000 - mae: 19362.9043\n",
      "Epoch 65/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4428428288.0000 - mae: 19680.2988\n",
      "Epoch 68/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 5863719936.0000 - mae: 20475.4434\n",
      "Epoch 65/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 5818919424.0000 - mae: 21065.6406\n",
      "Epoch 69/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 4214992384.0000 - mae: 19504.7051\n",
      "Epoch 68/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 5369449984.0000 - mae: 38605.7031\n",
      "\u001b[1m  49/1018\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 871280896.0000 - mae: 16167.7930Epoch 67/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 3676553984.0000 - mae: 19052.0508\n",
      "Epoch 65/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 5605267968.0000 - mae: 20384.6992\n",
      "Epoch 66/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 4554802688.0000 - mae: 19835.6367\n",
      "Epoch 69/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 4334741504.0000 - mae: 19268.9355\n",
      "Epoch 61/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 4152493824.0000 - mae: 19628.8730\n",
      "Epoch 66/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 3041358592.0000 - mae: 18502.2031\n",
      "\u001b[1m  46/1018\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 2971534336.0000 - mae: 35660.1094Epoch 69/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 3841501696.0000 - mae: 19237.4590\n",
      "Epoch 66/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 4525099008.0000 - mae: 19586.3496\n",
      "Epoch 62/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 5718387712.0000 - mae: 20245.6777\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5891670016.0000 - mae: 20553.4629Epoch 67/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 5891061248.0000 - mae: 20552.9004\n",
      "Epoch 70/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 4282666496.0000 - mae: 19262.8125\n",
      "Epoch 70/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 3895720448.0000 - mae: 18949.7539\n",
      "Epoch 67/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 7680411136.0000 - mae: 39172.3672\n",
      "Epoch 68/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4362394624.0000 - mae: 19798.0195\n",
      "Epoch 67/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 4366941184.0000 - mae: 19503.8477\n",
      "Epoch 70/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 670us/step - loss: 3362558720.0000 - mae: 18674.0215\n",
      "Epoch 68/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 712us/step - loss: 8241538048.0000 - mae: 39647.3633\n",
      "Epoch 69/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 5515394560.0000 - mae: 20270.0801\n",
      "Epoch 69/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 5460623872.0000 - mae: 38303.7148\n",
      "Epoch 70/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 5549706752.0000 - mae: 20091.0879\n",
      "Epoch 63/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 6406121472.0000 - mae: 20993.5547\n",
      "Epoch 68/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 5881809408.0000 - mae: 20798.6172\n",
      "Epoch 71/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 3854926336.0000 - mae: 19064.7734\n",
      "\u001b[1m 433/1018\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 2517030656.0000 - mae: 18453.8223Epoch 71/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 6616935424.0000 - mae: 20836.8457\n",
      "Epoch 68/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4449182208.0000 - mae: 19338.5840\n",
      "Epoch 64/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 5428964352.0000 - mae: 19495.8457\n",
      "Epoch 70/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 3391418368.0000 - mae: 18879.9395\n",
      "\u001b[1m 188/1018\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 1174001792.0000 - mae: 16870.9766Epoch 71/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 6962937344.0000 - mae: 39503.8203\n",
      "Epoch 71/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 5994903040.0000 - mae: 19996.4355\n",
      "Epoch 69/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 4434584064.0000 - mae: 20004.6562\n",
      "Epoch 72/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 3611229440.0000 - mae: 18772.7012\n",
      "Epoch 69/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 5608008192.0000 - mae: 38506.5273\n",
      "Epoch 72/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 5440800768.0000 - mae: 19688.0078\n",
      "Epoch 72/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 3934611456.0000 - mae: 19473.8359\n",
      "Epoch 65/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 5215767040.0000 - mae: 19757.8848\n",
      "Epoch 72/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4084251648.0000 - mae: 18893.0039\n",
      "Epoch 73/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 5194592768.0000 - mae: 20171.7227\n",
      "Epoch 71/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 5554330624.0000 - mae: 19801.8438\n",
      "Epoch 73/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 6777311232.0000 - mae: 20585.3398\n",
      "Epoch 70/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 5256121856.0000 - mae: 20156.2891\n",
      "Epoch 73/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 5913562624.0000 - mae: 38563.3164\n",
      "Epoch 73/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 5446031872.0000 - mae: 19980.5742\n",
      "\u001b[1m 989/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5131328512.0000 - mae: 20052.8496Epoch 74/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 5137295872.0000 - mae: 20055.1973\n",
      "Epoch 70/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 3838390528.0000 - mae: 19154.6855\n",
      "Epoch 72/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 4825455616.0000 - mae: 19287.5508\n",
      "Epoch 66/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 4696429568.0000 - mae: 19450.0137\n",
      "Epoch 74/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4598429184.0000 - mae: 19556.1621\n",
      "Epoch 74/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 4414941184.0000 - mae: 19694.9922\n",
      "Epoch 71/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 5251419136.0000 - mae: 38882.7188\n",
      "Epoch 74/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 5436486144.0000 - mae: 20213.0410\n",
      "Epoch 75/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 5107924992.0000 - mae: 19928.5781\n",
      "Epoch 71/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4028234496.0000 - mae: 19276.3555\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 5301475328.0000 - mae: 20711.8906\n",
      "Epoch 67/300\n",
      "Epoch 75/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 5358889472.0000 - mae: 20330.6836\n",
      "Epoch 73/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 4681986560.0000 - mae: 19874.6328\n",
      "Epoch 72/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 5070732288.0000 - mae: 19918.4785\n",
      "\u001b[1m 681/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 3238500352.0000 - mae: 19054.0137Epoch 76/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 3299711232.0000 - mae: 18780.2324\n",
      "Epoch 68/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 5533304832.0000 - mae: 19664.8945\n",
      "Epoch 76/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 6147090944.0000 - mae: 20238.4746\n",
      "Epoch 72/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 4317793280.0000 - mae: 19237.9355\n",
      "Epoch 74/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 3414001920.0000 - mae: 19066.6211\n",
      "Epoch 75/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 5276480512.0000 - mae: 38588.7227\n",
      "\u001b[1m 972/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2936529920.0000 - mae: 19080.2090Epoch 75/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 3007491072.0000 - mae: 19108.0840\n",
      "Epoch 73/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 4188117504.0000 - mae: 19137.5176  \n",
      "Epoch 75/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 4416865792.0000 - mae: 19133.7285\n",
      "Epoch 77/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 3857303552.0000 - mae: 19183.0430\n",
      "Epoch 73/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 4189263360.0000 - mae: 19728.9199\n",
      "Epoch 76/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 5541989376.0000 - mae: 19980.7324\n",
      "Epoch 78/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4932667392.0000 - mae: 20000.3184\n",
      "Epoch 74/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 3746617344.0000 - mae: 19418.8984\n",
      "Epoch 77/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 4497519104.0000 - mae: 19641.2422\n",
      "Epoch 69/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 5646604800.0000 - mae: 20457.0234\n",
      "Epoch 76/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 4523473408.0000 - mae: 37691.9297\n",
      "Epoch 76/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 3536111360.0000 - mae: 19164.2852\n",
      "Epoch 77/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 5662762496.0000 - mae: 20319.7773\n",
      "Epoch 79/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 4115392768.0000 - mae: 19950.5938\n",
      "Epoch 74/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 3262712832.0000 - mae: 18624.2324\n",
      "Epoch 75/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 4784974848.0000 - mae: 19402.8555\n",
      "Epoch 78/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4792348672.0000 - mae: 19275.5742\n",
      "Epoch 80/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 4527235072.0000 - mae: 19130.0820\n",
      "Epoch 70/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 5558858240.0000 - mae: 38776.5820\n",
      "Epoch 77/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 3785626368.0000 - mae: 19155.3730\n",
      "Epoch 77/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4894476288.0000 - mae: 19947.9941\n",
      "Epoch 79/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 5255697408.0000 - mae: 20171.0957\n",
      "Epoch 76/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4993947648.0000 - mae: 19885.5938\n",
      "Epoch 81/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 5551303680.0000 - mae: 20055.5723\n",
      "Epoch 78/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 6110492672.0000 - mae: 39067.8867\n",
      "Epoch 78/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 3333800448.0000 - mae: 19246.0586\n",
      "Epoch 75/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 4517787136.0000 - mae: 19334.2598\n",
      "Epoch 80/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 5113992192.0000 - mae: 19961.8105\n",
      "Epoch 82/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 5464432128.0000 - mae: 20490.7832\n",
      "Epoch 77/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 3754925312.0000 - mae: 19062.1035\n",
      "Epoch 78/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 5341232128.0000 - mae: 19943.9102\n",
      "Epoch 71/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 5043574784.0000 - mae: 19762.2500\n",
      "Epoch 79/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 3473153536.0000 - mae: 19150.5918\n",
      "Epoch 76/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 8233303040.0000 - mae: 39880.2070\n",
      "Epoch 79/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4845143040.0000 - mae: 19670.3594\n",
      "Epoch 78/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 5579536896.0000 - mae: 20498.5020\n",
      "Epoch 83/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 5856716288.0000 - mae: 20151.0742\n",
      "Epoch 79/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4371926528.0000 - mae: 19474.9863\n",
      "Epoch 77/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 7600457216.0000 - mae: 39314.3438\n",
      "Epoch 80/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 3200029440.0000 - mae: 18760.5977\n",
      "Epoch 81/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 6563020800.0000 - mae: 38781.8984\n",
      "Epoch 81/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 4217818624.0000 - mae: 19257.2090\n",
      "Epoch 79/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 3584582656.0000 - mae: 19125.5566\n",
      "Epoch 72/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 4015518720.0000 - mae: 19582.8164\n",
      "Epoch 80/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 5590098432.0000 - mae: 19385.2656\n",
      "Epoch 84/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 5010749952.0000 - mae: 20006.8047\n",
      "Epoch 78/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 3707560960.0000 - mae: 19247.8730\n",
      "Epoch 80/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 6404256256.0000 - mae: 38770.2148\n",
      "Epoch 82/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 4915667968.0000 - mae: 20234.8301\n",
      "Epoch 82/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4912045056.0000 - mae: 19933.6758\n",
      "Epoch 80/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 6665550336.0000 - mae: 20655.9102\n",
      "Epoch 85/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 7171618304.0000 - mae: 20933.5645\n",
      "Epoch 73/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4654464000.0000 - mae: 19622.9277\n",
      "Epoch 86/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 5786596864.0000 - mae: 20471.7324\n",
      "Epoch 81/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 5728673280.0000 - mae: 38593.3438\n",
      "Epoch 83/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 4394543616.0000 - mae: 19640.7266\n",
      "Epoch 79/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 3472617216.0000 - mae: 19010.3555\n",
      "Epoch 81/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 3545289472.0000 - mae: 18717.1484\n",
      "Epoch 74/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 3642626816.0000 - mae: 19280.6875\n",
      "Epoch 81/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 4004785408.0000 - mae: 19298.3184\n",
      "Epoch 83/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 6271367168.0000 - mae: 20588.3848\n",
      "Epoch 87/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4663385600.0000 - mae: 19518.5391\n",
      "\u001b[1m 996/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5354854912.0000 - mae: 20180.2031Epoch 80/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 5354188288.0000 - mae: 20178.6504\n",
      "Epoch 82/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 4793848832.0000 - mae: 19602.3398\n",
      "\u001b[1m 375/1018\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 6508628480.0000 - mae: 39277.5391Epoch 82/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 4513237504.0000 - mae: 19797.7969\n",
      "Epoch 82/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 4302508032.0000 - mae: 19721.7676\n",
      "Epoch 75/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 4669944320.0000 - mae: 19427.6055\n",
      "Epoch 81/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 5911249920.0000 - mae: 20158.9844\n",
      "Epoch 83/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 6378648064.0000 - mae: 39009.7305\n",
      "Epoch 84/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4313337344.0000 - mae: 19547.1270\n",
      "Epoch 82/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 4631244288.0000 - mae: 19555.9023\n",
      "Epoch 83/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 4273391616.0000 - mae: 19286.9160\n",
      "Epoch 83/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 3819524608.0000 - mae: 19007.2832\n",
      "\u001b[1m 545/1018\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 6110458368.0000 - mae: 39304.8008Epoch 76/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 5582717440.0000 - mae: 19980.4961\n",
      "Epoch 88/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 4114439680.0000 - mae: 19555.5332\n",
      "Epoch 84/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 6297880064.0000 - mae: 39225.0117\n",
      "Epoch 85/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 3448786944.0000 - mae: 19098.4707\n",
      "Epoch 83/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 3732755712.0000 - mae: 19134.7676\n",
      "Epoch 84/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 4707383296.0000 - mae: 19819.5723\n",
      "Epoch 84/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4975653376.0000 - mae: 19653.7188\n",
      "Epoch 77/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 4213783296.0000 - mae: 19354.5254\n",
      "Epoch 84/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 5102965760.0000 - mae: 20072.4082\n",
      "\u001b[1m 529/1018\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 5638167040.0000 - mae: 19873.4395Epoch 85/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 3947588096.0000 - mae: 19591.2188\n",
      "Epoch 84/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 6662455296.0000 - mae: 20681.1211\n",
      "Epoch 85/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 3491849728.0000 - mae: 18792.6484\n",
      "Epoch 78/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 5396358656.0000 - mae: 19904.4395\n",
      "Epoch 85/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 6487132672.0000 - mae: 38824.4258\n",
      "Epoch 86/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 4867236352.0000 - mae: 19742.3906\n",
      "Epoch 89/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 6189430784.0000 - mae: 38870.8750\n",
      "Epoch 87/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 5448756224.0000 - mae: 20226.0234\n",
      "Epoch 85/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 5406382592.0000 - mae: 20193.3750\n",
      "Epoch 86/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 4641845248.0000 - mae: 19426.3965\n",
      "Epoch 85/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 4614532096.0000 - mae: 19388.5625\n",
      "Epoch 86/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 5219415552.0000 - mae: 20271.0684\n",
      "Epoch 86/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 7266301440.0000 - mae: 39354.5430\n",
      "Epoch 88/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 4048392960.0000 - mae: 19474.5762\n",
      "Epoch 79/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4840848896.0000 - mae: 20113.5312\n",
      "Epoch 86/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 5079902208.0000 - mae: 19945.7383\n",
      "Epoch 90/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4725583360.0000 - mae: 19578.2988\n",
      "Epoch 87/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 5764236800.0000 - mae: 20249.9902\n",
      "Epoch 80/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4423420928.0000 - mae: 37934.0977\n",
      "Epoch 89/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 4800064512.0000 - mae: 19395.6660\n",
      "Epoch 86/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 6921966080.0000 - mae: 21264.6406\n",
      "Epoch 87/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 5330580480.0000 - mae: 20209.3555\n",
      "Epoch 91/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 4294980608.0000 - mae: 19497.3418\n",
      "Epoch 87/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 5737722368.0000 - mae: 20574.3555\n",
      "\u001b[1m 247/1018\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 2769563136.0000 - mae: 18549.1191Epoch 87/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 5461480448.0000 - mae: 19753.7344\n",
      "Epoch 87/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 4413452288.0000 - mae: 19424.4980\n",
      "\u001b[1m 543/1018\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 4109680384.0000 - mae: 19098.3574Epoch 88/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 5796356608.0000 - mae: 38644.3789\n",
      "\u001b[1m  90/1018\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 1669480192.0000 - mae: 18344.4473Epoch 90/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 3316187392.0000 - mae: 18824.3984\n",
      "Epoch 81/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4750317568.0000 - mae: 19571.6973\n",
      "Epoch 92/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 4674272256.0000 - mae: 19554.1562\n",
      "Epoch 88/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4545786368.0000 - mae: 19572.1191\n",
      "Epoch 82/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 3642900224.0000 - mae: 19211.5957\n",
      "\u001b[1m1007/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4355376128.0000 - mae: 19806.6914Epoch 88/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4359950848.0000 - mae: 19805.0137\n",
      "Epoch 88/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 3668871936.0000 - mae: 18768.1113\n",
      "Epoch 88/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 3925699328.0000 - mae: 19080.3867\n",
      "Epoch 89/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 4229323264.0000 - mae: 19032.5742\n",
      "Epoch 93/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 5188565504.0000 - mae: 38599.5508\n",
      "Epoch 91/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 4115595776.0000 - mae: 19245.1777\n",
      "Epoch 89/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 4498130432.0000 - mae: 19737.1797\n",
      "Epoch 89/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 5283371520.0000 - mae: 19918.5039\n",
      "Epoch 89/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 6221138432.0000 - mae: 20285.1035\n",
      "Epoch 83/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4462935552.0000 - mae: 19147.8652\n",
      "Epoch 89/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 7010998272.0000 - mae: 20889.7695\n",
      "Epoch 90/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 3224201472.0000 - mae: 19000.81054\n",
      "Epoch 90/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 3737613568.0000 - mae: 19177.2715\n",
      "Epoch 90/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 5256203776.0000 - mae: 19914.4141\n",
      "Epoch 94/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 4267439360.0000 - mae: 19522.8555\n",
      "Epoch 90/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 4885784576.0000 - mae: 19607.7520\n",
      "Epoch 90/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 7091695616.0000 - mae: 39339.0898\n",
      "Epoch 92/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 4137851392.0000 - mae: 19306.7969\n",
      "Epoch 91/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 5498632192.0000 - mae: 19960.3770\n",
      "Epoch 84/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 3273321984.0000 - mae: 19360.9531\n",
      "Epoch 91/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 4390703104.0000 - mae: 18998.8984\n",
      "Epoch 91/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 5406603776.0000 - mae: 19720.1309\n",
      "Epoch 95/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 4383114752.0000 - mae: 19602.1543\n",
      "Epoch 91/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 4661704192.0000 - mae: 19562.5781\n",
      "Epoch 91/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 5699652096.0000 - mae: 38552.9062\n",
      "\u001b[1m  26/1018\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 2046484864.0000 - mae: 19098.1934 Epoch 93/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 6331311616.0000 - mae: 20419.9590\n",
      "Epoch 85/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4866663936.0000 - mae: 19712.3184\n",
      "Epoch 92/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 4054465792.0000 - mae: 19304.5586\n",
      "Epoch 92/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 4266637056.0000 - mae: 19984.5430\n",
      "Epoch 92/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 4363172352.0000 - mae: 19678.7422\n",
      "Epoch 92/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 3128741888.0000 - mae: 18631.0000\n",
      "Epoch 92/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 7068883456.0000 - mae: 39195.3750\n",
      "Epoch 94/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 4239318528.0000 - mae: 18883.2676\n",
      "Epoch 96/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 4378002944.0000 - mae: 19227.4219\n",
      "Epoch 86/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 3919824640.0000 - mae: 19320.7734\n",
      "Epoch 93/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 4001745920.0000 - mae: 19069.9375\n",
      "Epoch 93/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 3029545728.0000 - mae: 18893.2188\n",
      "Epoch 93/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4067537920.0000 - mae: 19016.8496\n",
      "Epoch 93/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 5673505280.0000 - mae: 20052.6816\n",
      "Epoch 94/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4813603328.0000 - mae: 19092.9512\n",
      "Epoch 87/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 5949733376.0000 - mae: 20384.9512\n",
      "Epoch 97/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 5925603840.0000 - mae: 20429.9590\n",
      "Epoch 93/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 6663579648.0000 - mae: 38817.2500\n",
      "Epoch 95/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 5186057216.0000 - mae: 19699.2793\n",
      "Epoch 88/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 4544347136.0000 - mae: 19428.2617\n",
      "Epoch 94/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 5485114880.0000 - mae: 20254.5078\n",
      "Epoch 94/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 6843915264.0000 - mae: 20210.7207\n",
      "Epoch 95/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 5402640384.0000 - mae: 19934.8320\n",
      "\u001b[1m 196/1018\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 4344013312.0000 - mae: 18427.2207Epoch 98/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 4051356672.0000 - mae: 18848.2344\n",
      "\u001b[1m 255/1018\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 2616799232.0000 - mae: 17496.6387Epoch 94/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 5707589632.0000 - mae: 38915.4258\n",
      "Epoch 96/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 5771207680.0000 - mae: 20879.7871\n",
      "Epoch 94/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 4493423104.0000 - mae: 19425.5859\n",
      "Epoch 89/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 5335049728.0000 - mae: 20150.4473\n",
      "Epoch 95/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 3604801280.0000 - mae: 18661.4863\n",
      "Epoch 95/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 5264654848.0000 - mae: 19462.0332\n",
      "Epoch 96/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 5593210368.0000 - mae: 38344.4727\n",
      "Epoch 97/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 5324041728.0000 - mae: 20196.6543\n",
      "Epoch 99/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 3659171584.0000 - mae: 18945.2598\n",
      "Epoch 95/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 3833745664.0000 - mae: 19111.1621\n",
      "Epoch 95/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 5225599488.0000 - mae: 19853.4180\n",
      "Epoch 90/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 5130572800.0000 - mae: 19719.4883\n",
      "Epoch 96/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 4955656192.0000 - mae: 19318.9238\n",
      "Epoch 96/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 4432199168.0000 - mae: 19650.5078\n",
      "Epoch 96/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 4150961664.0000 - mae: 19200.3652\n",
      "Epoch 97/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 6304633344.0000 - mae: 20737.2402\n",
      "Epoch 96/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 4955832320.0000 - mae: 20059.1094\n",
      "Epoch 91/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 6978437120.0000 - mae: 20766.3945\n",
      "Epoch 97/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 4873994752.0000 - mae: 19756.5273\n",
      "\u001b[1m 780/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3717460992.0000 - mae: 18897.1953Epoch 100/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 3967809792.0000 - mae: 19083.8828\n",
      "Epoch 97/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 5761886720.0000 - mae: 20066.8516\n",
      "Epoch 97/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 7896227328.0000 - mae: 39290.0000\n",
      "Epoch 98/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 4994572288.0000 - mae: 19451.0059\n",
      "Epoch 98/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4665199616.0000 - mae: 19875.7949\n",
      "Epoch 92/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 5888796672.0000 - mae: 20951.6152\n",
      "Epoch 98/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 3893376000.0000 - mae: 18889.7383\n",
      "Epoch 97/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 5601252352.0000 - mae: 38471.0586\n",
      "Epoch 99/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 3661215488.0000 - mae: 18927.2500\n",
      "Epoch 99/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4939593216.0000 - mae: 19598.1152\n",
      "Epoch 93/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 5557878784.0000 - mae: 20061.0352\n",
      "Epoch 99/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 4780140544.0000 - mae: 20021.1348\n",
      "Epoch 101/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 5913783808.0000 - mae: 20167.9336\n",
      "Epoch 98/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 6393892864.0000 - mae: 20669.6777\n",
      "Epoch 98/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 3191787520.0000 - mae: 18500.7676\n",
      "Epoch 94/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 4528898048.0000 - mae: 19950.0996\n",
      "Epoch 98/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 5651825664.0000 - mae: 38281.8203\n",
      "Epoch 100/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 5871294976.0000 - mae: 20765.3418\n",
      "Epoch 100/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 3533362688.0000 - mae: 19428.8613\n",
      "Epoch 100/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 5094381568.0000 - mae: 19832.9805\n",
      "Epoch 102/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 5328632320.0000 - mae: 20004.6074\n",
      "Epoch 99/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 3849258752.0000 - mae: 18910.6914\n",
      "Epoch 99/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 5150965760.0000 - mae: 19688.2969\n",
      "Epoch 95/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 4098019072.0000 - mae: 19591.4668\n",
      "Epoch 101/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 6421510144.0000 - mae: 20658.5664\n",
      "Epoch 101/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 5603895808.0000 - mae: 38599.6445\n",
      "Epoch 101/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 6434496512.0000 - mae: 20374.9766\n",
      "Epoch 99/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 3902059520.0000 - mae: 18800.5391\n",
      "Epoch 100/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 2849054208.0000 - mae: 18987.4414\n",
      "Epoch 100/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 3488359680.0000 - mae: 18711.9316\n",
      "Epoch 102/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 4224296448.0000 - mae: 19614.0039\n",
      "Epoch 103/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 5669429248.0000 - mae: 20327.7969\n",
      "Epoch 102/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 5317227520.0000 - mae: 19653.5762\n",
      "Epoch 101/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 4686492160.0000 - mae: 19474.5859\n",
      "Epoch 101/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 3180370688.0000 - mae: 18736.0469\n",
      "Epoch 103/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 4130367488.0000 - mae: 19518.1289\n",
      "Epoch 96/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 3919536896.0000 - mae: 19342.7012\n",
      "Epoch 100/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 4879058432.0000 - mae: 38171.4648\n",
      "Epoch 102/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 5723801088.0000 - mae: 20246.2461\n",
      "Epoch 102/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 5086917120.0000 - mae: 19975.5234\n",
      "Epoch 104/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 901us/step - loss: 3846210560.0000 - mae: 19217.8262\n",
      "Epoch 101/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 7293133312.0000 - mae: 39013.7422\n",
      "\u001b[1m 982/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4490423808.0000 - mae: 19431.1426Epoch 103/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 4470940672.0000 - mae: 19419.1680\n",
      "\u001b[1m   1/1018\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m49s\u001b[0m 49ms/step - loss: 18980835328.0000 - mae: 55813.5938Epoch 104/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 4906376704.0000 - mae: 20021.6523\n",
      "Epoch 103/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 3746338816.0000 - mae: 19003.9199\n",
      "Epoch 103/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 6016016384.0000 - mae: 20475.9004\n",
      "Epoch 102/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 3734530304.0000 - mae: 19091.4141\n",
      "Epoch 102/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 4774829056.0000 - mae: 20033.7812\n",
      "Epoch 105/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 5901599232.0000 - mae: 38525.8047\n",
      "Epoch 104/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 4934972928.0000 - mae: 20011.2793\n",
      "Epoch 105/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 3425395200.0000 - mae: 18572.7480\n",
      "Epoch 97/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 5111657984.0000 - mae: 19715.6777\n",
      "Epoch 104/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 3544594944.0000 - mae: 19162.1523\n",
      "Epoch 103/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 5096765440.0000 - mae: 19567.9512\n",
      "Epoch 103/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 5954571264.0000 - mae: 20203.9512\n",
      "Epoch 106/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 5005494784.0000 - mae: 38481.8438\n",
      "Epoch 105/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4007105536.0000 - mae: 18907.0273\n",
      "Epoch 98/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 4696155648.0000 - mae: 19832.5391\n",
      "Epoch 104/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 4956520448.0000 - mae: 19810.1699\n",
      "Epoch 105/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 5281674240.0000 - mae: 19777.0156\n",
      "Epoch 104/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 5739709440.0000 - mae: 20542.9922\n",
      "Epoch 107/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 3359420672.0000 - mae: 18315.5195\n",
      "Epoch 106/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 4245586944.0000 - mae: 19954.1250\n",
      "Epoch 104/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 3950473984.0000 - mae: 19388.7617\n",
      "Epoch 99/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 4762768384.0000 - mae: 19805.0840\n",
      "Epoch 108/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 3475386624.0000 - mae: 19240.3848\n",
      "Epoch 105/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 3820666624.0000 - mae: 19015.1621\n",
      "Epoch 105/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 3100935680.0000 - mae: 18786.1543\n",
      "Epoch 107/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 6816245760.0000 - mae: 39004.2070\n",
      "Epoch 106/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 4490936320.0000 - mae: 19718.0449\n",
      "Epoch 105/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 5678086656.0000 - mae: 19906.3398\n",
      "Epoch 109/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 4362215424.0000 - mae: 20098.2148\n",
      "Epoch 106/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 4395057152.0000 - mae: 19916.6230\n",
      "Epoch 108/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 4502947840.0000 - mae: 19675.2734\n",
      "\u001b[1m 871/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4783861248.0000 - mae: 19296.2930Epoch 106/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 6637335552.0000 - mae: 39145.1250\n",
      "Epoch 107/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 3922964992.0000 - mae: 19509.5938\n",
      "Epoch 106/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 4687535104.0000 - mae: 19283.6152\n",
      "Epoch 100/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 5136822784.0000 - mae: 20138.5371\n",
      "Epoch 106/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 4700947456.0000 - mae: 20120.2637\n",
      "Epoch 110/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 5818627584.0000 - mae: 20159.4629\n",
      "Epoch 107/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 5255753216.0000 - mae: 20293.5469\n",
      "Epoch 101/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 4182312448.0000 - mae: 19240.841873\n",
      "Epoch 107/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4762797056.0000 - mae: 20096.2578\n",
      "Epoch 107/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 4925296128.0000 - mae: 19766.5566\n",
      "Epoch 102/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 3932561664.0000 - mae: 19444.4258\n",
      "Epoch 108/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 5436119040.0000 - mae: 20038.8652\n",
      "Epoch 108/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 5471013376.0000 - mae: 20593.1875\n",
      "Epoch 107/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 4351420928.0000 - mae: 19073.3633\n",
      "Epoch 109/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 6906831872.0000 - mae: 39101.2461\n",
      "\u001b[1m 192/1018\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 2263346432.0000 - mae: 18328.4629Epoch 108/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 5481853952.0000 - mae: 20217.3223\n",
      "Epoch 108/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 5213336576.0000 - mae: 20092.2559\n",
      "Epoch 111/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 3602014720.0000 - mae: 19334.1309\n",
      "Epoch 109/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 4865912832.0000 - mae: 19229.2988\n",
      "Epoch 103/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 6127046656.0000 - mae: 20835.5664\n",
      "\u001b[1m  52/1018\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 1352337408.0000 - mae: 17198.7695Epoch 109/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 4248362752.0000 - mae: 19272.7480\n",
      "Epoch 108/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 7018315776.0000 - mae: 39499.5469\n",
      "\u001b[1m 243/1018\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 3020571392.0000 - mae: 18813.2812Epoch 109/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 5230056448.0000 - mae: 19993.3906\n",
      "Epoch 112/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 6235474432.0000 - mae: 20560.2793\n",
      "Epoch 109/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4172311040.0000 - mae: 19258.4922\n",
      "Epoch 104/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 4091319552.0000 - mae: 19155.3438\n",
      "Epoch 110/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 2983805952.0000 - mae: 18912.1699\n",
      "Epoch 113/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 4360815616.0000 - mae: 19397.5762\n",
      "Epoch 110/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 6447219712.0000 - mae: 38866.7539\n",
      "Epoch 110/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 5918771712.0000 - mae: 20281.8086\n",
      "Epoch 111/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 4035709440.0000 - mae: 18780.9160\n",
      "Epoch 111/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 4610988032.0000 - mae: 19656.9121\n",
      "Epoch 110/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 4191792384.0000 - mae: 18951.2070\n",
      "Epoch 109/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 6181240832.0000 - mae: 20661.3066\n",
      "Epoch 114/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 5102202368.0000 - mae: 19907.4512\n",
      "Epoch 105/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 5429601280.0000 - mae: 20130.2676\n",
      "Epoch 112/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 5491525120.0000 - mae: 20670.4785\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 5234776576.0000 - mae: 38609.0078\n",
      "Epoch 110/300\n",
      "Epoch 111/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 4502589440.0000 - mae: 19376.9414\n",
      "Epoch 112/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4392104448.0000 - mae: 19435.7129\n",
      "Epoch 113/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 5539630080.0000 - mae: 20067.3320\n",
      "Epoch 111/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 4239421440.0000 - mae: 19463.6523\n",
      "Epoch 111/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 4110837248.0000 - mae: 19384.1035\n",
      "Epoch 115/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 5685880832.0000 - mae: 38924.0430\n",
      "Epoch 112/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 4628169728.0000 - mae: 19599.1934\n",
      "Epoch 110/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 4829530112.0000 - mae: 19658.3398\n",
      "Epoch 106/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 5230138880.0000 - mae: 19875.1367\n",
      "Epoch 112/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4090482944.0000 - mae: 19143.1133\n",
      "\u001b[1m 641/1018\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3513001728.0000 - mae: 18622.9023Epoch 112/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 3755595008.0000 - mae: 18847.7559\n",
      "Epoch 114/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 3594874880.0000 - mae: 19069.3945\n",
      "Epoch 113/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4512816640.0000 - mae: 19361.5566\n",
      "Epoch 107/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 4252836352.0000 - mae: 19272.6777\n",
      "\u001b[1m 294/1018\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 5115094016.0000 - mae: 38499.5781Epoch 111/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 5047563264.0000 - mae: 20157.0938\n",
      "Epoch 113/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 5750060032.0000 - mae: 20248.9824\n",
      "Epoch 116/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 4184368384.0000 - mae: 19581.3184\n",
      "Epoch 113/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 6210079744.0000 - mae: 20107.8496\n",
      "Epoch 115/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 5287854592.0000 - mae: 38602.7734\n",
      "\u001b[1m  14/1018\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 8561211392.0000 - mae: 21870.1504  Epoch 113/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 4368928768.0000 - mae: 19956.4961\n",
      "Epoch 112/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 3992282880.0000 - mae: 19247.2656\n",
      "Epoch 108/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 3672526848.0000 - mae: 18885.0430\n",
      "Epoch 114/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 4479340032.0000 - mae: 19565.8477\n",
      "Epoch 117/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 6622212096.0000 - mae: 20922.5391\n",
      "Epoch 114/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 3228444416.0000 - mae: 18346.8125\n",
      "Epoch 116/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 4033818368.0000 - mae: 19540.1582\n",
      "Epoch 114/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 6075650048.0000 - mae: 19907.9688\n",
      "Epoch 113/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 5114885632.0000 - mae: 20575.5371\n",
      "Epoch 115/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 4782562816.0000 - mae: 19634.0469\n",
      "\u001b[1m 899/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5433095168.0000 - mae: 19978.0762Epoch 109/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 5278712320.0000 - mae: 19880.3535\n",
      "Epoch 117/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 5027088896.0000 - mae: 20019.6836\n",
      "Epoch 114/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 4029832960.0000 - mae: 19662.3613\n",
      "Epoch 115/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 6529018880.0000 - mae: 39085.0273\n",
      "Epoch 114/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 4359538688.0000 - mae: 19381.7715\n",
      "Epoch 116/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 5864898560.0000 - mae: 19951.2168\n",
      "Epoch 110/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 5674750976.0000 - mae: 20175.9727\n",
      "Epoch 115/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 5364198400.0000 - mae: 20073.7676\n",
      "Epoch 118/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 5894568960.0000 - mae: 20094.8262\n",
      "Epoch 118/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4322350592.0000 - mae: 19430.0820\n",
      "\u001b[1m 170/1018\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 896us/step - loss: 3736334336.0000 - mae: 18476.4414Epoch 115/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4497544192.0000 - mae: 19661.3809\n",
      "Epoch 117/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 4428438528.0000 - mae: 19090.8301\n",
      "Epoch 119/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 5091475968.0000 - mae: 19477.7734\n",
      "Epoch 119/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 4620826624.0000 - mae: 19660.1660\n",
      "Epoch 116/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 6029677568.0000 - mae: 38888.03127\n",
      "Epoch 115/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4365172224.0000 - mae: 19394.1348\n",
      "Epoch 116/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 3180687872.0000 - mae: 18730.0469\n",
      "\u001b[1m 596/1018\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 5072766976.0000 - mae: 19691.3398Epoch 120/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 4583393280.0000 - mae: 19525.6289\n",
      "Epoch 117/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 5063589888.0000 - mae: 19748.6660\n",
      "Epoch 118/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 5581080064.0000 - mae: 20060.7051\n",
      "Epoch 120/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 5884533248.0000 - mae: 20197.7070\n",
      "Epoch 116/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 7112610304.0000 - mae: 20614.1191\n",
      "\u001b[1m 761/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4899534336.0000 - mae: 19821.1719Epoch 111/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 6334204928.0000 - mae: 38984.1680\n",
      "Epoch 116/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 4898720768.0000 - mae: 19821.5195\n",
      "Epoch 117/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 4792545280.0000 - mae: 19414.3398\n",
      "Epoch 121/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 6322722816.0000 - mae: 39019.3594\n",
      "Epoch 117/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 4630723584.0000 - mae: 19599.2715\n",
      "Epoch 118/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 3114475264.0000 - mae: 18515.5898\n",
      "Epoch 119/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 4348878848.0000 - mae: 19073.3223\n",
      "Epoch 112/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 6192479744.0000 - mae: 20832.2441\n",
      "Epoch 118/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 3866084096.0000 - mae: 19477.2559\n",
      "Epoch 122/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 4465931776.0000 - mae: 19764.6992\n",
      "Epoch 117/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 5684234752.0000 - mae: 20037.3281\n",
      "\u001b[1m 367/1018\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 4837877248.0000 - mae: 19331.1465Epoch 121/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 6128408576.0000 - mae: 38869.3359\n",
      "Epoch 118/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4343814656.0000 - mae: 19212.7969\n",
      "\u001b[1m 523/1018\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 4021667584.0000 - mae: 19194.4277Epoch 113/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 4778110464.0000 - mae: 19488.3301\n",
      "Epoch 119/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 2996501248.0000 - mae: 18662.6777\n",
      "\u001b[1m 734/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4521261568.0000 - mae: 19497.4551Epoch 123/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 4318881280.0000 - mae: 19190.9512\n",
      "Epoch 122/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 4838432256.0000 - mae: 19753.4199\n",
      "Epoch 118/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4202395904.0000 - mae: 19206.8125\n",
      "Epoch 114/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 4820284928.0000 - mae: 19764.2773\n",
      "Epoch 120/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 6200128512.0000 - mae: 38705.3086\n",
      "Epoch 119/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 5004469760.0000 - mae: 19687.5879\n",
      "Epoch 124/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 5980034048.0000 - mae: 20245.8066\n",
      "Epoch 119/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 4673741312.0000 - mae: 19643.7500\n",
      "Epoch 123/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 4849227776.0000 - mae: 19545.5293\n",
      "Epoch 119/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4825755648.0000 - mae: 19445.5234\n",
      "Epoch 115/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 6289011712.0000 - mae: 38835.3359\n",
      "Epoch 120/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 4162545920.0000 - mae: 19184.7109\n",
      "\u001b[1m 684/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3701178112.0000 - mae: 18672.9102Epoch 120/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 974us/step - loss: 3832074240.0000 - mae: 18859.3398\n",
      "Epoch 121/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 3893906944.0000 - mae: 18904.9238\n",
      "Epoch 125/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4927928320.0000 - mae: 20316.5684\n",
      "Epoch 120/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 3837306880.0000 - mae: 18994.8574\n",
      "Epoch 116/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 4674053120.0000 - mae: 19883.3164\n",
      "Epoch 122/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 6410119680.0000 - mae: 38795.4883\n",
      "Epoch 121/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 6633137664.0000 - mae: 20847.9688\n",
      "Epoch 121/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 4766316032.0000 - mae: 19357.3750\n",
      "Epoch 120/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 4616514048.0000 - mae: 20030.8027\n",
      "\u001b[1m 970/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3617157120.0000 - mae: 19023.4336Epoch 124/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 3641784320.0000 - mae: 19029.5996\n",
      "Epoch 126/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 3963968768.0000 - mae: 19654.7363\n",
      "Epoch 121/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 7675608576.0000 - mae: 39557.3203\n",
      "Epoch 122/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 6052402688.0000 - mae: 20700.7227\n",
      "Epoch 123/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 5501879296.0000 - mae: 20202.0137\n",
      "Epoch 122/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 3735597312.0000 - mae: 18803.0820\n",
      "Epoch 117/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 4569100288.0000 - mae: 19628.9238\n",
      "Epoch 125/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 3535968512.0000 - mae: 18814.2266\n",
      "Epoch 122/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 5842061824.0000 - mae: 38319.1875\n",
      "Epoch 123/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 3788478464.0000 - mae: 19230.5742\n",
      "Epoch 124/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 4734283776.0000 - mae: 19220.6250\n",
      "Epoch 127/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 5150464512.0000 - mae: 19941.7988\n",
      "Epoch 121/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 5567576064.0000 - mae: 19863.5254\n",
      "Epoch 123/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 3827900672.0000 - mae: 19008.5039\n",
      "Epoch 118/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 4225293568.0000 - mae: 19224.2285\n",
      "Epoch 126/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 4966791680.0000 - mae: 20091.6895\n",
      "Epoch 123/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 5991982592.0000 - mae: 20531.7285\n",
      "Epoch 127/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 5004822528.0000 - mae: 19932.0801\n",
      "Epoch 119/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 5680971776.0000 - mae: 38529.5859\n",
      "Epoch 124/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 4638965760.0000 - mae: 19657.3301\n",
      "Epoch 122/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 4503015936.0000 - mae: 18952.6035\n",
      "Epoch 128/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 5525906944.0000 - mae: 20144.2285\n",
      "\u001b[1m  24/1018\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 42115579904.0000 - mae: 30716.0176     Epoch 125/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4529552896.0000 - mae: 19710.9062\n",
      "Epoch 124/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 4517732352.0000 - mae: 20005.7070\n",
      "\u001b[1m 661/1018\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7568967168.0000 - mae: 20626.4141Epoch 124/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 6454162432.0000 - mae: 20188.3516\n",
      "Epoch 129/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 6142043648.0000 - mae: 38743.0117\n",
      "Epoch 125/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 5489296384.0000 - mae: 19880.1230\n",
      "Epoch 125/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 3957646592.0000 - mae: 19081.8770\n",
      "Epoch 126/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 3349126656.0000 - mae: 18371.9766\n",
      "Epoch 130/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 4841481216.0000 - mae: 19711.4277\n",
      "Epoch 125/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 5625898496.0000 - mae: 38610.2031\n",
      "Epoch 126/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 5684650496.0000 - mae: 20839.9727\n",
      "Epoch 123/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 4396430848.0000 - mae: 19142.6699\n",
      "Epoch 120/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 6050436608.0000 - mae: 20043.8164\n",
      "Epoch 128/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 3702649600.0000 - mae: 19526.4980\n",
      "Epoch 127/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 6392174080.0000 - mae: 20135.2715\n",
      "Epoch 126/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 3920509952.0000 - mae: 18927.9844\n",
      "Epoch 131/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4493551616.0000 - mae: 19858.0645\n",
      "Epoch 128/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 3646965504.0000 - mae: 18713.1953\n",
      "Epoch 132/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 6310466560.0000 - mae: 20622.8594\n",
      "Epoch 129/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 4533826048.0000 - mae: 19348.5742\n",
      "Epoch 121/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 4634043904.0000 - mae: 19452.4434\n",
      "Epoch 126/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 4092435456.0000 - mae: 19252.5059\n",
      "Epoch 127/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 5635186176.0000 - mae: 19659.2852\n",
      "\u001b[1m 678/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5512236544.0000 - mae: 19805.9219Epoch 124/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4856222720.0000 - mae: 20157.3535\n",
      "Epoch 129/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 5849816576.0000 - mae: 38458.8203\n",
      "\u001b[1m 266/1018\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3016388608.0000 - mae: 18958.7012Epoch 127/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 5097357824.0000 - mae: 19666.1230\n",
      "Epoch 133/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 5352881152.0000 - mae: 20240.6836\n",
      "Epoch 127/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 3695462144.0000 - mae: 19221.8301\n",
      "Epoch 130/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 5220684288.0000 - mae: 20352.4141\n",
      "Epoch 125/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 4481492992.0000 - mae: 19537.0684\n",
      "Epoch 128/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 4531950592.0000 - mae: 19489.2363\n",
      "Epoch 134/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 6700574720.0000 - mae: 39028.7695\n",
      "\u001b[1m 736/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5465259008.0000 - mae: 20916.4551Epoch 128/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 4933390336.0000 - mae: 19741.5098\n",
      "Epoch 130/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 3781081344.0000 - mae: 19215.5781\n",
      "\u001b[1m 157/1018\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 6472455168.0000 - mae: 39372.3477Epoch 122/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 5304224256.0000 - mae: 20656.7051\n",
      "Epoch 128/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 4395138048.0000 - mae: 19683.3574\n",
      "Epoch 131/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 4873554944.0000 - mae: 20243.9727\n",
      "Epoch 126/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 4392704512.0000 - mae: 18851.4258\n",
      "Epoch 135/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 6960268800.0000 - mae: 21070.6133\n",
      "Epoch 129/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 6807723520.0000 - mae: 20549.0957\n",
      "Epoch 131/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 5716232704.0000 - mae: 38596.3906\n",
      "Epoch 129/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 5174444544.0000 - mae: 19862.8613\n",
      "Epoch 123/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 5318915584.0000 - mae: 19961.9863\n",
      "Epoch 129/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4361647616.0000 - mae: 19485.3340\n",
      "Epoch 130/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4601042944.0000 - mae: 19856.7500\n",
      "Epoch 127/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 3890722560.0000 - mae: 19170.7148\n",
      "Epoch 136/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 5276976128.0000 - mae: 20068.0957\n",
      "Epoch 132/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 3673253120.0000 - mae: 19275.1406\n",
      "Epoch 132/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 5959282688.0000 - mae: 20323.1641\n",
      "Epoch 131/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 4315357184.0000 - mae: 19582.6875\n",
      "Epoch 130/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 3996368640.0000 - mae: 19642.9922\n",
      "Epoch 128/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4953202176.0000 - mae: 19960.3418\n",
      "Epoch 133/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 5691909632.0000 - mae: 38506.1250\n",
      "\u001b[1m 155/1018\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4037567232.0000 - mae: 20480.9512Epoch 130/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 3611559936.0000 - mae: 18637.7500\n",
      "Epoch 124/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 3677775104.0000 - mae: 19121.6074\n",
      "Epoch 133/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4673941504.0000 - mae: 20023.0215\n",
      "Epoch 129/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 5460143616.0000 - mae: 20190.6914\n",
      "Epoch 132/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 5410252800.0000 - mae: 20089.4316\n",
      "Epoch 134/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 4472881664.0000 - mae: 19397.2754\n",
      "Epoch 137/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4128920832.0000 - mae: 19086.0938\n",
      "Epoch 133/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 4441779200.0000 - mae: 19891.5859\n",
      "Epoch 134/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 4066447104.0000 - mae: 18995.2969\n",
      "\u001b[1m   1/1018\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m57s\u001b[0m 56ms/step - loss: 459609024.0000 - mae: 16675.3301Epoch 131/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 3976345088.0000 - mae: 19680.1406\n",
      "Epoch 130/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 5194735104.0000 - mae: 19661.3047\n",
      "Epoch 135/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 5932023808.0000 - mae: 38799.4844\n",
      "Epoch 131/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 5352902656.0000 - mae: 20211.2012\n",
      "Epoch 125/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 3375836416.0000 - mae: 18529.4531\n",
      "Epoch 138/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 5826144768.0000 - mae: 19839.4766\n",
      "Epoch 134/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 3919917312.0000 - mae: 19275.0879\n",
      "\u001b[1m 121/1018\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 2338810368.0000 - mae: 17421.9980Epoch 135/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 6224165376.0000 - mae: 20426.3398\n",
      "Epoch 136/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 6897161728.0000 - mae: 38835.3828\n",
      "Epoch 132/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 6022106624.0000 - mae: 19921.5742\n",
      "Epoch 126/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 5057857536.0000 - mae: 19514.7559\n",
      "\u001b[1m 765/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4488909824.0000 - mae: 19035.0977Epoch 139/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4655796736.0000 - mae: 19199.1191\n",
      "Epoch 137/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 4297290240.0000 - mae: 19073.8809\n",
      "Epoch 131/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 5624942592.0000 - mae: 19967.6367\n",
      "\u001b[1m   1/1018\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m50s\u001b[0m 50ms/step - loss: 6214444032.0000 - mae: 30311.0039Epoch 132/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 4541733376.0000 - mae: 19422.4727\n",
      "\u001b[1m 173/1018\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 7525427200.0000 - mae: 20766.8086Epoch 136/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 5120624128.0000 - mae: 20066.5391\n",
      "Epoch 140/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 3328140288.0000 - mae: 18741.4375\n",
      "Epoch 127/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 5326135808.0000 - mae: 19803.8398\n",
      "\u001b[1m1017/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4900511232.0000 - mae: 19757.4727Epoch 133/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 4901248000.0000 - mae: 19758.0430\n",
      "Epoch 135/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 6103121920.0000 - mae: 20030.8613\n",
      "\u001b[1m 962/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5638902272.0000 - mae: 20126.2930Epoch 138/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 5586706944.0000 - mae: 20107.5547\n",
      "\u001b[1m 325/1018\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 8237527552.0000 - mae: 20492.4844Epoch 132/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 5159133184.0000 - mae: 19994.6074\n",
      "Epoch 137/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 5814891520.0000 - mae: 38918.4336\n",
      "Epoch 133/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 5697488384.0000 - mae: 19669.8340\n",
      "Epoch 128/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 4229646336.0000 - mae: 19038.0840\n",
      "Epoch 141/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 6814125056.0000 - mae: 20552.1094\n",
      "Epoch 139/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 5248653824.0000 - mae: 19961.5996\n",
      "Epoch 136/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 5798764544.0000 - mae: 38349.1914\n",
      "Epoch 134/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4217439488.0000 - mae: 19364.6172\n",
      "Epoch 129/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4118153472.0000 - mae: 19292.2910\n",
      "Epoch 140/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 3489617664.0000 - mae: 18813.0488\n",
      "Epoch 133/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 4978577408.0000 - mae: 19720.7910\n",
      "Epoch 134/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 5115931136.0000 - mae: 19826.1289\n",
      "Epoch 137/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 5259927040.0000 - mae: 19738.9473\n",
      "\u001b[1m 723/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5424483328.0000 - mae: 19718.5996Epoch 138/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 5763622400.0000 - mae: 38607.7070\n",
      "Epoch 135/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 5447104512.0000 - mae: 19764.3379\n",
      "Epoch 141/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4311310336.0000 - mae: 19595.7109\n",
      "Epoch 134/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 4803047424.0000 - mae: 20032.7715\n",
      "Epoch 130/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 4269186560.0000 - mae: 19351.9531\n",
      "Epoch 142/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 5439389696.0000 - mae: 20022.2812\n",
      "Epoch 139/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 5256663552.0000 - mae: 20397.6289\n",
      "Epoch 138/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 5063213568.0000 - mae: 19513.3691\n",
      "Epoch 135/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4191002624.0000 - mae: 19508.2109\n",
      "Epoch 135/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4355724288.0000 - mae: 19223.1895\n",
      "\u001b[1m 413/1018\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 4104044544.0000 - mae: 19159.2188Epoch 131/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 5365779456.0000 - mae: 19686.2012\n",
      "Epoch 140/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 5425663488.0000 - mae: 38692.6523\n",
      "Epoch 136/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 5156544000.0000 - mae: 19746.8066\n",
      "Epoch 139/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 4082741248.0000 - mae: 19248.1777\n",
      "Epoch 136/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 4947448320.0000 - mae: 19617.9082\n",
      "\u001b[1m 958/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5142656000.0000 - mae: 19801.3828Epoch 142/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 3380235264.0000 - mae: 18554.1992\n",
      "Epoch 143/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 5108240384.0000 - mae: 19792.4121\n",
      "Epoch 136/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 4262379520.0000 - mae: 19128.6602\n",
      "Epoch 132/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 4794204672.0000 - mae: 20105.1074\n",
      "Epoch 141/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 6321916928.0000 - mae: 38795.6289\n",
      "Epoch 137/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 5037234688.0000 - mae: 19886.2305\n",
      "Epoch 140/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 4648061952.0000 - mae: 19385.9512\n",
      "Epoch 137/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4283047680.0000 - mae: 19091.5625\n",
      "Epoch 144/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 6108085760.0000 - mae: 20408.2031\n",
      "Epoch 143/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4666090496.0000 - mae: 19202.2090\n",
      "Epoch 141/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 4655356928.0000 - mae: 19753.6504\n",
      "Epoch 142/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 6197853696.0000 - mae: 20347.4766\n",
      "Epoch 138/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 3987530240.0000 - mae: 18970.6172\n",
      "Epoch 145/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 4743866880.0000 - mae: 19394.2207\n",
      "Epoch 137/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 4106888704.0000 - mae: 19159.6406\n",
      "Epoch 133/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 5277465600.0000 - mae: 19769.2676\n",
      "Epoch 144/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 7766933504.0000 - mae: 39423.3438\n",
      "Epoch 138/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 6336271360.0000 - mae: 20483.3945\n",
      "\u001b[1m 864/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4241807104.0000 - mae: 19385.3750Epoch 145/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 4413329408.0000 - mae: 19492.1094\n",
      "Epoch 142/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 5636297728.0000 - mae: 20171.8535\n",
      "Epoch 139/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 4967448064.0000 - mae: 19261.1816\n",
      "Epoch 146/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 6227640320.0000 - mae: 38761.1797\n",
      "Epoch 139/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 4757810176.0000 - mae: 19628.5703\n",
      "Epoch 138/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 3830401792.0000 - mae: 19509.3887\n",
      "Epoch 143/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 6446242304.0000 - mae: 20279.7969\n",
      "Epoch 146/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 5161291264.0000 - mae: 19906.2988\n",
      "Epoch 143/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 4500131328.0000 - mae: 19289.7969\n",
      "Epoch 147/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 3796327936.0000 - mae: 19046.7129\n",
      "Epoch 140/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 5801565184.0000 - mae: 38511.8984\n",
      "Epoch 140/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 4553571328.0000 - mae: 19406.1191\n",
      "\u001b[1m 105/1018\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 2901997056.0000 - mae: 36329.0078Epoch 134/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 5414943232.0000 - mae: 20141.0488\n",
      "Epoch 144/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 5325382144.0000 - mae: 20167.8691\n",
      "Epoch 139/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 4898972672.0000 - mae: 19449.7070\n",
      "Epoch 147/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 5809397248.0000 - mae: 20334.9941\n",
      "Epoch 144/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 3627713280.0000 - mae: 18713.5449\n",
      "Epoch 148/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 4577093120.0000 - mae: 37970.9883\n",
      "Epoch 141/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 5515638784.0000 - mae: 20185.1328\n",
      "Epoch 148/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 3604721920.0000 - mae: 19382.8945\n",
      "Epoch 145/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 6234230272.0000 - mae: 38594.2578\n",
      "Epoch 142/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 4095689984.0000 - mae: 18975.7109\n",
      "Epoch 141/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 3113662208.0000 - mae: 18730.4531\n",
      "Epoch 135/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 5364801536.0000 - mae: 20125.2109\n",
      "Epoch 145/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 4409851904.0000 - mae: 19650.2207\n",
      "Epoch 140/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 5602075648.0000 - mae: 38957.5000\n",
      "Epoch 143/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 5542902272.0000 - mae: 20295.4609\n",
      "Epoch 149/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 5251813376.0000 - mae: 20228.1816\n",
      "Epoch 146/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 4010106368.0000 - mae: 19810.4551\n",
      "Epoch 142/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 3771806464.0000 - mae: 19444.7422\n",
      "Epoch 141/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 4666988544.0000 - mae: 19668.6582\n",
      "Epoch 149/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 7782875136.0000 - mae: 39429.1016\n",
      "Epoch 144/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 6186699264.0000 - mae: 20582.4375\n",
      "Epoch 150/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 4611579392.0000 - mae: 19703.2773\n",
      "Epoch 146/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 3616515328.0000 - mae: 19176.3047\n",
      "Epoch 136/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 7177447424.0000 - mae: 20884.1973\n",
      "Epoch 147/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 5551838720.0000 - mae: 20341.7793\n",
      "Epoch 151/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 3631623168.0000 - mae: 18945.6348\n",
      "Epoch 142/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 6206210560.0000 - mae: 38654.0625\n",
      "Epoch 145/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 6519217152.0000 - mae: 20792.1758\n",
      "Epoch 148/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 4625945600.0000 - mae: 19990.4512\n",
      "Epoch 143/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 5713484288.0000 - mae: 19844.5508\n",
      "Epoch 137/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 7867460096.0000 - mae: 39561.7539\n",
      "\u001b[1m 350/1018\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1894885248.0000 - mae: 18490.5020Epoch 146/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 3382312960.0000 - mae: 18602.0312\n",
      "Epoch 150/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 4503175680.0000 - mae: 19518.7070\n",
      "Epoch 152/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 3171006976.0000 - mae: 18910.1875\n",
      "\u001b[1m 312/1018\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 6883635712.0000 - mae: 20075.8555Epoch 143/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 6530255360.0000 - mae: 20711.1777\n",
      "Epoch 149/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 4011193856.0000 - mae: 19507.9453\n",
      "Epoch 147/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 3239464960.0000 - mae: 18821.2148\n",
      "Epoch 144/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 5372439040.0000 - mae: 20153.9160\n",
      "Epoch 153/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 5188640256.0000 - mae: 19796.6562\n",
      "Epoch 138/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 2951226112.0000 - mae: 18822.1777\n",
      "\u001b[1m  40/1018\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 10056185856.0000 - mae: 22354.7617Epoch 151/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 6045601280.0000 - mae: 19961.8477\n",
      "Epoch 150/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4484154880.0000 - mae: 19237.6973\n",
      "Epoch 145/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 3410439424.0000 - mae: 19247.7734\n",
      "Epoch 144/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 5760248320.0000 - mae: 20550.9531\n",
      "Epoch 148/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 5505631232.0000 - mae: 38494.3945\n",
      "Epoch 147/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 3114746624.0000 - mae: 18885.6133\n",
      "Epoch 139/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 4208208640.0000 - mae: 19096.3320\n",
      "Epoch 154/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 3782818560.0000 - mae: 19145.6992\n",
      "Epoch 152/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 4000273664.0000 - mae: 19322.0957\n",
      "Epoch 149/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 4233852672.0000 - mae: 19682.6621\n",
      "Epoch 151/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 4724186624.0000 - mae: 19458.8242\n",
      "Epoch 146/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 5269874176.0000 - mae: 20153.5430\n",
      "Epoch 152/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 5380247552.0000 - mae: 38515.3086\n",
      "Epoch 148/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 3713470976.0000 - mae: 18911.6328\n",
      "Epoch 150/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 4856192512.0000 - mae: 19855.3711\n",
      "Epoch 145/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 4973960192.0000 - mae: 19417.5684\n",
      "Epoch 153/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 4501251072.0000 - mae: 19674.8262\n",
      "Epoch 153/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 3676664064.0000 - mae: 19067.9609\n",
      "Epoch 147/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 4733573632.0000 - mae: 19484.5410\n",
      "Epoch 140/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 6645122560.0000 - mae: 38997.0938\n",
      "Epoch 149/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 3236376576.0000 - mae: 18473.4492\n",
      "Epoch 154/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 4735705600.0000 - mae: 19600.4258\n",
      "Epoch 146/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 4500909056.0000 - mae: 19265.3418\n",
      "Epoch 151/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 4669867008.0000 - mae: 19454.1660\n",
      "Epoch 155/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 5115555328.0000 - mae: 20169.9199\n",
      "Epoch 154/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 5575813120.0000 - mae: 19814.3223\n",
      "Epoch 141/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 3804244992.0000 - mae: 19161.302776\n",
      "Epoch 155/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 3807550208.0000 - mae: 19501.4629\n",
      "Epoch 147/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 5951837696.0000 - mae: 20211.4766\n",
      "Epoch 155/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 3945916928.0000 - mae: 18892.0020\n",
      "Epoch 142/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 5594595328.0000 - mae: 19899.3262\n",
      "\u001b[1m 146/1018\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4455216640.0000 - mae: 20546.6855Epoch 156/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 5398719488.0000 - mae: 19579.0195\n",
      "Epoch 148/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 6570056192.0000 - mae: 39034.5781\n",
      "Epoch 150/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 6977821184.0000 - mae: 21379.6641\n",
      "Epoch 156/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4006343680.0000 - mae: 19390.1484\n",
      "\u001b[1m 778/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4224532224.0000 - mae: 19177.9121Epoch 143/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 4515755520.0000 - mae: 19367.9336\n",
      "Epoch 156/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 5018612736.0000 - mae: 19848.0449\n",
      "Epoch 148/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 5106531328.0000 - mae: 19615.2422\n",
      "Epoch 149/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 4670401536.0000 - mae: 19722.8125\n",
      "Epoch 152/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 6202582016.0000 - mae: 20317.1094\n",
      "Epoch 157/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 3685537280.0000 - mae: 18660.5859\n",
      "Epoch 157/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4746565120.0000 - mae: 19707.9082\n",
      "\u001b[1m 617/1018\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 3789190400.0000 - mae: 18772.9883Epoch 158/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 5556055040.0000 - mae: 38510.1758\n",
      "\u001b[1m 549/1018\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 4684037120.0000 - mae: 20334.5742Epoch 151/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 3980298496.0000 - mae: 19565.5605\n",
      "Epoch 144/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 5851836928.0000 - mae: 19906.8594\n",
      "Epoch 157/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 4866947072.0000 - mae: 19801.9902\n",
      "Epoch 150/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 3970184960.0000 - mae: 19180.7617\n",
      "Epoch 158/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 4193346560.0000 - mae: 19120.5117\n",
      "Epoch 149/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 4565621248.0000 - mae: 20085.9004\n",
      "Epoch 153/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 6230766080.0000 - mae: 38794.6914\n",
      "Epoch 152/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 5990689792.0000 - mae: 20247.6348\n",
      "Epoch 159/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 3853255936.0000 - mae: 19170.2656\n",
      "Epoch 145/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 6296226304.0000 - mae: 38810.1055\n",
      "Epoch 153/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 4420541952.0000 - mae: 19807.9160\n",
      "\u001b[1m 896/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4433645056.0000 - mae: 19538.8438Epoch 158/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 3907886080.0000 - mae: 19256.0684\n",
      "Epoch 150/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4460205568.0000 - mae: 19565.1484\n",
      "Epoch 154/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 3759369216.0000 - mae: 18954.8418\n",
      "Epoch 159/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 3963593728.0000 - mae: 19211.8730\n",
      "\u001b[1m 489/1018\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6110045696.0000 - mae: 39444.8438Epoch 151/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 5313892352.0000 - mae: 19967.1094\n",
      "Epoch 155/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 6295767552.0000 - mae: 39179.6211\n",
      "Epoch 154/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4520072704.0000 - mae: 19502.3359\n",
      "Epoch 160/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 3675726336.0000 - mae: 19040.9336\n",
      "Epoch 151/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4207397888.0000 - mae: 19488.0234\n",
      "Epoch 156/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 5815475200.0000 - mae: 19877.6582\n",
      "Epoch 152/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 6509905408.0000 - mae: 20704.4160\n",
      "Epoch 160/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 7025586688.0000 - mae: 39448.5547\n",
      "Epoch 155/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 3826326528.0000 - mae: 19006.1641\n",
      "Epoch 146/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4750227456.0000 - mae: 19695.9043\n",
      "Epoch 152/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 3716850944.0000 - mae: 18844.0312\n",
      "Epoch 159/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4817033216.0000 - mae: 19519.0957\n",
      "Epoch 157/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 4275568384.0000 - mae: 19291.5293\n",
      "Epoch 161/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 5845270016.0000 - mae: 38631.8438\n",
      "Epoch 156/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 3552718336.0000 - mae: 19075.2148\n",
      "Epoch 153/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 4776003072.0000 - mae: 19570.0664\n",
      "Epoch 158/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 4392945152.0000 - mae: 19260.3867\n",
      "Epoch 162/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 6574666752.0000 - mae: 38681.4609\n",
      "Epoch 157/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4463418880.0000 - mae: 19747.8184\n",
      "Epoch 154/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 4458045440.0000 - mae: 19301.5312\n",
      "Epoch 153/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 3542450688.0000 - mae: 18859.6602\n",
      "Epoch 163/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 6016095744.0000 - mae: 20413.9258\n",
      "Epoch 161/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 4453133312.0000 - mae: 19516.2891\n",
      "Epoch 159/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 3582325248.0000 - mae: 19070.6367\n",
      "Epoch 147/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 6310526464.0000 - mae: 20636.1074\n",
      "Epoch 160/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 5230413824.0000 - mae: 20055.1094\n",
      "Epoch 155/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 3917608192.0000 - mae: 18894.7051\n",
      "Epoch 154/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 6215038976.0000 - mae: 38881.0469\n",
      "Epoch 158/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 5306529792.0000 - mae: 20158.0039\n",
      "Epoch 164/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 5018331136.0000 - mae: 19934.7754\n",
      "Epoch 162/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 5166879744.0000 - mae: 19885.2832\n",
      "Epoch 161/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 5716021248.0000 - mae: 19937.6797\n",
      "Epoch 163/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 5016051712.0000 - mae: 19463.4023\n",
      "Epoch 155/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 3678661632.0000 - mae: 19268.7832\n",
      "Epoch 156/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 4634375680.0000 - mae: 38138.0938\n",
      "Epoch 159/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 4444976128.0000 - mae: 19796.4219\n",
      "\u001b[1m 252/1018\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 5014138880.0000 - mae: 20472.1484Epoch 160/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 3766988544.0000 - mae: 19494.4004\n",
      "Epoch 165/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 7132026368.0000 - mae: 20301.7871\n",
      "Epoch 148/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 5041206272.0000 - mae: 20041.1543\n",
      "Epoch 162/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 3269820416.0000 - mae: 19187.7012\n",
      "\u001b[1m 659/1018\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3092048640.0000 - mae: 18387.6836Epoch 157/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 3981235456.0000 - mae: 19369.1641\n",
      "Epoch 161/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 5719430656.0000 - mae: 38582.4609\n",
      "Epoch 160/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 3580428032.0000 - mae: 19316.8281\n",
      "Epoch 164/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 3454460928.0000 - mae: 18661.8438\n",
      "Epoch 166/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 5560271360.0000 - mae: 19996.7891\n",
      "Epoch 149/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 4092562944.0000 - mae: 19099.7266\n",
      "Epoch 156/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 5323496960.0000 - mae: 20154.5996\n",
      "Epoch 162/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 5298408448.0000 - mae: 20054.1895\n",
      "Epoch 163/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 6421872128.0000 - mae: 38961.3008\n",
      "Epoch 161/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 4730849792.0000 - mae: 19898.2090\n",
      "Epoch 158/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 862us/step - loss: 6471340544.0000 - mae: 20599.7852\n",
      "Epoch 164/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 4085736192.0000 - mae: 19312.8262 \n",
      "Epoch 163/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 5427328512.0000 - mae: 20070.2246\n",
      "Epoch 157/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 5672074240.0000 - mae: 20027.0391\n",
      "Epoch 159/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 5430021632.0000 - mae: 19474.0625\n",
      "Epoch 165/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4864261120.0000 - mae: 19688.6914\n",
      "Epoch 164/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 5236785664.0000 - mae: 20015.7793\n",
      "Epoch 165/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 5828456448.0000 - mae: 38339.1523\n",
      "Epoch 162/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 5006283264.0000 - mae: 20112.9648\n",
      "Epoch 167/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 6393502720.0000 - mae: 20351.0312\n",
      "Epoch 158/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 5032373760.0000 - mae: 19643.5410\n",
      "Epoch 150/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4012590080.0000 - mae: 19181.8848\n",
      "\u001b[1m 705/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6821665792.0000 - mae: 20695.7363Epoch 160/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4642236928.0000 - mae: 19625.0059\n",
      "Epoch 165/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4198822656.0000 - mae: 19663.7852\n",
      "Epoch 166/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 6259073024.0000 - mae: 20377.3496\n",
      "Epoch 166/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 5035530752.0000 - mae: 19611.1504\n",
      "Epoch 168/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 5215744512.0000 - mae: 20152.7734\n",
      "Epoch 166/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4030485248.0000 - mae: 19701.9453\n",
      "Epoch 161/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 6041750016.0000 - mae: 20601.6328\n",
      "Epoch 167/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 5322509824.0000 - mae: 20068.9844\n",
      "Epoch 151/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 5739343872.0000 - mae: 38781.3516\n",
      "Epoch 163/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 2765051392.0000 - mae: 17926.6348\n",
      "Epoch 169/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 4213399040.0000 - mae: 19493.3535\n",
      "Epoch 159/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 4462924288.0000 - mae: 19187.0898\n",
      "Epoch 152/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 4944129024.0000 - mae: 20196.8535\n",
      "Epoch 168/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 6389068288.0000 - mae: 38575.4297\n",
      "Epoch 164/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 4396462592.0000 - mae: 19654.8594\n",
      "Epoch 162/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 4500024832.0000 - mae: 19659.7207\n",
      "Epoch 167/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 3393601792.0000 - mae: 19033.1055\n",
      "\u001b[1m 140/1018\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 5139206656.0000 - mae: 22559.0820Epoch 167/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 3880249600.0000 - mae: 19088.9648\n",
      "Epoch 170/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 3993275136.0000 - mae: 19070.8379\n",
      "\u001b[1m 812/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5737350144.0000 - mae: 38517.1719Epoch 160/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 5817188352.0000 - mae: 38546.3867\n",
      "Epoch 165/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4402437120.0000 - mae: 19811.6523\n",
      "Epoch 169/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4408734208.0000 - mae: 19347.9492\n",
      "Epoch 163/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4218239232.0000 - mae: 19910.5586\n",
      "Epoch 168/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 862us/step - loss: 5002878464.0000 - mae: 19858.6465\n",
      "Epoch 170/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 3454079488.0000 - mae: 19303.33794\n",
      "Epoch 161/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 6555490304.0000 - mae: 38908.1680\n",
      "Epoch 166/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 4330758656.0000 - mae: 19499.2832\n",
      "Epoch 153/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 4344465408.0000 - mae: 19447.3320\n",
      "\u001b[1m 925/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5173862400.0000 - mae: 20285.2930Epoch 164/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 4027542272.0000 - mae: 19092.7949\n",
      "Epoch 168/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 5168690688.0000 - mae: 20255.6094\n",
      "Epoch 171/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 4916026880.0000 - mae: 19841.0508\n",
      "\u001b[1m 353/1018\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 4077647872.0000 - mae: 19041.5000Epoch 169/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 3526183168.0000 - mae: 18741.2441\n",
      "Epoch 171/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 4272102144.0000 - mae: 19361.1934\n",
      "Epoch 162/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 5037312000.0000 - mae: 19704.4316\n",
      "Epoch 172/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 3818360064.0000 - mae: 18903.5234\n",
      "Epoch 154/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 847us/step - loss: 5629986304.0000 - mae: 20178.4141\n",
      "Epoch 173/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 6217895424.0000 - mae: 20274.4980\n",
      "Epoch 169/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 4557864448.0000 - mae: 19157.6074\n",
      "Epoch 163/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 4373876224.0000 - mae: 19791.8672\n",
      "Epoch 172/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4294398976.0000 - mae: 19142.0176\n",
      "Epoch 170/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 5290164224.0000 - mae: 38124.6797\n",
      "Epoch 167/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 4696979968.0000 - mae: 19475.8418\n",
      "Epoch 174/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 4010016256.0000 - mae: 19089.5938\n",
      "Epoch 165/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 4407043072.0000 - mae: 19248.4805\n",
      "\u001b[1m 839/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4442597376.0000 - mae: 19090.6113Epoch 155/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 5183357440.0000 - mae: 19437.9316\n",
      "Epoch 170/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4543289856.0000 - mae: 19189.0781\n",
      "Epoch 171/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 6103693824.0000 - mae: 20265.6973\n",
      "Epoch 175/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 3483905536.0000 - mae: 18561.4102\n",
      "Epoch 164/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 5435911168.0000 - mae: 38692.0430\n",
      "Epoch 168/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4200915712.0000 - mae: 19629.8867\n",
      "Epoch 166/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 4248592384.0000 - mae: 19264.0371\n",
      "Epoch 173/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 5791243776.0000 - mae: 20939.3027\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 3226097664.0000 - mae: 18895.9629\n",
      "Epoch 176/300\n",
      "Epoch 172/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 5575748096.0000 - mae: 20268.8945\n",
      "Epoch 167/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 5027466240.0000 - mae: 38287.1992\n",
      "Epoch 169/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 3448950272.0000 - mae: 18328.4121\n",
      "Epoch 174/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 4964948992.0000 - mae: 19537.7910\n",
      "Epoch 173/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 5090405376.0000 - mae: 19734.7539\n",
      "Epoch 177/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 6090656256.0000 - mae: 20579.5977\n",
      "\u001b[1m 987/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5510369792.0000 - mae: 20247.7012Epoch 171/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 5479910400.0000 - mae: 20222.0273\n",
      "Epoch 156/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 5839449600.0000 - mae: 20324.9648\n",
      "Epoch 165/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 5764247040.0000 - mae: 20199.1660\n",
      "Epoch 168/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 6478604800.0000 - mae: 20736.8594\n",
      "Epoch 178/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 6046765568.0000 - mae: 38202.0820\n",
      "Epoch 170/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 3334405120.0000 - mae: 18502.8203\n",
      "Epoch 175/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4364715008.0000 - mae: 19315.9785\n",
      "Epoch 172/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4822070272.0000 - mae: 19206.4941\n",
      "Epoch 157/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 5912333824.0000 - mae: 38528.9453\n",
      "Epoch 171/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4879636992.0000 - mae: 19636.0684\n",
      "Epoch 169/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 4880125440.0000 - mae: 19844.4609\n",
      "Epoch 174/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 5552530944.0000 - mae: 20216.2676\n",
      "\u001b[1m 794/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5645039104.0000 - mae: 19560.6348Epoch 179/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 3938359040.0000 - mae: 19120.5293\n",
      "\u001b[1m 806/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3828714240.0000 - mae: 19244.9219Epoch 176/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 2762195712.0000 - mae: 18350.7578\n",
      "Epoch 166/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 5482991104.0000 - mae: 19580.7773\n",
      "Epoch 158/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 4009731584.0000 - mae: 19347.9922\n",
      "Epoch 173/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 5123305472.0000 - mae: 38302.0586\n",
      "Epoch 172/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 5878274048.0000 - mae: 19947.5762\n",
      "Epoch 170/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4828068864.0000 - mae: 20057.7090\n",
      "Epoch 180/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 5064583168.0000 - mae: 19608.6504\n",
      "Epoch 175/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4915660800.0000 - mae: 19134.5762\n",
      "Epoch 177/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 980us/step - loss: 3946967552.0000 - mae: 19048.4336\n",
      "Epoch 176/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 4209355008.0000 - mae: 19401.3262\n",
      "Epoch 167/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 4201842176.0000 - mae: 19488.3301\n",
      "Epoch 171/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 5696928768.0000 - mae: 20426.3164\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 3565175040.0000 - mae: 18628.5938\n",
      "Epoch 181/300\n",
      "Epoch 178/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 5611958272.0000 - mae: 19781.9316\n",
      "\u001b[1m 722/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6490079232.0000 - mae: 20511.2383Epoch 159/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 5333060608.0000 - mae: 19798.7617\n",
      "Epoch 174/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 6240513024.0000 - mae: 20391.7949\n",
      "\u001b[1m 510/1018\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 5854582272.0000 - mae: 20086.6191Epoch 177/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 5538083328.0000 - mae: 19731.2871\n",
      "Epoch 168/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 7273546240.0000 - mae: 39068.9531\n",
      "Epoch 173/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4353695232.0000 - mae: 19274.0430\n",
      "Epoch 179/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 5340895232.0000 - mae: 19907.9043\n",
      "\u001b[1m 926/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5640324608.0000 - mae: 20382.1719Epoch 172/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 5617768448.0000 - mae: 20357.0176\n",
      "Epoch 182/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 5286676992.0000 - mae: 20205.3223\n",
      "Epoch 160/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 5374169600.0000 - mae: 20150.2656\n",
      "Epoch 175/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 3240429824.0000 - mae: 18781.0527\n",
      "Epoch 180/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 5930720768.0000 - mae: 19840.7812\n",
      "Epoch 183/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 4488335360.0000 - mae: 19068.5352\n",
      "Epoch 176/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4342297600.0000 - mae: 18802.4434\n",
      "Epoch 161/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 5321664512.0000 - mae: 19539.4941\n",
      "Epoch 178/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 3667263232.0000 - mae: 18879.0254\n",
      "Epoch 181/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 6221007872.0000 - mae: 38447.1953\n",
      "Epoch 174/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 3794591488.0000 - mae: 19129.2617\n",
      "Epoch 169/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 5663483392.0000 - mae: 19939.0645\n",
      "Epoch 184/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 2938440960.0000 - mae: 18517.6719\n",
      "Epoch 173/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 3878732288.0000 - mae: 19327.3457\n",
      "Epoch 177/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4838579712.0000 - mae: 19973.4395\n",
      "Epoch 162/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 6094416896.0000 - mae: 21034.7266\n",
      "Epoch 174/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 4719567360.0000 - mae: 19647.5156\n",
      "Epoch 179/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 3869419520.0000 - mae: 19502.6973\n",
      "Epoch 185/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 5796457472.0000 - mae: 38616.0703\n",
      "Epoch 175/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4290546432.0000 - mae: 19792.2305\n",
      "Epoch 178/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 5935132672.0000 - mae: 20151.3691\n",
      "Epoch 163/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 4182172160.0000 - mae: 19279.1777\n",
      "Epoch 182/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 6140150784.0000 - mae: 20694.7109\n",
      "Epoch 186/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 5310766592.0000 - mae: 19831.8965\n",
      "Epoch 180/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 3710375424.0000 - mae: 19288.0977\n",
      "Epoch 170/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 6907275264.0000 - mae: 39431.9023\n",
      "Epoch 176/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 4873606656.0000 - mae: 19745.8496\n",
      "Epoch 179/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 3639498752.0000 - mae: 19357.1816\n",
      "Epoch 175/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 5745913856.0000 - mae: 20409.5664\n",
      "Epoch 164/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 4210924544.0000 - mae: 18657.2051\n",
      "Epoch 181/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 5988283904.0000 - mae: 38764.2695\n",
      "Epoch 177/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 5386918400.0000 - mae: 20052.6230\n",
      "Epoch 176/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 4890021888.0000 - mae: 19544.1641\n",
      "Epoch 165/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 5387548160.0000 - mae: 19431.0098\n",
      "Epoch 182/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4815773184.0000 - mae: 37986.3789\n",
      "\u001b[1m 624/1018\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4772208640.0000 - mae: 19351.2266Epoch 178/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 4455710720.0000 - mae: 18966.1465\n",
      "Epoch 183/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4832474112.0000 - mae: 19506.3184\n",
      "Epoch 177/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 5425845760.0000 - mae: 19692.3965\n",
      "Epoch 171/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 5789027328.0000 - mae: 20243.8594\n",
      "Epoch 187/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 3839443456.0000 - mae: 18957.6094\n",
      "Epoch 166/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 4476382208.0000 - mae: 19049.7402\n",
      "Epoch 183/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 6801444864.0000 - mae: 20651.3340\n",
      "Epoch 188/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 4811397120.0000 - mae: 37938.78527\n",
      "Epoch 179/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 3850350592.0000 - mae: 19410.8086\n",
      "Epoch 180/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 2792676096.0000 - mae: 18519.2402\n",
      "Epoch 184/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 4563088896.0000 - mae: 19515.5254\n",
      "Epoch 178/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 799us/step - loss: 5693044736.0000 - mae: 20053.2090\n",
      "Epoch 189/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4764087808.0000 - mae: 19115.2227\n",
      "Epoch 172/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 3690692864.0000 - mae: 19483.5957\n",
      "\u001b[1m 653/1018\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4772564480.0000 - mae: 19439.3574Epoch 190/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 3634932736.0000 - mae: 19196.3027\n",
      "Epoch 185/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 3174938368.0000 - mae: 19136.1895\n",
      "Epoch 179/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 4523102720.0000 - mae: 19310.0586\n",
      "Epoch 167/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 4587814400.0000 - mae: 19266.9414\n",
      "\u001b[1m 100/1018\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 3800099072.0000 - mae: 18764.1465Epoch 173/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 4407413760.0000 - mae: 19495.5215\n",
      "Epoch 184/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4660043776.0000 - mae: 19544.7207\n",
      "\u001b[1m 214/1018\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 3200098304.0000 - mae: 18639.7305Epoch 191/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 4840432640.0000 - mae: 19432.5430\n",
      "\u001b[1m 254/1018\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 1457165824.0000 - mae: 17638.2402Epoch 181/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 5245958144.0000 - mae: 38103.2734\n",
      "Epoch 180/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 3469848320.0000 - mae: 19211.2930\n",
      "Epoch 180/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 4360161280.0000 - mae: 19241.4805\n",
      "\u001b[1m 803/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2960159232.0000 - mae: 18441.7617Epoch 186/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 3281942528.0000 - mae: 18631.8809\n",
      "Epoch 174/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 6576549376.0000 - mae: 20941.0469\n",
      "Epoch 185/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 6926828032.0000 - mae: 38839.1328\n",
      "Epoch 181/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 4392726016.0000 - mae: 19342.9883\n",
      "\u001b[1m  89/1018\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1672587264.0000 - mae: 18942.4316Epoch 168/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 5284499968.0000 - mae: 20076.1250\n",
      "\u001b[1m 759/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5421471744.0000 - mae: 20067.8535Epoch 192/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 5273964032.0000 - mae: 19998.3711\n",
      "\u001b[1m 699/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2994631424.0000 - mae: 19133.6016Epoch 181/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 3558117376.0000 - mae: 19299.3145\n",
      "Epoch 175/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 6098378752.0000 - mae: 38748.6836\n",
      "Epoch 182/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4955762176.0000 - mae: 19798.3496\n",
      "Epoch 186/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 5229243904.0000 - mae: 19557.4844\n",
      "\u001b[1m 657/1018\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8482699776.0000 - mae: 21268.6113Epoch 169/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 4005484032.0000 - mae: 19671.5469\n",
      "Epoch 182/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 7380526080.0000 - mae: 20791.0684\n",
      "Epoch 193/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 3442996480.0000 - mae: 18950.3594\n",
      "Epoch 187/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 7101127168.0000 - mae: 39171.0938\n",
      "Epoch 183/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 6144814080.0000 - mae: 19998.4570\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 5118245376.0000 - mae: 19912.7988\n",
      "Epoch 176/200\n",
      "Epoch 187/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 5241727488.0000 - mae: 19836.7871\n",
      "Epoch 183/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 4295001088.0000 - mae: 19011.0039\n",
      "Epoch 170/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 5254427648.0000 - mae: 19487.0078\n",
      "Epoch 188/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 4548858880.0000 - mae: 19262.6562\n",
      "Epoch 194/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 6256051712.0000 - mae: 20176.6230\n",
      "Epoch 182/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 4539266560.0000 - mae: 19838.1816\n",
      "Epoch 188/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 6035749376.0000 - mae: 38155.7461\n",
      "Epoch 184/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 4374413312.0000 - mae: 19498.3242\n",
      "Epoch 189/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 5181761024.0000 - mae: 19965.0762\n",
      "\u001b[1m 155/1018\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 4749105664.0000 - mae: 20732.6191Epoch 171/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 5795207680.0000 - mae: 20329.8008\n",
      "\u001b[1m 473/1018\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 5065830912.0000 - mae: 19998.0156Epoch 195/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 3061907712.0000 - mae: 18786.4355\n",
      "Epoch 183/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 5878575616.0000 - mae: 20242.9160\n",
      "Epoch 177/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 4102839808.0000 - mae: 19004.3906\n",
      "\u001b[1m 726/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6027564032.0000 - mae: 38813.9570Epoch 189/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 6159879168.0000 - mae: 20442.3535\n",
      "Epoch 190/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 4431155200.0000 - mae: 19543.4004\n",
      "Epoch 172/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 6078362112.0000 - mae: 38850.6562 42\n",
      "Epoch 185/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 6193165824.0000 - mae: 20145.6641\n",
      "Epoch 184/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 876us/step - loss: 3796128512.0000 - mae: 18788.6133\n",
      "Epoch 173/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4583604736.0000 - mae: 19641.6113\n",
      "Epoch 178/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 4208946176.0000 - mae: 19735.8926\n",
      "Epoch 191/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 6316943872.0000 - mae: 20582.7305\n",
      "Epoch 185/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 4216417280.0000 - mae: 19092.6465\n",
      "Epoch 190/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4173903872.0000 - mae: 18895.6387\n",
      "Epoch 174/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 5316014592.0000 - mae: 19961.9707\n",
      "Epoch 186/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 5162423296.0000 - mae: 19875.8848\n",
      "Epoch 196/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 4582307840.0000 - mae: 19444.6953\n",
      "Epoch 179/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 4496096768.0000 - mae: 19671.7832\n",
      "Epoch 184/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 4906864640.0000 - mae: 19693.4492\n",
      "Epoch 192/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 5874839552.0000 - mae: 38592.2266\n",
      "Epoch 186/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4065637888.0000 - mae: 19423.8301\n",
      "Epoch 175/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 5600462848.0000 - mae: 20344.4922\n",
      "Epoch 187/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 5210439168.0000 - mae: 20038.4395\n",
      "Epoch 180/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 5312074752.0000 - mae: 20016.8984\n",
      "Epoch 197/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 4012952064.0000 - mae: 18918.6035\n",
      "\u001b[1m 912/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3151634688.0000 - mae: 18575.5332Epoch 191/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 3316449792.0000 - mae: 18661.4688\n",
      "Epoch 176/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 850us/step - loss: 4051836672.0000 - mae: 18939.4199\n",
      "Epoch 181/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4986188800.0000 - mae: 19753.4473\n",
      "Epoch 177/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 4171499008.0000 - mae: 19902.1602\n",
      "Epoch 185/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 4308355072.0000 - mae: 18926.0449\n",
      "\u001b[1m  25/1018\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 1351384704.0000 - mae: 18240.9160Epoch 188/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 5056917504.0000 - mae: 19638.3125\n",
      "Epoch 198/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 4019910144.0000 - mae: 19167.2715\n",
      "Epoch 182/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 4310069248.0000 - mae: 19031.0195\n",
      "Epoch 192/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 7287031808.0000 - mae: 20484.2637\n",
      "Epoch 193/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 6685175808.0000 - mae: 39029.6484\n",
      "Epoch 187/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 5120137728.0000 - mae: 20066.9355\n",
      "Epoch 186/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 3986946816.0000 - mae: 19281.6055\n",
      "Epoch 178/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 6850583040.0000 - mae: 21454.3164\n",
      "Epoch 187/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 3129873152.0000 - mae: 19041.0410\n",
      "Epoch 189/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 5467920384.0000 - mae: 20002.1133\n",
      "Epoch 199/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4467379712.0000 - mae: 19537.4844\n",
      "Epoch 193/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 5116970496.0000 - mae: 38271.0977\n",
      "Epoch 188/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 4874324992.0000 - mae: 19660.3438\n",
      "Epoch 188/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4436976128.0000 - mae: 19506.5586\n",
      "Epoch 179/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 5446878208.0000 - mae: 20154.9141\n",
      "Epoch 183/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 6965591552.0000 - mae: 38734.1758\n",
      "Epoch 189/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4247291392.0000 - mae: 19206.7832\n",
      "Epoch 194/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 5295756800.0000 - mae: 19494.6543\n",
      "Epoch 194/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 4591692288.0000 - mae: 19546.6348\n",
      "Epoch 184/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 5274385920.0000 - mae: 38221.7344\n",
      "Epoch 190/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 3763087872.0000 - mae: 18805.8770\n",
      "Epoch 195/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 4434572800.0000 - mae: 19761.0898\n",
      "Epoch 190/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 3633554944.0000 - mae: 19111.5664\n",
      "Epoch 189/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 4076522496.0000 - mae: 19060.7031\n",
      "Epoch 200/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 4196111872.0000 - mae: 18833.3730\n",
      "Epoch 180/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 2876855552.0000 - mae: 18272.5508\n",
      "Epoch 195/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4837799424.0000 - mae: 19780.4121\n",
      "Epoch 191/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 4876900864.0000 - mae: 38016.1250\n",
      "Epoch 191/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 3493433856.0000 - mae: 18708.6172\n",
      "\u001b[1m  22/1018\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4735689728.0000 - mae: 41007.4180   Epoch 185/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 5347066368.0000 - mae: 20265.9531\n",
      "Epoch 196/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 6156894208.0000 - mae: 20723.1387\n",
      "\u001b[1m 233/1018\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 3560271360.0000 - mae: 19306.6719Epoch 190/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 6670697472.0000 - mae: 20863.8730\n",
      "Epoch 201/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 2945343232.0000 - mae: 18300.5781\n",
      "Epoch 196/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 3578989056.0000 - mae: 18708.0977\n",
      "\u001b[1m 790/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4357975040.0000 - mae: 19175.8340Epoch 191/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 5710736384.0000 - mae: 19970.9746\n",
      "Epoch 192/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 6626262016.0000 - mae: 39126.1875\n",
      "Epoch 192/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 4625876480.0000 - mae: 19288.6270\n",
      "Epoch 197/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 5246627840.0000 - mae: 20148.4863\n",
      "\u001b[1m 382/1018\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7323954176.0000 - mae: 39493.1094Epoch 181/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 5579847680.0000 - mae: 20546.6797\n",
      "Epoch 202/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 6290141184.0000 - mae: 20692.5430\n",
      "Epoch 186/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 6447227392.0000 - mae: 38934.9883\n",
      "Epoch 193/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 5815907840.0000 - mae: 20405.9883\n",
      "Epoch 192/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 6240773632.0000 - mae: 20251.8379\n",
      "Epoch 193/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4477135872.0000 - mae: 18854.5254\n",
      "Epoch 182/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 4573865472.0000 - mae: 19636.9238\n",
      "Epoch 197/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 7498799104.0000 - mae: 39201.2109\n",
      "Epoch 194/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 4171140352.0000 - mae: 19304.32030\n",
      "Epoch 203/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 882us/step - loss: 6567156736.0000 - mae: 38639.8555\n",
      "Epoch 195/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 5074940928.0000 - mae: 19874.2656\n",
      "\u001b[1m 690/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4903774720.0000 - mae: 19390.7129Epoch 193/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 4911527424.0000 - mae: 19471.1289\n",
      "Epoch 187/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 3932074240.0000 - mae: 18693.9863\n",
      "Epoch 198/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 5277756416.0000 - mae: 19925.1016\n",
      "\u001b[1m 405/1018\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3972533248.0000 - mae: 19482.2305Epoch 198/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 4862638592.0000 - mae: 19414.2988\n",
      "Epoch 183/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 5870669824.0000 - mae: 38936.3945\n",
      "\u001b[1m 474/1018\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5913675776.0000 - mae: 19753.3730Epoch 196/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4331277312.0000 - mae: 19519.4316\n",
      "Epoch 194/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4472086528.0000 - mae: 19512.1387\n",
      "Epoch 188/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 5612094464.0000 - mae: 19774.4863\n",
      "\u001b[1m 143/1018\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 2451695872.0000 - mae: 18456.8301Epoch 199/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 3760573440.0000 - mae: 18915.2227\n",
      "Epoch 199/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 4097679360.0000 - mae: 19277.5957\n",
      "Epoch 194/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 3721901312.0000 - mae: 19109.3398\n",
      "Epoch 204/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 5850411520.0000 - mae: 38299.8281\n",
      "Epoch 197/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 5144312832.0000 - mae: 19696.8594\n",
      "Epoch 195/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4486115328.0000 - mae: 19235.3242\n",
      "Epoch 200/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 4545608192.0000 - mae: 19608.6055\n",
      "\u001b[1m 965/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4853287936.0000 - mae: 19420.6816Epoch 189/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 4878991360.0000 - mae: 19440.1016\n",
      "Epoch 200/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 5220680704.0000 - mae: 19753.8789\n",
      "Epoch 196/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 4596846080.0000 - mae: 20210.2715\n",
      "Epoch 205/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 4399174144.0000 - mae: 19656.0449\n",
      "Epoch 195/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 4283107584.0000 - mae: 19024.0898\n",
      "Epoch 184/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 5593741312.0000 - mae: 38661.4609\n",
      "\u001b[1m 856/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3071066112.0000 - mae: 18956.5469Epoch 198/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 5180843008.0000 - mae: 19764.4707\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 3306684160.0000 - mae: 19034.4883\n",
      "Epoch 196/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 3324897536.0000 - mae: 18296.9883\n",
      "Epoch 201/300\n",
      "\u001b[1m   1/1018\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m47s\u001b[0m 47ms/step - loss: 550862592.0000 - mae: 16432.9023654.0117"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-17 10:38:36.188395: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 146889860 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/stepep - loss: 5496364544.0000 - mae: 20240.04\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 5193255936.0000 - mae: 19830.4375\n",
      "Epoch 197/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 4066668288.0000 - mae: 18733.2227\n",
      "\u001b[1m 787/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4903704064.0000 - mae: 20315.0410Epoch 185/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 6246808576.0000 - mae: 38565.9180\n",
      "Epoch 199/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 4878098944.0000 - mae: 20151.6504\n",
      "Epoch 190/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 3937093632.0000 - mae: 19508.8438\n",
      "Epoch 202/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 5500168192.0000 - mae: 20105.4395\n",
      "Epoch 206/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 3893615104.0000 - mae: 19358.3613\n",
      "Epoch 197/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 5936571392.0000 - mae: 20382.714822\n",
      "Epoch 198/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4517437952.0000 - mae: 19238.8262\n",
      "Epoch 191/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 6271910912.0000 - mae: 20666.3828\n",
      "Epoch 198/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 5487563776.0000 - mae: 38642.1367\n",
      "Epoch 200/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 4613393920.0000 - mae: 19866.8418\n",
      "Epoch 186/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 3594806528.0000 - mae: 18741.9531\n",
      "Epoch 203/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 3798476800.0000 - mae: 19185.4590\n",
      "Epoch 199/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 5741933056.0000 - mae: 20394.5703\n",
      "Epoch 207/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 5003305472.0000 - mae: 19732.3574\n",
      "Epoch 187/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 5412759552.0000 - mae: 38551.1680\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 4141370112.0000 - mae: 19013.7363\n",
      "Epoch 192/200\n",
      "\u001b[1m 591/1018\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 5453364736.0000 - mae: 20424.5000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-17 10:38:43.185405: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 146889860 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 5921467904.0000 - mae: 20378.7012\n",
      "Epoch 199/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4805985280.0000 - mae: 19490.2910\n",
      "\u001b[1m136/340\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/stepEpoch 208/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 3480597248.0000 - mae: 18965.3633\n",
      "Epoch 204/300\n",
      "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/stepep - loss: 5340717568.0000 - mae: 20325.9398\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 5235129856.0000 - mae: 20215.4043\n",
      "Epoch 200/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 5402716672.0000 - mae: 19996.0664\n",
      "Epoch 188/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 3240549376.0000 - mae: 18670.9473\n",
      "Epoch 200/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4748081664.0000 - mae: 20050.2402\n",
      "Epoch 209/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4217316352.0000 - mae: 19088.63879\n",
      "Epoch 205/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 941us/step - loss: 4465790976.0000 - mae: 19869.6172\n",
      "Epoch 201/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 6282333184.0000 - mae: 20377.8906\n",
      "Epoch 193/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 5353795072.0000 - mae: 19649.1055\n",
      "Epoch 189/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4485921792.0000 - mae: 19790.9766\n",
      "Epoch 210/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 3184755200.0000 - mae: 18594.9512\n",
      "Epoch 206/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 4737192448.0000 - mae: 19368.0371\n",
      "Epoch 202/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4677298688.0000 - mae: 19156.8535\n",
      "Epoch 194/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 5855649280.0000 - mae: 20567.0352 \n",
      "Epoch 203/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 4734381056.0000 - mae: 19523.7461\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 3276871168.0000 - mae: 18385.3516\n",
      "Epoch 190/300\n",
      "\u001b[1m 702/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7118531584.0000 - mae: 21189.4492"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-17 10:38:49.318461: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 146876328 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 5626278912.0000 - mae: 19752.4258\n",
      "Epoch 207/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 6720172032.0000 - mae: 20930.7871\n",
      "Epoch 211/300\n",
      "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 866us/step - loss: 3801767168.0000 - mae: 19594.9097\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 5850526208.0000 - mae: 20075.4453\n",
      "Epoch 195/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4099487232.0000 - mae: 19507.5273\n",
      "Epoch 204/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4148085504.0000 - mae: 19638.4355\n",
      "Epoch 191/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 4429996544.0000 - mae: 18994.2480\n",
      "Epoch 208/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4263816448.0000 - mae: 18966.8711\n",
      "Epoch 196/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 4628209152.0000 - mae: 19597.7949\n",
      "Epoch 212/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 810us/step - loss: 5696873984.0000 - mae: 19962.9434\n",
      "\u001b[1m 967/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4384269312.0000 - mae: 19206.6309Epoch 213/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4378121728.0000 - mae: 19214.3223\n",
      "Epoch 205/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4087188736.0000 - mae: 19332.5781\n",
      "Epoch 192/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 5539460096.0000 - mae: 19587.0801\n",
      "Epoch 197/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 818us/step - loss: 4854000640.0000 - mae: 19872.3086\n",
      "Epoch 214/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 6514498048.0000 - mae: 20541.5742\n",
      "Epoch 209/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 5031863808.0000 - mae: 20012.2969\n",
      "Epoch 215/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4523773440.0000 - mae: 19711.2754\n",
      "\u001b[1m 149/1018\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2614575104.0000 - mae: 19906.7891Epoch 193/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 5106150400.0000 - mae: 19622.5215\n",
      "Epoch 198/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 907us/step - loss: 4766797312.0000 - mae: 20025.3320\n",
      "Epoch 216/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 6087014400.0000 - mae: 20973.1367\n",
      "Epoch 206/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4387211776.0000 - mae: 18989.8652\n",
      "Epoch 210/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4419352576.0000 - mae: 19585.4512\n",
      "Epoch 194/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4575183872.0000 - mae: 19375.0000\n",
      "Epoch 199/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 866us/step - loss: 5321459712.0000 - mae: 19391.9395\n",
      "Epoch 195/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 5535508480.0000 - mae: 20190.2852\n",
      "Epoch 217/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4474798080.0000 - mae: 19551.6680\n",
      "Epoch 207/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 3749759232.0000 - mae: 19170.4570\n",
      "Epoch 211/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 815us/step - loss: 3739067136.0000 - mae: 19298.1562\n",
      "Epoch 196/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 3912970752.0000 - mae: 18844.7695\n",
      "\u001b[1m 196/1018\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 5780646400.0000 - mae: 19313.2070Epoch 200/200\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 909us/step - loss: 4653039104.0000 - mae: 19331.1680\n",
      "Epoch 197/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 6974674944.0000 - mae: 20661.1660\n",
      "Epoch 208/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 4029960448.0000 - mae: 18724.5977\n",
      "Epoch 212/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 5749942272.0000 - mae: 19934.0762\n",
      "Epoch 218/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 811us/step - loss: 4094044672.0000 - mae: 19519.0840\n",
      "Epoch 198/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 6980574720.0000 - mae: 20728.8750  \n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 5769218048.0000 - mae: 19752.3027\n",
      "Epoch 213/300\n",
      "\u001b[1m  37/1018\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 2280753152.0000 - mae: 20510.4570 19773.9133"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-17 10:39:00.599953: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 146876328 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 839us/step - loss: 5635175936.0000 - mae: 19720.5801\n",
      "Epoch 199/300\n",
      "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 981us/step - loss: 4452677632.0000 - mae: 20705.2994\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 5796135936.0000 - mae: 19815.0625\n",
      "Epoch 209/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 982us/step - loss: 6151159808.0000 - mae: 20346.9375\n",
      "Epoch 200/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 5470539776.0000 - mae: 20192.9902\n",
      "\u001b[1m 370/1018\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 819us/step - loss: 4965432320.0000 - mae: 19077.1133Epoch 214/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 4851638784.0000 - mae: 20452.2949\n",
      "Epoch 219/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 834us/step - loss: 4927035392.0000 - mae: 19348.5645\n",
      "Epoch 201/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 3866199808.0000 - mae: 19166.6641\n",
      "Epoch 210/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 3734851072.0000 - mae: 19105.2441\n",
      "Epoch 215/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 5094716416.0000 - mae: 19842.5762\n",
      "Epoch 220/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 921us/step - loss: 4460356608.0000 - mae: 19274.3223\n",
      "Epoch 202/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 604us/step - loss: 5527251968.0000 - mae: 20173.3379\n",
      "Epoch 221/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 719us/step - loss: 5563614208.0000 - mae: 19857.0996\n",
      "Epoch 203/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 5474119680.0000 - mae: 19981.7871\n",
      "Epoch 222/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 4366152704.0000 - mae: 19606.2402\n",
      "Epoch 211/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 835us/step - loss: 4225134336.0000 - mae: 19108.0820\n",
      "Epoch 216/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 6271603712.0000 - mae: 20148.3750\n",
      "Epoch 204/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 791us/step - loss: 5901107200.0000 - mae: 20232.0977\n",
      "Epoch 217/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 5317491712.0000 - mae: 19854.8691\n",
      "Epoch 223/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 6342866432.0000 - mae: 19986.56058\n",
      "Epoch 212/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 5193483776.0000 - mae: 19911.5078\n",
      "Epoch 205/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 814us/step - loss: 4081532672.0000 - mae: 19534.7676\n",
      "Epoch 218/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 780us/step - loss: 3960613120.0000 - mae: 18776.1367\n",
      "Epoch 219/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 4666084864.0000 - mae: 19989.7734\n",
      "Epoch 224/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 4949339648.0000 - mae: 19655.40439\n",
      "Epoch 213/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 3418081280.0000 - mae: 18784.6758\n",
      "\u001b[1m 154/1018\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 8305243648.0000 - mae: 20669.9453Epoch 206/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 834us/step - loss: 4349559808.0000 - mae: 19224.2207\n",
      "Epoch 220/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 5647543808.0000 - mae: 20281.4902\n",
      "Epoch 225/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 811us/step - loss: 3349022464.0000 - mae: 18407.9609\n",
      "Epoch 221/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 5495233536.0000 - mae: 20155.3008\n",
      "Epoch 214/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 4578884608.0000 - mae: 19678.1445\n",
      "Epoch 207/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 880us/step - loss: 4906988032.0000 - mae: 19301.5371\n",
      "Epoch 222/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 991us/step - loss: 6010018816.0000 - mae: 20417.5176\n",
      "Epoch 226/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 972us/step - loss: 3968034816.0000 - mae: 19498.5352\n",
      "\u001b[1m 265/1018\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 768us/step - loss: 6327478784.0000 - mae: 20214.0840Epoch 215/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 3220509696.0000 - mae: 18588.5137\n",
      "\u001b[1m 490/1018\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 8160371200.0000 - mae: 21443.2695Epoch 223/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 5271924736.0000 - mae: 19793.8359\n",
      "Epoch 227/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 985us/step - loss: 6852771328.0000 - mae: 20810.8066\n",
      "Epoch 216/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 5077798912.0000 - mae: 19848.5117\n",
      "Epoch 208/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 4332066816.0000 - mae: 19502.3945\n",
      "\u001b[1m 586/1018\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5114297344.0000 - mae: 19908.1543Epoch 228/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 5687075840.0000 - mae: 19989.1094\n",
      "Epoch 224/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 4983815168.0000 - mae: 19843.8555\n",
      "Epoch 217/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 3829081600.0000 - mae: 19332.8164\n",
      "Epoch 209/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 5430477312.0000 - mae: 20284.9414\n",
      "Epoch 229/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 3500455936.0000 - mae: 18305.4512\n",
      "Epoch 225/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 3217425408.0000 - mae: 18672.8008\n",
      "Epoch 218/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 4094993664.0000 - mae: 19189.2832\n",
      "Epoch 210/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 3591609344.0000 - mae: 18924.4824\n",
      "Epoch 230/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 808us/step - loss: 4770843648.0000 - mae: 19721.4258\n",
      "Epoch 219/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 3414778112.0000 - mae: 18466.582037\n",
      "Epoch 226/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 710us/step - loss: 4150543360.0000 - mae: 19405.4043\n",
      "Epoch 220/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 4623307776.0000 - mae: 19416.712958\n",
      "Epoch 231/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 6846730752.0000 - mae: 20025.7734\n",
      "Epoch 227/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 5305905664.0000 - mae: 19744.8301\n",
      "Epoch 221/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 3936396032.0000 - mae: 19284.9922\n",
      "Epoch 211/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 3730406400.0000 - mae: 19073.6270\n",
      "Epoch 232/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 4904035840.0000 - mae: 18968.9395\n",
      "\u001b[1m 294/1018\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4830695936.0000 - mae: 18868.2695Epoch 228/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 4599842304.0000 - mae: 19783.5215\n",
      "Epoch 222/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 5950304256.0000 - mae: 20103.3027\n",
      "Epoch 212/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 5050407424.0000 - mae: 19562.5977\n",
      "Epoch 233/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 4008103424.0000 - mae: 19260.6348\n",
      "Epoch 229/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 5025351680.0000 - mae: 19397.5801\n",
      "Epoch 213/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 4415504384.0000 - mae: 20334.6992\n",
      "Epoch 223/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 4811450880.0000 - mae: 19722.1445\n",
      "Epoch 234/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 4125402624.0000 - mae: 19278.7305\n",
      "Epoch 230/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 4790941696.0000 - mae: 19452.9531\n",
      "Epoch 214/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 4391886336.0000 - mae: 19428.5020\n",
      "Epoch 224/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 687us/step - loss: 4697062400.0000 - mae: 18953.9082\n",
      "Epoch 231/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 747us/step - loss: 3692984064.0000 - mae: 18644.2715\n",
      "Epoch 232/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 5089033216.0000 - mae: 19885.2031\n",
      "Epoch 225/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 6816166912.0000 - mae: 21151.33989\n",
      "Epoch 215/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 6744789504.0000 - mae: 21054.2012\n",
      "Epoch 235/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 2958924800.0000 - mae: 18071.4316\n",
      "Epoch 233/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 936us/step - loss: 6031031808.0000 - mae: 20267.2109\n",
      "Epoch 226/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 4648392704.0000 - mae: 19103.5098\n",
      "Epoch 216/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 5801871360.0000 - mae: 20190.7969\n",
      "\u001b[1m 515/1018\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3602775552.0000 - mae: 19315.2324Epoch 236/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 5202097152.0000 - mae: 19986.7559\n",
      "Epoch 234/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 4093073920.0000 - mae: 19489.0273\n",
      "Epoch 227/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 5470529024.0000 - mae: 19880.9395\n",
      "Epoch 217/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 5346502656.0000 - mae: 20050.7363\n",
      "Epoch 237/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 3534947328.0000 - mae: 19040.9668\n",
      "\u001b[1m 857/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3941827584.0000 - mae: 19142.2363Epoch 235/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 4053170176.0000 - mae: 19223.5254\n",
      "Epoch 228/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 5636278784.0000 - mae: 20257.7227\n",
      "Epoch 238/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 4639239168.0000 - mae: 19341.6426\n",
      "Epoch 218/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 3724405248.0000 - mae: 18637.01178\n",
      "\u001b[1m 827/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4886566400.0000 - mae: 19434.5742Epoch 236/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 4875070976.0000 - mae: 19491.1250\n",
      "Epoch 229/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 717us/step - loss: 8334133760.0000 - mae: 20984.5859\n",
      "Epoch 219/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 3840727040.0000 - mae: 19192.3438\n",
      "Epoch 239/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 675us/step - loss: 3452953088.0000 - mae: 18166.8594\n",
      "Epoch 220/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 961us/step - loss: 5375219712.0000 - mae: 19808.0762\n",
      "Epoch 230/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 692us/step - loss: 6175955456.0000 - mae: 20087.1230\n",
      "Epoch 221/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 4785227264.0000 - mae: 19710.0547\n",
      "Epoch 240/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 2716776704.0000 - mae: 18080.8184\n",
      "Epoch 237/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 933us/step - loss: 3738312960.0000 - mae: 19130.9082\n",
      "Epoch 222/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4629451264.0000 - mae: 19546.2910\n",
      "Epoch 231/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 5921620992.0000 - mae: 20619.8691\n",
      "Epoch 241/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 4427807232.0000 - mae: 19119.5957\n",
      "Epoch 238/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 3001404928.0000 - mae: 18294.0625\n",
      "Epoch 223/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 4491153408.0000 - mae: 19435.3184\n",
      "Epoch 232/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 767us/step - loss: 3616848640.0000 - mae: 18637.8867\n",
      "Epoch 239/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 5100708352.0000 - mae: 19428.611321\n",
      "Epoch 242/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 883us/step - loss: 4717081600.0000 - mae: 19869.4492\n",
      "Epoch 233/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 918us/step - loss: 3733462528.0000 - mae: 18850.5332\n",
      "Epoch 240/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 5105688576.0000 - mae: 19535.3984\n",
      "Epoch 243/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 717us/step - loss: 4118160128.0000 - mae: 19195.6270\n",
      "Epoch 241/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 4078499072.0000 - mae: 19379.7363\n",
      "Epoch 234/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 5375678976.0000 - mae: 20004.3848\n",
      "Epoch 224/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 5339200512.0000 - mae: 20145.64845\n",
      "Epoch 244/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 947us/step - loss: 3792789504.0000 - mae: 18728.8164\n",
      "Epoch 242/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 3407622656.0000 - mae: 19282.4941\n",
      "Epoch 235/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 809us/step - loss: 3281824512.0000 - mae: 18752.2773\n",
      "Epoch 243/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4204618496.0000 - mae: 18936.7891\n",
      "Epoch 225/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 6218178560.0000 - mae: 20431.5430\n",
      "Epoch 245/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 761us/step - loss: 4835725312.0000 - mae: 19578.5195\n",
      "Epoch 236/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 753us/step - loss: 3771484160.0000 - mae: 19313.4316\n",
      "Epoch 237/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 3952418560.0000 - mae: 19035.1445\n",
      "Epoch 244/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 5017765888.0000 - mae: 19429.0840\n",
      "Epoch 226/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 6976455680.0000 - mae: 20715.4414\n",
      "Epoch 246/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 716us/step - loss: 4319651840.0000 - mae: 19398.0059\n",
      "Epoch 238/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 3813338880.0000 - mae: 19297.3086\n",
      "Epoch 245/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 724us/step - loss: 5742420992.0000 - mae: 20182.1543\n",
      "Epoch 247/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 3858195200.0000 - mae: 19014.5645\n",
      "Epoch 239/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 718us/step - loss: 4247024896.0000 - mae: 19566.0391\n",
      "Epoch 248/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 3908486656.0000 - mae: 19347.6133\n",
      "Epoch 246/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 4494285312.0000 - mae: 19146.1387\n",
      "Epoch 227/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 940us/step - loss: 6056753664.0000 - mae: 20498.6484\n",
      "Epoch 249/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4367504384.0000 - mae: 19605.8164\n",
      "Epoch 240/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 935us/step - loss: 3822403584.0000 - mae: 19070.8125\n",
      "Epoch 247/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 4608395264.0000 - mae: 19121.0703\n",
      "Epoch 228/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 5512913920.0000 - mae: 20062.2129\n",
      "Epoch 250/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 858us/step - loss: 5022397440.0000 - mae: 19537.6680\n",
      "Epoch 248/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 4750356480.0000 - mae: 19470.57425\n",
      "Epoch 241/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 791us/step - loss: 6286015488.0000 - mae: 19999.7812\n",
      "Epoch 251/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 810us/step - loss: 6139138048.0000 - mae: 20637.2070\n",
      "Epoch 242/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 775us/step - loss: 3985134336.0000 - mae: 19032.4707\n",
      "Epoch 249/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 803us/step - loss: 4565232640.0000 - mae: 19051.0156\n",
      "Epoch 250/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 4914414080.0000 - mae: 19141.5352\n",
      "Epoch 252/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 4256009216.0000 - mae: 19088.3086\n",
      "Epoch 229/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 4470657536.0000 - mae: 19828.3867\n",
      "Epoch 243/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 762us/step - loss: 3812439040.0000 - mae: 19010.5469\n",
      "Epoch 251/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 672us/step - loss: 4663941120.0000 - mae: 19545.8730\n",
      "Epoch 244/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 706us/step - loss: 3702679552.0000 - mae: 18522.3047\n",
      "Epoch 252/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 735us/step - loss: 4856056320.0000 - mae: 19773.3086\n",
      "Epoch 245/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 5197320192.0000 - mae: 19620.4043\n",
      "Epoch 253/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 3951241472.0000 - mae: 19001.4961\n",
      "Epoch 253/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 4588698624.0000 - mae: 19258.4355\n",
      "Epoch 230/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 5188739584.0000 - mae: 20184.4492\n",
      "Epoch 246/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 816us/step - loss: 3398112768.0000 - mae: 18873.8555\n",
      "Epoch 231/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 3784772096.0000 - mae: 19353.9844\n",
      "Epoch 254/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 4355848704.0000 - mae: 19560.5234\n",
      "Epoch 254/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 851us/step - loss: 3867232512.0000 - mae: 19270.4141\n",
      "Epoch 232/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 3856104448.0000 - mae: 19294.8691\n",
      "Epoch 247/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 3892875008.0000 - mae: 18857.265674\n",
      "Epoch 255/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 795us/step - loss: 4430473728.0000 - mae: 19710.0820\n",
      "Epoch 248/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 6724820992.0000 - mae: 20642.0176\n",
      "Epoch 233/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 3477426432.0000 - mae: 18601.0527\n",
      "\u001b[1m 895/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3371418368.0000 - mae: 19700.2227Epoch 256/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 3599318016.0000 - mae: 19750.0234\n",
      "Epoch 255/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 3756837632.0000 - mae: 19215.6426\n",
      "Epoch 249/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 884us/step - loss: 3536339200.0000 - mae: 18367.3418\n",
      "Epoch 257/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 4331865600.0000 - mae: 18944.4941\n",
      "Epoch 234/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 4024941312.0000 - mae: 19356.4609\n",
      "Epoch 256/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 3469128192.0000 - mae: 18807.916030\n",
      "Epoch 250/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 739us/step - loss: 4164254208.0000 - mae: 19036.2070\n",
      "Epoch 258/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 4233494784.0000 - mae: 19322.6484\n",
      "Epoch 257/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 5587286528.0000 - mae: 19967.8555\n",
      "Epoch 251/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 885us/step - loss: 6041246720.0000 - mae: 19689.8242\n",
      "Epoch 259/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 4343146496.0000 - mae: 19289.4551\n",
      "Epoch 235/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 817us/step - loss: 4292460288.0000 - mae: 19447.7031\n",
      "Epoch 252/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 4297637376.0000 - mae: 19387.7734\n",
      "Epoch 260/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 6156355584.0000 - mae: 20744.9590\n",
      "Epoch 258/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 921us/step - loss: 3979330816.0000 - mae: 19028.5156\n",
      "Epoch 253/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 6584602624.0000 - mae: 20135.2422\n",
      "Epoch 236/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 844us/step - loss: 6448609280.0000 - mae: 20480.7559\n",
      "Epoch 237/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 3451461376.0000 - mae: 18690.6953\n",
      "Epoch 261/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 4547434496.0000 - mae: 19680.1328\n",
      "\u001b[1m 895/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4302396928.0000 - mae: 19435.9375Epoch 259/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 4345149952.0000 - mae: 19439.3105\n",
      "\u001b[1m 172/1018\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 2840901120.0000 - mae: 18570.8027Epoch 254/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 4235105280.0000 - mae: 19145.3574\n",
      "Epoch 262/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 6492066816.0000 - mae: 20406.5430\n",
      "Epoch 260/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 6597716992.0000 - mae: 20550.9062\n",
      "Epoch 238/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 4624441344.0000 - mae: 19838.4824\n",
      "Epoch 255/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 878us/step - loss: 3318172160.0000 - mae: 18525.6270\n",
      "Epoch 263/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 4831176192.0000 - mae: 19983.2949\n",
      "Epoch 261/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 3587082752.0000 - mae: 18692.0078\n",
      "Epoch 256/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 803us/step - loss: 4398949376.0000 - mae: 19150.4316\n",
      "Epoch 264/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 5500557824.0000 - mae: 20129.1035\n",
      "Epoch 262/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 4079078656.0000 - mae: 18928.8145\n",
      "Epoch 239/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 889us/step - loss: 5252548608.0000 - mae: 19892.8320\n",
      "Epoch 265/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 3908841472.0000 - mae: 19169.9707\n",
      "Epoch 257/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 826us/step - loss: 4668251648.0000 - mae: 19424.9258\n",
      "Epoch 263/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 4989655552.0000 - mae: 19566.9551\n",
      "Epoch 240/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 3675859200.0000 - mae: 18876.7715\n",
      "Epoch 266/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 4022727168.0000 - mae: 19100.5098\n",
      "Epoch 258/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 6108135936.0000 - mae: 20420.4453\n",
      "Epoch 264/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 847us/step - loss: 5481951744.0000 - mae: 20107.2578\n",
      "Epoch 259/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 5512088576.0000 - mae: 19845.3555\n",
      "Epoch 267/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 5594963968.0000 - mae: 19933.7891\n",
      "Epoch 241/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 3940844032.0000 - mae: 19372.8926\n",
      "Epoch 265/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 5422325760.0000 - mae: 20108.9961\n",
      "Epoch 260/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 928us/step - loss: 5267666432.0000 - mae: 19771.3125\n",
      "Epoch 242/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 832us/step - loss: 4557153792.0000 - mae: 19790.1367\n",
      "Epoch 266/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 813us/step - loss: 4243157248.0000 - mae: 19410.9941\n",
      "Epoch 261/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 869us/step - loss: 4926874112.0000 - mae: 19903.5703\n",
      "Epoch 262/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 5147725824.0000 - mae: 19701.4180\n",
      "Epoch 243/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 4818097664.0000 - mae: 19901.1816\n",
      "Epoch 267/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 4864980992.0000 - mae: 19385.0410\n",
      "Epoch 268/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 828us/step - loss: 4473560576.0000 - mae: 19520.3047\n",
      "Epoch 263/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 6145808896.0000 - mae: 20087.1777\n",
      "Epoch 268/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 4003328000.0000 - mae: 18605.2695\n",
      "Epoch 269/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4096456448.0000 - mae: 19266.4922\n",
      "Epoch 244/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 3035101696.0000 - mae: 18467.9902\n",
      "\u001b[1m 330/1018\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 4750264832.0000 - mae: 20422.2422Epoch 264/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 773us/step - loss: 5021924864.0000 - mae: 19640.9902\n",
      "Epoch 270/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 5169585152.0000 - mae: 20196.6465\n",
      "Epoch 269/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 5350880256.0000 - mae: 19487.783218\n",
      "Epoch 245/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 687us/step - loss: 4181539072.0000 - mae: 18990.3691\n",
      "Epoch 271/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 790us/step - loss: 3549159168.0000 - mae: 18963.4355\n",
      "Epoch 246/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 3361349888.0000 - mae: 18678.0078\n",
      "Epoch 270/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 966us/step - loss: 4422607872.0000 - mae: 19047.2402\n",
      "Epoch 272/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 3353871360.0000 - mae: 18897.1074\n",
      "Epoch 265/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 5632678400.0000 - mae: 20202.5215\n",
      "Epoch 247/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 6870799872.0000 - mae: 20993.4609\n",
      "Epoch 271/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 3562706688.0000 - mae: 18741.3965\n",
      "Epoch 273/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 701us/step - loss: 4153853440.0000 - mae: 19472.4863\n",
      "Epoch 248/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 4817666048.0000 - mae: 19746.7461\n",
      "Epoch 272/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 724us/step - loss: 3700311808.0000 - mae: 18841.8066\n",
      "Epoch 249/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 4787518464.0000 - mae: 19792.1914\n",
      "Epoch 274/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 5754196992.0000 - mae: 20280.4297\n",
      "Epoch 266/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 5074607616.0000 - mae: 19401.5176\n",
      "Epoch 273/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 7084943360.0000 - mae: 20819.2031\n",
      "Epoch 250/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 3695283712.0000 - mae: 18449.9082\n",
      "Epoch 275/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 972us/step - loss: 3884046848.0000 - mae: 18925.1113\n",
      "Epoch 267/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 720us/step - loss: 4064721664.0000 - mae: 19082.4883\n",
      "Epoch 276/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 5940326912.0000 - mae: 19658.9238\n",
      "\u001b[1m 130/1018\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 2387063552.0000 - mae: 18027.0312Epoch 251/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 4182624256.0000 - mae: 19435.2715\n",
      "Epoch 268/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 692us/step - loss: 3353741824.0000 - mae: 18924.0859\n",
      "Epoch 277/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 716us/step - loss: 3287896832.0000 - mae: 18801.2715\n",
      "Epoch 278/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 5383389696.0000 - mae: 19972.0898\n",
      "Epoch 274/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4745468416.0000 - mae: 19094.3457\n",
      "Epoch 252/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4643204608.0000 - mae: 19248.1621\n",
      "Epoch 269/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 718us/step - loss: 3555366400.0000 - mae: 18588.0488\n",
      "\u001b[1m 303/1018\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1765664256.0000 - mae: 17056.5312Epoch 279/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 3636795904.0000 - mae: 18565.2754\n",
      "Epoch 275/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 3969250304.0000 - mae: 19365.2773\n",
      "Epoch 253/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 5546370048.0000 - mae: 20225.6895\n",
      "\u001b[1m 476/1018\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3647786240.0000 - mae: 19227.6758Epoch 270/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 768us/step - loss: 4773989888.0000 - mae: 19441.1641\n",
      "Epoch 254/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4051077376.0000 - mae: 19153.4707\n",
      "Epoch 280/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 3965668608.0000 - mae: 19257.9297\n",
      "Epoch 276/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 844us/step - loss: 3610442240.0000 - mae: 18994.9531\n",
      "Epoch 255/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 4813101056.0000 - mae: 19703.2031\n",
      "Epoch 271/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 3369471488.0000 - mae: 18360.7480\n",
      "Epoch 281/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 695us/step - loss: 4787313664.0000 - mae: 19496.9531\n",
      "Epoch 272/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 5053744640.0000 - mae: 19900.8027\n",
      "Epoch 256/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 806us/step - loss: 4725043200.0000 - mae: 19385.4785\n",
      "Epoch 273/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 3727405824.0000 - mae: 18478.5957\n",
      "\u001b[1m 821/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 863us/step - loss: 4024295424.0000 - mae: 19462.7461Epoch 282/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 6866689536.0000 - mae: 20624.6152\n",
      "Epoch 277/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 5040000000.0000 - mae: 19416.6875\n",
      "Epoch 257/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 994us/step - loss: 4151157248.0000 - mae: 19493.3340\n",
      "Epoch 274/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 714us/step - loss: 3909433088.0000 - mae: 19120.7695\n",
      "Epoch 258/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 6272350208.0000 - mae: 20152.5273\n",
      "Epoch 278/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 3518198016.0000 - mae: 18705.7715\n",
      "Epoch 283/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 7495383552.0000 - mae: 20663.8340\n",
      "Epoch 275/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 725us/step - loss: 4534724096.0000 - mae: 19155.1270\n",
      "Epoch 259/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 638us/step - loss: 3215595008.0000 - mae: 18804.0293\n",
      "Epoch 260/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 688us/step - loss: 5766452224.0000 - mae: 19852.9922\n",
      "Epoch 276/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 743us/step - loss: 4033806080.0000 - mae: 19779.0957\n",
      "Epoch 261/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 768us/step - loss: 5688080384.0000 - mae: 19888.3398\n",
      "Epoch 262/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 5200327680.0000 - mae: 19718.8984\n",
      "Epoch 277/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 5252184064.0000 - mae: 19843.0098\n",
      "Epoch 284/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 3905758720.0000 - mae: 19587.1035\n",
      "Epoch 279/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 826us/step - loss: 4090164224.0000 - mae: 18793.6035\n",
      "Epoch 263/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 991us/step - loss: 4597209088.0000 - mae: 19708.32235\n",
      "Epoch 278/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 950us/step - loss: 3143113472.0000 - mae: 18244.5840\n",
      "Epoch 285/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 875us/step - loss: 5303196160.0000 - mae: 19497.3574\n",
      "Epoch 264/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 4774209024.0000 - mae: 19858.1055\n",
      "Epoch 280/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 3496866304.0000 - mae: 18787.1562\n",
      "Epoch 286/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 831us/step - loss: 4713786368.0000 - mae: 19336.1406\n",
      "Epoch 265/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 4758121472.0000 - mae: 19467.7090\n",
      "Epoch 279/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 860us/step - loss: 4779195904.0000 - mae: 19202.7559\n",
      "Epoch 266/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 4844435456.0000 - mae: 19563.9746\n",
      "Epoch 281/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 3466444288.0000 - mae: 18839.0586\n",
      "Epoch 287/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 5127872512.0000 - mae: 20118.4688\n",
      "Epoch 280/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 3218671360.0000 - mae: 18395.6973\n",
      "Epoch 267/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 927us/step - loss: 3983138048.0000 - mae: 19597.6738\n",
      "Epoch 282/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 784us/step - loss: 3711351552.0000 - mae: 18796.5703\n",
      "Epoch 281/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 799us/step - loss: 4891502592.0000 - mae: 19490.6172\n",
      "Epoch 283/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 4332239872.0000 - mae: 19308.0391\n",
      "Epoch 268/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 4535232000.0000 - mae: 19264.2070\n",
      "Epoch 282/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 4974513152.0000 - mae: 19281.3086\n",
      "Epoch 288/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 771us/step - loss: 5050224640.0000 - mae: 19808.9805\n",
      "Epoch 284/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 4709016576.0000 - mae: 19035.7305\n",
      "Epoch 269/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 5324190720.0000 - mae: 19830.1562\n",
      "Epoch 285/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 6026101760.0000 - mae: 20154.080111\n",
      "Epoch 283/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 3324779264.0000 - mae: 18307.07621\n",
      "Epoch 289/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 883us/step - loss: 3059078400.0000 - mae: 18320.5840\n",
      "Epoch 270/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 968us/step - loss: 4225626880.0000 - mae: 19382.4980\n",
      "Epoch 290/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 6031129088.0000 - mae: 20387.6445\n",
      "Epoch 286/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 5891468800.0000 - mae: 20282.1914\n",
      "Epoch 284/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 4067329024.0000 - mae: 19173.4863\n",
      "Epoch 271/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 771us/step - loss: 5055153152.0000 - mae: 19923.9180\n",
      "Epoch 287/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 5235870720.0000 - mae: 19867.9766\n",
      "Epoch 291/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 5731819008.0000 - mae: 20158.1328\n",
      "Epoch 285/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 766us/step - loss: 4881100288.0000 - mae: 19956.0469\n",
      "Epoch 288/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 5821803008.0000 - mae: 19940.8652\n",
      "Epoch 272/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 737us/step - loss: 5448315904.0000 - mae: 19916.7734\n",
      "Epoch 289/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 3394351360.0000 - mae: 18111.6973\n",
      "Epoch 292/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 4741902848.0000 - mae: 19773.3125\n",
      "Epoch 286/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 5968589824.0000 - mae: 20171.1055\n",
      "Epoch 273/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 771us/step - loss: 4226770176.0000 - mae: 19031.7754\n",
      "Epoch 293/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 4405007872.0000 - mae: 19051.6582\n",
      "Epoch 290/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 5421820416.0000 - mae: 20030.0957\n",
      "Epoch 287/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 792us/step - loss: 5616430592.0000 - mae: 20079.3848\n",
      "Epoch 291/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 3430373376.0000 - mae: 18837.1484\n",
      "Epoch 294/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 4481361408.0000 - mae: 18992.87700\n",
      "Epoch 274/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 691us/step - loss: 5195215872.0000 - mae: 19330.6758\n",
      "Epoch 292/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 4253799936.0000 - mae: 19373.140678\n",
      "Epoch 288/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 919us/step - loss: 4588902912.0000 - mae: 19578.6270\n",
      "Epoch 295/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 766us/step - loss: 7545873408.0000 - mae: 21299.6328\n",
      "Epoch 293/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 5111043072.0000 - mae: 19584.3574\n",
      "Epoch 289/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 832us/step - loss: 3481999104.0000 - mae: 18695.3984\n",
      "Epoch 275/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 3846173696.0000 - mae: 18465.5254\n",
      "Epoch 296/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 5313826816.0000 - mae: 19772.5723\n",
      "Epoch 294/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 733us/step - loss: 5546270720.0000 - mae: 19592.8945\n",
      "Epoch 295/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 3925275136.0000 - mae: 19384.0508\n",
      "Epoch 290/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 3945054720.0000 - mae: 18882.7910\n",
      "Epoch 276/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 5173874688.0000 - mae: 19167.8145\n",
      "Epoch 297/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 727us/step - loss: 4036881664.0000 - mae: 19260.4629\n",
      "Epoch 296/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 710us/step - loss: 4123736832.0000 - mae: 19087.6523\n",
      "Epoch 297/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 6423420928.0000 - mae: 20801.0762\n",
      "Epoch 291/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 4826893824.0000 - mae: 19269.0938\n",
      "Epoch 277/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 4073426688.0000 - mae: 19083.6816\n",
      "Epoch 298/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 728us/step - loss: 6433485312.0000 - mae: 20844.5371\n",
      "Epoch 298/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 745us/step - loss: 5265420288.0000 - mae: 19663.6680\n",
      "Epoch 299/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 4900685312.0000 - mae: 19293.1426\n",
      "Epoch 292/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 4019643392.0000 - mae: 18752.9023\n",
      "Epoch 278/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 3381326848.0000 - mae: 18394.2734\n",
      "Epoch 299/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 758us/step - loss: 2832777728.0000 - mae: 18104.1055\n",
      "Epoch 300/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 875us/step - loss: 3862023936.0000 - mae: 18942.1797\n",
      "Epoch 293/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 931us/step - loss: 5276013056.0000 - mae: 19938.9902\n",
      "Epoch 300/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 821us/step - loss: 3014552832.0000 - mae: 18380.9102\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 3977386496.0000 - mae: 18672.3281\n",
      "Epoch 294/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 4649555456.0000 - mae: 19298.5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-17 10:40:46.802014: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 146889860 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 5353538048.0000 - mae: 19837.83201\n",
      "Epoch 279/300\n",
      "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 571us/step - loss: 10697401344.0000 - mae: 23737.87\n",
      "\u001b[1m 138/1018\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 736us/step - loss: 4287959808.0000 - mae: 19429.5781"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-17 10:40:47.179207: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 146889860 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 613us/stepep - loss: 4724122624.0000 - mae: 19322.42\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 863us/step - loss: 7220253184.0000 - mae: 21257.1191\n",
      "Epoch 295/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 724us/step - loss: 4635955712.0000 - mae: 19431.2969\n",
      "Epoch 280/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 695us/step - loss: 3638231808.0000 - mae: 18966.9023\n",
      "Epoch 296/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 714us/step - loss: 4020799488.0000 - mae: 18889.7480\n",
      "Epoch 281/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 685us/step - loss: 4705466368.0000 - mae: 19388.3613\n",
      "Epoch 297/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 635us/step - loss: 3270156288.0000 - mae: 19021.9238\n",
      "Epoch 282/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 673us/step - loss: 5492568576.0000 - mae: 19876.9648\n",
      "Epoch 298/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 665us/step - loss: 3619542784.0000 - mae: 18674.2266\n",
      "Epoch 283/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 624us/step - loss: 4405369856.0000 - mae: 19572.8691\n",
      "Epoch 299/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 656us/step - loss: 4105646336.0000 - mae: 19056.1875\n",
      "Epoch 284/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 613us/step - loss: 4465683456.0000 - mae: 19353.1621\n",
      "Epoch 300/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 606us/step - loss: 3603447552.0000 - mae: 19011.9102\n",
      "Epoch 285/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 625us/step - loss: 4269820672.0000 - mae: 19194.9902\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 669us/step - loss: 5233607680.0000 - mae: 20018.3906\n",
      "Epoch 286/300\n",
      "\u001b[1m   1/1018\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m20s\u001b[0m 20ms/step - loss: 197522176.0000 - mae: 10466.6387"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-17 10:40:52.044127: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 146876328 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 490us/stepep - loss: 5501355520.0000 - mae: 18927.75\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 663us/step - loss: 5233849856.0000 - mae: 19055.7324\n",
      "Epoch 287/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 663us/step - loss: 4829892096.0000 - mae: 19279.0391\n",
      "Epoch 288/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 654us/step - loss: 4656275968.0000 - mae: 19070.8496\n",
      "Epoch 289/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 627us/step - loss: 3837089280.0000 - mae: 18877.6133\n",
      "Epoch 290/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 635us/step - loss: 6019085312.0000 - mae: 20111.0762\n",
      "Epoch 291/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 621us/step - loss: 3866378496.0000 - mae: 19041.8047\n",
      "Epoch 292/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 612us/step - loss: 5645633536.0000 - mae: 19916.8223\n",
      "Epoch 293/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 621us/step - loss: 3133217024.0000 - mae: 18198.5020\n",
      "Epoch 294/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 610us/step - loss: 3350381824.0000 - mae: 18339.3184\n",
      "Epoch 295/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 625us/step - loss: 4524103168.0000 - mae: 19352.0469\n",
      "Epoch 296/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 612us/step - loss: 4699172864.0000 - mae: 19302.9492\n",
      "Epoch 297/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 616us/step - loss: 5494189568.0000 - mae: 19546.2168\n",
      "Epoch 298/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 614us/step - loss: 4561405440.0000 - mae: 19222.7969\n",
      "Epoch 299/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 629us/step - loss: 3084635648.0000 - mae: 18368.1270\n",
      "Epoch 300/300\n",
      "\u001b[1m1018/1018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 613us/step - loss: 3835162880.0000 - mae: 18818.9707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-17 10:41:02.031943: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 146876328 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 439us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/sdb1/2ndHome/anaconda3/envs/kaggle/lib/python3.10/site-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/mnt/sdb1/2ndHome/anaconda3/envs/kaggle/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 631us/step - loss: 5443931136.0000 - mae: 33271.0039\n",
      "Epoch 2/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 684us/step - loss: 4142927872.0000 - mae: 20063.2227\n",
      "Epoch 3/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 625us/step - loss: 5547051008.0000 - mae: 19777.1738\n",
      "Epoch 4/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 643us/step - loss: 4610949632.0000 - mae: 19912.8633\n",
      "Epoch 5/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 615us/step - loss: 4511784448.0000 - mae: 19516.8711\n",
      "Epoch 6/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 632us/step - loss: 3812902912.0000 - mae: 19199.9648\n",
      "Epoch 7/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 618us/step - loss: 5652322304.0000 - mae: 20094.5645\n",
      "Epoch 8/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 646us/step - loss: 3696718592.0000 - mae: 19080.5137\n",
      "Epoch 9/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 614us/step - loss: 5095417344.0000 - mae: 19957.0762\n",
      "Epoch 10/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 620us/step - loss: 4313112576.0000 - mae: 19645.5020\n",
      "Epoch 11/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 614us/step - loss: 4856549376.0000 - mae: 19973.2949\n",
      "Epoch 12/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 626us/step - loss: 3683718912.0000 - mae: 18942.7305\n",
      "Epoch 13/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 607us/step - loss: 4636127232.0000 - mae: 19818.8027\n",
      "Epoch 14/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 621us/step - loss: 4536429568.0000 - mae: 19806.2305\n",
      "Epoch 15/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 636us/step - loss: 4011804928.0000 - mae: 19482.7988\n",
      "Epoch 16/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 614us/step - loss: 5318497792.0000 - mae: 19986.2148\n",
      "Epoch 17/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 629us/step - loss: 5493515776.0000 - mae: 20208.5996\n",
      "Epoch 18/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 603us/step - loss: 4104355840.0000 - mae: 19214.0723\n",
      "Epoch 19/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 646us/step - loss: 4924678656.0000 - mae: 19863.5527\n",
      "Epoch 20/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 637us/step - loss: 4200665088.0000 - mae: 19511.8438\n",
      "Epoch 21/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 650us/step - loss: 4854225920.0000 - mae: 19614.0957\n",
      "Epoch 22/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 646us/step - loss: 4919685632.0000 - mae: 19664.5938\n",
      "Epoch 23/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 638us/step - loss: 4989120000.0000 - mae: 19787.4004\n",
      "Epoch 24/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 634us/step - loss: 5286280192.0000 - mae: 20092.9102\n",
      "Epoch 25/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 642us/step - loss: 3386454528.0000 - mae: 19013.1016\n",
      "Epoch 26/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 616us/step - loss: 4561095168.0000 - mae: 19761.5117\n",
      "Epoch 27/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 595us/step - loss: 3732637184.0000 - mae: 19144.3496\n",
      "Epoch 28/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 631us/step - loss: 4712453632.0000 - mae: 19978.9961\n",
      "Epoch 29/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 647us/step - loss: 3977268736.0000 - mae: 19306.7207\n",
      "Epoch 30/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 629us/step - loss: 4892510208.0000 - mae: 19950.6543\n",
      "Epoch 31/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 611us/step - loss: 3473836800.0000 - mae: 19093.1445\n",
      "Epoch 32/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 636us/step - loss: 4481651712.0000 - mae: 19570.4863\n",
      "Epoch 33/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 641us/step - loss: 4385992704.0000 - mae: 19459.3066\n",
      "Epoch 34/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 634us/step - loss: 4119949568.0000 - mae: 19765.4785\n",
      "Epoch 35/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 637us/step - loss: 4639715840.0000 - mae: 19751.4180\n",
      "Epoch 36/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 642us/step - loss: 4598730240.0000 - mae: 19245.0156\n",
      "Epoch 37/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 637us/step - loss: 4490491904.0000 - mae: 19501.4414\n",
      "Epoch 38/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 639us/step - loss: 4302763008.0000 - mae: 19111.4648\n",
      "Epoch 39/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 612us/step - loss: 3765939456.0000 - mae: 19471.9043\n",
      "Epoch 40/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 629us/step - loss: 6375937536.0000 - mae: 20672.0781\n",
      "Epoch 41/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 603us/step - loss: 4879680512.0000 - mae: 19886.5645\n",
      "Epoch 42/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 652us/step - loss: 5514251776.0000 - mae: 19974.1016\n",
      "Epoch 43/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 612us/step - loss: 5179586048.0000 - mae: 19979.2305\n",
      "Epoch 44/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 621us/step - loss: 3660168448.0000 - mae: 19123.9648\n",
      "Epoch 45/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 620us/step - loss: 4127853568.0000 - mae: 19481.9082\n",
      "Epoch 46/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 600us/step - loss: 4631000064.0000 - mae: 19517.4199\n",
      "Epoch 47/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 620us/step - loss: 5624008704.0000 - mae: 19961.3281\n",
      "Epoch 48/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 598us/step - loss: 3849698304.0000 - mae: 19108.8066\n",
      "Epoch 49/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 636us/step - loss: 4513502208.0000 - mae: 19486.3203\n",
      "Epoch 50/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 610us/step - loss: 5241432576.0000 - mae: 19714.8848\n",
      "Epoch 51/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 612us/step - loss: 4502768640.0000 - mae: 19345.7207\n",
      "Epoch 52/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 632us/step - loss: 4061683200.0000 - mae: 19048.0312\n",
      "Epoch 53/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 627us/step - loss: 4321297408.0000 - mae: 19582.4883\n",
      "Epoch 54/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 615us/step - loss: 3781272320.0000 - mae: 19444.1602\n",
      "Epoch 55/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 615us/step - loss: 5039965696.0000 - mae: 19669.4180\n",
      "Epoch 56/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 615us/step - loss: 5332671488.0000 - mae: 20081.8145\n",
      "Epoch 57/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 639us/step - loss: 3992720640.0000 - mae: 19228.2266\n",
      "Epoch 58/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 627us/step - loss: 5127769088.0000 - mae: 20210.3125\n",
      "Epoch 59/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 639us/step - loss: 4393729024.0000 - mae: 19547.1641\n",
      "Epoch 60/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 602us/step - loss: 5328976384.0000 - mae: 19908.2383\n",
      "Epoch 61/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 641us/step - loss: 5014012928.0000 - mae: 19901.2637\n",
      "Epoch 62/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 629us/step - loss: 3695417344.0000 - mae: 19014.4883\n",
      "Epoch 63/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 645us/step - loss: 5416938496.0000 - mae: 19793.6777\n",
      "Epoch 64/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 614us/step - loss: 4983161344.0000 - mae: 19709.3184\n",
      "Epoch 65/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 644us/step - loss: 5162940928.0000 - mae: 19990.4336\n",
      "Epoch 66/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 618us/step - loss: 5233255424.0000 - mae: 19918.5742\n",
      "Epoch 67/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 638us/step - loss: 6052539392.0000 - mae: 19745.4473\n",
      "Epoch 68/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 622us/step - loss: 4381051392.0000 - mae: 19483.7500\n",
      "Epoch 69/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 645us/step - loss: 5251859456.0000 - mae: 19965.5645\n",
      "Epoch 70/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 635us/step - loss: 3996372992.0000 - mae: 18605.0488\n",
      "Epoch 71/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 604us/step - loss: 4157868800.0000 - mae: 19040.6973\n",
      "Epoch 72/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 622us/step - loss: 4992728576.0000 - mae: 19515.0176\n",
      "Epoch 73/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 616us/step - loss: 4118266112.0000 - mae: 19068.8613\n",
      "Epoch 74/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 626us/step - loss: 4588860416.0000 - mae: 19557.4648\n",
      "Epoch 75/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 602us/step - loss: 5714156544.0000 - mae: 20073.2266\n",
      "Epoch 76/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 636us/step - loss: 4462994432.0000 - mae: 19286.4258\n",
      "Epoch 77/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 611us/step - loss: 4283805184.0000 - mae: 19469.9277\n",
      "Epoch 78/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 620us/step - loss: 5058512384.0000 - mae: 19875.7891\n",
      "Epoch 79/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 635us/step - loss: 4527059968.0000 - mae: 19562.4941\n",
      "Epoch 80/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 615us/step - loss: 5470219264.0000 - mae: 19711.8125\n",
      "Epoch 81/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 636us/step - loss: 3987672576.0000 - mae: 19160.2695\n",
      "Epoch 82/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 636us/step - loss: 5936376832.0000 - mae: 20252.9922\n",
      "Epoch 83/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 646us/step - loss: 4584830976.0000 - mae: 19317.2266\n",
      "Epoch 84/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 644us/step - loss: 5181311488.0000 - mae: 19910.9199\n",
      "Epoch 85/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 634us/step - loss: 4398369280.0000 - mae: 18821.7441\n",
      "Epoch 86/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 645us/step - loss: 4906518016.0000 - mae: 19618.5137\n",
      "Epoch 87/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 654us/step - loss: 4096303104.0000 - mae: 19268.2520\n",
      "Epoch 88/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 600us/step - loss: 4048492544.0000 - mae: 19111.1680\n",
      "Epoch 89/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 642us/step - loss: 5826178560.0000 - mae: 19949.2109\n",
      "Epoch 90/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 641us/step - loss: 4677747712.0000 - mae: 19523.4121\n",
      "Epoch 91/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 645us/step - loss: 4433563648.0000 - mae: 19389.8125\n",
      "Epoch 92/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 640us/step - loss: 5213808128.0000 - mae: 19703.6543\n",
      "Epoch 93/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 617us/step - loss: 4869270016.0000 - mae: 19734.8711\n",
      "Epoch 94/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 646us/step - loss: 3907033600.0000 - mae: 19265.8516\n",
      "Epoch 95/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 625us/step - loss: 5247816192.0000 - mae: 20088.2422\n",
      "Epoch 96/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 620us/step - loss: 3729723136.0000 - mae: 19166.2676\n",
      "Epoch 97/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 629us/step - loss: 4005427712.0000 - mae: 18905.4824\n",
      "Epoch 98/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 603us/step - loss: 4619400704.0000 - mae: 19752.9688\n",
      "Epoch 99/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 652us/step - loss: 4732874752.0000 - mae: 19567.4473\n",
      "Epoch 100/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 618us/step - loss: 4168460800.0000 - mae: 19067.8789\n",
      "Epoch 101/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 623us/step - loss: 4341991424.0000 - mae: 19667.7539\n",
      "Epoch 102/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 650us/step - loss: 3922932992.0000 - mae: 18934.2461\n",
      "Epoch 103/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 639us/step - loss: 3912273152.0000 - mae: 19116.0625\n",
      "Epoch 104/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 651us/step - loss: 4764764672.0000 - mae: 19863.6152\n",
      "Epoch 105/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 608us/step - loss: 4448676352.0000 - mae: 19631.5586\n",
      "Epoch 106/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 616us/step - loss: 5022494208.0000 - mae: 19576.2754\n",
      "Epoch 107/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 642us/step - loss: 4956294144.0000 - mae: 19883.4902\n",
      "Epoch 108/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 653us/step - loss: 4648603648.0000 - mae: 19183.3594\n",
      "Epoch 109/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 631us/step - loss: 3930025984.0000 - mae: 19237.8457\n",
      "Epoch 110/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 642us/step - loss: 4492951040.0000 - mae: 19730.3145\n",
      "Epoch 111/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 636us/step - loss: 3393298432.0000 - mae: 18681.4336\n",
      "Epoch 112/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 646us/step - loss: 4620233216.0000 - mae: 19722.8633\n",
      "Epoch 113/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 639us/step - loss: 3416541184.0000 - mae: 18495.6934\n",
      "Epoch 114/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 631us/step - loss: 4622677504.0000 - mae: 19470.7793\n",
      "Epoch 115/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 639us/step - loss: 4881760256.0000 - mae: 19614.7637\n",
      "Epoch 116/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 630us/step - loss: 4788682752.0000 - mae: 19769.9883\n",
      "Epoch 117/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 630us/step - loss: 5048039424.0000 - mae: 19820.6191\n",
      "Epoch 118/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 623us/step - loss: 4113468672.0000 - mae: 19324.3496\n",
      "Epoch 119/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 622us/step - loss: 4333283328.0000 - mae: 19609.6992\n",
      "Epoch 120/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 653us/step - loss: 4151035392.0000 - mae: 19189.9922\n",
      "Epoch 121/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 620us/step - loss: 4680455680.0000 - mae: 19653.2949\n",
      "Epoch 122/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 650us/step - loss: 3491549184.0000 - mae: 18627.6113\n",
      "Epoch 123/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 634us/step - loss: 4458041344.0000 - mae: 19354.7031\n",
      "Epoch 124/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 657us/step - loss: 3620073472.0000 - mae: 18824.4551\n",
      "Epoch 125/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 639us/step - loss: 5674829824.0000 - mae: 20048.4727\n",
      "Epoch 126/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 629us/step - loss: 4113436672.0000 - mae: 19209.5859\n",
      "Epoch 127/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 650us/step - loss: 5845982720.0000 - mae: 20499.4766\n",
      "Epoch 128/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 645us/step - loss: 3840262400.0000 - mae: 19006.8105\n",
      "Epoch 129/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 632us/step - loss: 4451853312.0000 - mae: 19193.8750\n",
      "Epoch 130/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 618us/step - loss: 4346108928.0000 - mae: 19569.5176\n",
      "Epoch 131/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 657us/step - loss: 5040485888.0000 - mae: 19672.5488\n",
      "Epoch 132/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 636us/step - loss: 4838151680.0000 - mae: 19711.7305\n",
      "Epoch 133/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 641us/step - loss: 4109351168.0000 - mae: 19090.5820\n",
      "Epoch 134/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 627us/step - loss: 5324779008.0000 - mae: 19908.5586\n",
      "Epoch 135/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 639us/step - loss: 5195747328.0000 - mae: 19495.7695\n",
      "Epoch 136/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 644us/step - loss: 5543425024.0000 - mae: 20002.9297\n",
      "Epoch 137/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 628us/step - loss: 4919559168.0000 - mae: 19678.4297\n",
      "Epoch 138/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 645us/step - loss: 5756565504.0000 - mae: 19810.6699\n",
      "Epoch 139/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 649us/step - loss: 3862324992.0000 - mae: 19362.4160\n",
      "Epoch 140/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 645us/step - loss: 3763365120.0000 - mae: 19009.9805\n",
      "Epoch 141/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 648us/step - loss: 3614151936.0000 - mae: 18921.2441\n",
      "Epoch 142/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 624us/step - loss: 4222612224.0000 - mae: 18986.8203\n",
      "Epoch 143/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 644us/step - loss: 4810987520.0000 - mae: 19600.7891\n",
      "Epoch 144/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 639us/step - loss: 4118095872.0000 - mae: 19023.1230\n",
      "Epoch 145/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 641us/step - loss: 4180542720.0000 - mae: 19549.8340\n",
      "Epoch 146/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 661us/step - loss: 5093044736.0000 - mae: 19513.2520\n",
      "Epoch 147/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 620us/step - loss: 5435236352.0000 - mae: 20090.4746\n",
      "Epoch 148/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 623us/step - loss: 5423108096.0000 - mae: 19887.5723\n",
      "Epoch 149/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 662us/step - loss: 3664630528.0000 - mae: 18927.5879\n",
      "Epoch 150/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 615us/step - loss: 5056529408.0000 - mae: 20081.9766\n",
      "Epoch 151/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 637us/step - loss: 5341648384.0000 - mae: 20061.2539\n",
      "Epoch 152/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 657us/step - loss: 4399480832.0000 - mae: 19393.4141\n",
      "Epoch 153/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 636us/step - loss: 4714797056.0000 - mae: 19313.7988\n",
      "Epoch 154/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 640us/step - loss: 4471118336.0000 - mae: 19066.5078\n",
      "Epoch 155/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 639us/step - loss: 5122007552.0000 - mae: 19638.1270\n",
      "Epoch 156/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 649us/step - loss: 5556848128.0000 - mae: 19627.7363\n",
      "Epoch 157/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 643us/step - loss: 4068435712.0000 - mae: 19225.8145\n",
      "Epoch 158/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 665us/step - loss: 4178284544.0000 - mae: 19057.6426\n",
      "Epoch 159/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 646us/step - loss: 5331911168.0000 - mae: 20071.0664\n",
      "Epoch 160/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 626us/step - loss: 5165981696.0000 - mae: 19854.1191\n",
      "Epoch 161/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 663us/step - loss: 3645825792.0000 - mae: 19220.5449\n",
      "Epoch 162/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 624us/step - loss: 4450969600.0000 - mae: 19409.4785\n",
      "Epoch 163/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 634us/step - loss: 3577682944.0000 - mae: 19129.5098\n",
      "Epoch 164/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 655us/step - loss: 5594808832.0000 - mae: 19744.1699\n",
      "Epoch 165/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 637us/step - loss: 4177496320.0000 - mae: 18927.2227\n",
      "Epoch 166/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 648us/step - loss: 4621509632.0000 - mae: 19537.3984\n",
      "Epoch 167/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 641us/step - loss: 4913057792.0000 - mae: 19694.9785\n",
      "Epoch 168/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 606us/step - loss: 5245322240.0000 - mae: 19790.5586\n",
      "Epoch 169/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 662us/step - loss: 5368598528.0000 - mae: 19470.8203\n",
      "Epoch 170/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 647us/step - loss: 4752772096.0000 - mae: 19467.6699\n",
      "Epoch 171/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 605us/step - loss: 4415180288.0000 - mae: 19735.0449\n",
      "Epoch 172/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 650us/step - loss: 4372267008.0000 - mae: 19228.6309\n",
      "Epoch 173/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 659us/step - loss: 6838956032.0000 - mae: 20322.3984\n",
      "Epoch 174/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 648us/step - loss: 3827184384.0000 - mae: 19076.9160\n",
      "Epoch 175/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 649us/step - loss: 4535425536.0000 - mae: 19216.5371\n",
      "Epoch 176/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 666us/step - loss: 5762891264.0000 - mae: 19927.0723\n",
      "Epoch 177/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 636us/step - loss: 3992673024.0000 - mae: 18901.8086\n",
      "Epoch 178/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 652us/step - loss: 5097400320.0000 - mae: 19346.5020\n",
      "Epoch 179/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 651us/step - loss: 3998022912.0000 - mae: 19035.6992\n",
      "Epoch 180/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 650us/step - loss: 5867976704.0000 - mae: 20176.4434\n",
      "Epoch 181/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 647us/step - loss: 4171630848.0000 - mae: 18760.7168\n",
      "Epoch 182/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 647us/step - loss: 4034063104.0000 - mae: 19326.1543\n",
      "Epoch 183/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 660us/step - loss: 5532572672.0000 - mae: 19920.3203\n",
      "Epoch 184/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 658us/step - loss: 4336571392.0000 - mae: 19252.3184\n",
      "Epoch 185/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 623us/step - loss: 5665907712.0000 - mae: 19706.0605\n",
      "Epoch 186/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 616us/step - loss: 4705155072.0000 - mae: 19098.6953\n",
      "Epoch 187/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 652us/step - loss: 5268334592.0000 - mae: 19517.9824\n",
      "Epoch 188/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 637us/step - loss: 4954148352.0000 - mae: 19564.8848\n",
      "Epoch 189/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 642us/step - loss: 4903834624.0000 - mae: 19260.0254\n",
      "Epoch 190/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 640us/step - loss: 4640080896.0000 - mae: 19459.4004\n",
      "Epoch 191/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 663us/step - loss: 4147881216.0000 - mae: 18691.4336\n",
      "Epoch 192/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 634us/step - loss: 4926052352.0000 - mae: 19812.0312\n",
      "Epoch 193/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 668us/step - loss: 5838674944.0000 - mae: 19983.2344\n",
      "Epoch 194/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 645us/step - loss: 5232818688.0000 - mae: 19849.0332\n",
      "Epoch 195/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 627us/step - loss: 5088512000.0000 - mae: 19170.1348\n",
      "Epoch 196/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 628us/step - loss: 4414622208.0000 - mae: 19006.9355\n",
      "Epoch 197/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 634us/step - loss: 5585966592.0000 - mae: 19661.5840\n",
      "Epoch 198/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 624us/step - loss: 4372026368.0000 - mae: 18869.9922\n",
      "Epoch 199/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 656us/step - loss: 4566069248.0000 - mae: 19155.1973\n",
      "Epoch 200/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 657us/step - loss: 3085710592.0000 - mae: 18060.3477\n",
      "Epoch 201/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 633us/step - loss: 4901409280.0000 - mae: 19458.5098\n",
      "Epoch 202/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 646us/step - loss: 5163666432.0000 - mae: 19938.4297\n",
      "Epoch 203/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 656us/step - loss: 3629081088.0000 - mae: 18607.5371\n",
      "Epoch 204/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 649us/step - loss: 5245740032.0000 - mae: 19456.7031\n",
      "Epoch 205/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 646us/step - loss: 6014739456.0000 - mae: 19890.6816\n",
      "Epoch 206/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 627us/step - loss: 4517648896.0000 - mae: 18970.4824\n",
      "Epoch 207/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 647us/step - loss: 4367276544.0000 - mae: 18876.7461\n",
      "Epoch 208/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 645us/step - loss: 4188976128.0000 - mae: 18660.4648\n",
      "Epoch 209/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 613us/step - loss: 4759675904.0000 - mae: 19487.6094\n",
      "Epoch 210/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 644us/step - loss: 5417843712.0000 - mae: 19649.2910\n",
      "Epoch 211/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 673us/step - loss: 3461200896.0000 - mae: 18244.3223\n",
      "Epoch 212/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 620us/step - loss: 4798164480.0000 - mae: 19671.7070\n",
      "Epoch 213/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 671us/step - loss: 4600011264.0000 - mae: 19140.4629\n",
      "Epoch 214/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 662us/step - loss: 4079825664.0000 - mae: 19290.2637\n",
      "Epoch 215/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 634us/step - loss: 5413106176.0000 - mae: 19081.7734\n",
      "Epoch 216/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 637us/step - loss: 4374703616.0000 - mae: 19201.7969\n",
      "Epoch 217/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 628us/step - loss: 4494667264.0000 - mae: 19159.8340\n",
      "Epoch 218/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 659us/step - loss: 6297734656.0000 - mae: 20123.5449\n",
      "Epoch 219/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 625us/step - loss: 6155749376.0000 - mae: 19960.3613\n",
      "Epoch 220/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 643us/step - loss: 4418548736.0000 - mae: 18871.6504\n",
      "Epoch 221/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 616us/step - loss: 4176366848.0000 - mae: 18806.3027\n",
      "Epoch 222/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 643us/step - loss: 3991955200.0000 - mae: 18805.1680\n",
      "Epoch 223/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 638us/step - loss: 4013891328.0000 - mae: 18613.3594\n",
      "Epoch 224/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 651us/step - loss: 5808081408.0000 - mae: 19334.8613\n",
      "Epoch 225/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 642us/step - loss: 3417627136.0000 - mae: 18608.0078\n",
      "Epoch 226/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 642us/step - loss: 4812064768.0000 - mae: 19154.8359\n",
      "Epoch 227/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 615us/step - loss: 3699572224.0000 - mae: 18597.3613\n",
      "Epoch 228/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 636us/step - loss: 4224600832.0000 - mae: 18859.6680\n",
      "Epoch 229/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 651us/step - loss: 4659117056.0000 - mae: 19267.1797\n",
      "Epoch 230/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 659us/step - loss: 5848459264.0000 - mae: 19561.1367\n",
      "Epoch 231/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 642us/step - loss: 4202902784.0000 - mae: 18626.9941\n",
      "Epoch 232/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 651us/step - loss: 3944990208.0000 - mae: 18136.5820\n",
      "Epoch 233/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 660us/step - loss: 5466338304.0000 - mae: 19637.0840\n",
      "Epoch 234/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 644us/step - loss: 4097622272.0000 - mae: 18674.0234\n",
      "Epoch 235/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 641us/step - loss: 4482317312.0000 - mae: 18630.9023\n",
      "Epoch 236/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 690us/step - loss: 6496014336.0000 - mae: 19584.0547\n",
      "Epoch 237/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 658us/step - loss: 4606564352.0000 - mae: 18673.7070\n",
      "Epoch 238/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 639us/step - loss: 4434087424.0000 - mae: 18783.2715\n",
      "Epoch 239/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 650us/step - loss: 5138016768.0000 - mae: 19459.9355\n",
      "Epoch 240/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 667us/step - loss: 4191520768.0000 - mae: 18787.2461\n",
      "Epoch 241/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 621us/step - loss: 4786471424.0000 - mae: 18899.7207\n",
      "Epoch 242/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 633us/step - loss: 4039282944.0000 - mae: 18753.1465\n",
      "Epoch 243/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 664us/step - loss: 4523291136.0000 - mae: 18793.3945\n",
      "Epoch 244/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 627us/step - loss: 4918739968.0000 - mae: 18911.0781\n",
      "Epoch 245/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 637us/step - loss: 3907748608.0000 - mae: 18344.2363\n",
      "Epoch 246/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 655us/step - loss: 4006357760.0000 - mae: 18690.5645\n",
      "Epoch 247/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 646us/step - loss: 5193575424.0000 - mae: 19086.6953\n",
      "Epoch 248/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 658us/step - loss: 4119578624.0000 - mae: 18424.0117\n",
      "Epoch 249/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 639us/step - loss: 4135950848.0000 - mae: 18488.6309\n",
      "Epoch 250/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 656us/step - loss: 4173890816.0000 - mae: 18888.1406\n",
      "Epoch 251/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 640us/step - loss: 3884869888.0000 - mae: 18196.4707\n",
      "Epoch 252/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 622us/step - loss: 5148552704.0000 - mae: 19343.4844\n",
      "Epoch 253/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 650us/step - loss: 4736230400.0000 - mae: 18762.0820\n",
      "Epoch 254/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 670us/step - loss: 4194266880.0000 - mae: 18555.9062\n",
      "Epoch 255/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 663us/step - loss: 5800181760.0000 - mae: 19092.1289\n",
      "Epoch 256/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 615us/step - loss: 4743973376.0000 - mae: 18865.1348\n",
      "Epoch 257/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 646us/step - loss: 4585966592.0000 - mae: 18333.5547\n",
      "Epoch 258/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 610us/step - loss: 5167060992.0000 - mae: 18697.3184\n",
      "Epoch 259/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 646us/step - loss: 3765926912.0000 - mae: 18068.7871\n",
      "Epoch 260/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 671us/step - loss: 5636717568.0000 - mae: 19226.1426\n",
      "Epoch 261/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 642us/step - loss: 4662937600.0000 - mae: 18458.6641\n",
      "Epoch 262/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 646us/step - loss: 3823841792.0000 - mae: 17837.0938\n",
      "Epoch 263/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 638us/step - loss: 5822319104.0000 - mae: 18989.5332\n",
      "Epoch 264/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 632us/step - loss: 3974389504.0000 - mae: 18075.6582\n",
      "Epoch 265/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 619us/step - loss: 3975588864.0000 - mae: 18099.1387\n",
      "Epoch 266/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 672us/step - loss: 3780076032.0000 - mae: 17785.3691\n",
      "Epoch 267/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 628us/step - loss: 4323479040.0000 - mae: 18285.8613\n",
      "Epoch 268/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 626us/step - loss: 3763411200.0000 - mae: 17920.1074\n",
      "Epoch 269/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 652us/step - loss: 4689207296.0000 - mae: 18758.7441\n",
      "Epoch 270/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 644us/step - loss: 4385354752.0000 - mae: 18543.6875\n",
      "Epoch 271/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 659us/step - loss: 3947067392.0000 - mae: 17910.8359\n",
      "Epoch 272/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 647us/step - loss: 3502546176.0000 - mae: 17584.5078\n",
      "Epoch 273/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 623us/step - loss: 4499398144.0000 - mae: 18428.2285\n",
      "Epoch 274/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 645us/step - loss: 6182186496.0000 - mae: 18988.9121\n",
      "Epoch 275/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 655us/step - loss: 4681683456.0000 - mae: 18707.3496\n",
      "Epoch 276/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 641us/step - loss: 3666097408.0000 - mae: 17440.8223\n",
      "Epoch 277/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 613us/step - loss: 4518407680.0000 - mae: 18592.3965\n",
      "Epoch 278/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 647us/step - loss: 5388693504.0000 - mae: 18823.9277\n",
      "Epoch 279/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 646us/step - loss: 4645811200.0000 - mae: 18179.3574\n",
      "Epoch 280/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 623us/step - loss: 4129319936.0000 - mae: 18189.6719\n",
      "Epoch 281/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 636us/step - loss: 3826564352.0000 - mae: 17918.1230\n",
      "Epoch 282/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 635us/step - loss: 4892078592.0000 - mae: 18929.6172\n",
      "Epoch 283/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 625us/step - loss: 6260968448.0000 - mae: 18950.9453\n",
      "Epoch 284/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 673us/step - loss: 3477646336.0000 - mae: 17930.2598\n",
      "Epoch 285/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 642us/step - loss: 4826425344.0000 - mae: 18298.2422\n",
      "Epoch 286/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 660us/step - loss: 4671380992.0000 - mae: 18320.8516\n",
      "Epoch 287/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 614us/step - loss: 4045765888.0000 - mae: 17932.6406\n",
      "Epoch 288/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 648us/step - loss: 4303208960.0000 - mae: 17884.9961\n",
      "Epoch 289/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 641us/step - loss: 5356606976.0000 - mae: 18435.2168\n",
      "Epoch 290/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 645us/step - loss: 4355320320.0000 - mae: 18249.3535\n",
      "Epoch 291/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 653us/step - loss: 3807586816.0000 - mae: 17975.6211\n",
      "Epoch 292/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 660us/step - loss: 5053350912.0000 - mae: 19248.4766\n",
      "Epoch 293/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 637us/step - loss: 4967159808.0000 - mae: 18366.3418\n",
      "Epoch 294/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 660us/step - loss: 5611054592.0000 - mae: 18634.3711\n",
      "Epoch 295/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 627us/step - loss: 4889606144.0000 - mae: 18683.2363\n",
      "Epoch 296/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 625us/step - loss: 4220048384.0000 - mae: 17863.2148\n",
      "Epoch 297/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 615us/step - loss: 3333378048.0000 - mae: 17666.4551\n",
      "Epoch 298/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 621us/step - loss: 4583035392.0000 - mae: 18479.5938\n",
      "Epoch 299/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 649us/step - loss: 5089718784.0000 - mae: 18309.6992\n",
      "Epoch 300/300\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 637us/step - loss: 4827266560.0000 - mae: 18054.1914\n",
      "CPU times: user 9min 49s, sys: 53.9 s, total: 10min 43s\n",
      "Wall time: 17min 9s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-6 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-6 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-6 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-6 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-6 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-6 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-6 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-6 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-6 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-6 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-6 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-6 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-6 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=4,\n",
       "             estimator=KerasRegressor(build_fn=&lt;function create_model at 0x7ff42375e320&gt;),\n",
       "             n_jobs=-1, param_grid={&#x27;batch_size&#x27;: [32], &#x27;epochs&#x27;: [200, 300]},\n",
       "             refit=&#x27;neg_mean_absolute_error&#x27;,\n",
       "             scoring=[&#x27;neg_mean_absolute_error&#x27;, &#x27;neg_mean_squared_error&#x27;,\n",
       "                      &#x27;r2&#x27;],\n",
       "             verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;GridSearchCV<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.model_selection.GridSearchCV.html\">?<span>Documentation for GridSearchCV</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>GridSearchCV(cv=4,\n",
       "             estimator=KerasRegressor(build_fn=&lt;function create_model at 0x7ff42375e320&gt;),\n",
       "             n_jobs=-1, param_grid={&#x27;batch_size&#x27;: [32], &#x27;epochs&#x27;: [200, 300]},\n",
       "             refit=&#x27;neg_mean_absolute_error&#x27;,\n",
       "             scoring=[&#x27;neg_mean_absolute_error&#x27;, &#x27;neg_mean_squared_error&#x27;,\n",
       "                      &#x27;r2&#x27;],\n",
       "             verbose=1)</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" ><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">best_estimator_: KerasRegressor</label><div class=\"sk-toggleable__content fitted\"><pre>KerasRegressor(\n",
       "\tmodel=None\n",
       "\tbuild_fn=&lt;function create_model at 0x7ff42375e320&gt;\n",
       "\twarm_start=False\n",
       "\trandom_state=None\n",
       "\toptimizer=rmsprop\n",
       "\tloss=None\n",
       "\tmetrics=None\n",
       "\tbatch_size=32\n",
       "\tvalidation_batch_size=None\n",
       "\tverbose=1\n",
       "\tcallbacks=None\n",
       "\tvalidation_split=0.0\n",
       "\tshuffle=True\n",
       "\trun_eagerly=False\n",
       "\tepochs=300\n",
       ")</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-16\" type=\"checkbox\" ><label for=\"sk-estimator-id-16\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">KerasRegressor</label><div class=\"sk-toggleable__content fitted\"><pre>KerasRegressor(\n",
       "\tmodel=None\n",
       "\tbuild_fn=&lt;function create_model at 0x7ff42375e320&gt;\n",
       "\twarm_start=False\n",
       "\trandom_state=None\n",
       "\toptimizer=rmsprop\n",
       "\tloss=None\n",
       "\tmetrics=None\n",
       "\tbatch_size=32\n",
       "\tvalidation_batch_size=None\n",
       "\tverbose=1\n",
       "\tcallbacks=None\n",
       "\tvalidation_split=0.0\n",
       "\tshuffle=True\n",
       "\trun_eagerly=False\n",
       "\tepochs=300\n",
       ")</pre></div> </div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=4,\n",
       "             estimator=KerasRegressor(build_fn=<function create_model at 0x7ff42375e320>),\n",
       "             n_jobs=-1, param_grid={'batch_size': [32], 'epochs': [200, 300]},\n",
       "             refit='neg_mean_absolute_error',\n",
       "             scoring=['neg_mean_absolute_error', 'neg_mean_squared_error',\n",
       "                      'r2'],\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "tf_model1.fit(X_train_array, y_train_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "b98ae0a2-1078-4a68-8841-a50039db7c9f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-20667.467647854428"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Examine best score\n",
    "\n",
    "tf_model1.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d9f7af99-e76d-459f-bbf5-fa5fcfd7ab5f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'batch_size': 32, 'epochs': 300}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Examine best parameters\n",
    "\n",
    "tf_model1.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ccca695d-196a-4051-99a0-6d1956c4287b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>neg_mean_absolute_error</th>\n",
       "      <th>neg_mean_squared_error</th>\n",
       "      <th>r2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LR CV</td>\n",
       "      <td>-19924.294089</td>\n",
       "      <td>-5.036322e+09</td>\n",
       "      <td>0.012942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LR test</td>\n",
       "      <td>20031.098488</td>\n",
       "      <td>5.680592e+09</td>\n",
       "      <td>0.040122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RF CV</td>\n",
       "      <td>-19412.829282</td>\n",
       "      <td>-4.900808e+09</td>\n",
       "      <td>0.048282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RF test</td>\n",
       "      <td>19291.191762</td>\n",
       "      <td>5.535498e+09</td>\n",
       "      <td>0.064639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGB CV</td>\n",
       "      <td>-18400.682970</td>\n",
       "      <td>-4.886125e+09</td>\n",
       "      <td>0.044883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGB test</td>\n",
       "      <td>18564.635809</td>\n",
       "      <td>5.531917e+09</td>\n",
       "      <td>0.065244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DTC CV</td>\n",
       "      <td>-19348.237368</td>\n",
       "      <td>-4.829772e+09</td>\n",
       "      <td>0.060186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DTC test</td>\n",
       "      <td>19451.246515</td>\n",
       "      <td>5.511835e+09</td>\n",
       "      <td>0.068638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TF CV</td>\n",
       "      <td>-20667.467648</td>\n",
       "      <td>-4.686534e+09</td>\n",
       "      <td>0.094720</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      model  neg_mean_absolute_error  neg_mean_squared_error        r2\n",
       "0     LR CV            -19924.294089           -5.036322e+09  0.012942\n",
       "0   LR test             20031.098488            5.680592e+09  0.040122\n",
       "0     RF CV            -19412.829282           -4.900808e+09  0.048282\n",
       "0   RF test             19291.191762            5.535498e+09  0.064639\n",
       "0    XGB CV            -18400.682970           -4.886125e+09  0.044883\n",
       "0  XGB test             18564.635809            5.531917e+09  0.065244\n",
       "0    DTC CV            -19348.237368           -4.829772e+09  0.060186\n",
       "0  DTC test             19451.246515            5.511835e+09  0.068638\n",
       "0     TF CV            -20667.467648           -4.686534e+09  0.094720"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Call 'make_results()' on the GridSearch object\n",
    "\n",
    "tf_cv_results = make_results('TF CV', tf_model1, 'neg_mean_absolute_error')\n",
    "results = pd.concat([results, tf_cv_results], axis=0)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "c4628fd5-4444-4f30-8e9c-5374cd1ccf44",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 476us/step\n"
     ]
    }
   ],
   "source": [
    "# Get scores on test data\n",
    "\n",
    "tf_preds = tf_model1.best_estimator_.predict(X_test_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "84c6f7a3-8f3b-4e4c-818e-a6fb79e27c1c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>neg_mean_absolute_error</th>\n",
       "      <th>neg_mean_squared_error</th>\n",
       "      <th>r2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LR CV</td>\n",
       "      <td>-19924.294089</td>\n",
       "      <td>-5.036322e+09</td>\n",
       "      <td>0.012942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LR test</td>\n",
       "      <td>20031.098488</td>\n",
       "      <td>5.680592e+09</td>\n",
       "      <td>0.040122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RF CV</td>\n",
       "      <td>-19412.829282</td>\n",
       "      <td>-4.900808e+09</td>\n",
       "      <td>0.048282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RF test</td>\n",
       "      <td>19291.191762</td>\n",
       "      <td>5.535498e+09</td>\n",
       "      <td>0.064639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGB CV</td>\n",
       "      <td>-18400.682970</td>\n",
       "      <td>-4.886125e+09</td>\n",
       "      <td>0.044883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGB test</td>\n",
       "      <td>18564.635809</td>\n",
       "      <td>5.531917e+09</td>\n",
       "      <td>0.065244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DTC CV</td>\n",
       "      <td>-19348.237368</td>\n",
       "      <td>-4.829772e+09</td>\n",
       "      <td>0.060186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DTC test</td>\n",
       "      <td>19451.246515</td>\n",
       "      <td>5.511835e+09</td>\n",
       "      <td>0.068638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TF CV</td>\n",
       "      <td>-20667.467648</td>\n",
       "      <td>-4.686534e+09</td>\n",
       "      <td>0.094720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TF test</td>\n",
       "      <td>17489.360555</td>\n",
       "      <td>5.341247e+09</td>\n",
       "      <td>0.097463</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      model  neg_mean_absolute_error  neg_mean_squared_error        r2\n",
       "0     LR CV            -19924.294089           -5.036322e+09  0.012942\n",
       "0   LR test             20031.098488            5.680592e+09  0.040122\n",
       "0     RF CV            -19412.829282           -4.900808e+09  0.048282\n",
       "0   RF test             19291.191762            5.535498e+09  0.064639\n",
       "0    XGB CV            -18400.682970           -4.886125e+09  0.044883\n",
       "0  XGB test             18564.635809            5.531917e+09  0.065244\n",
       "0    DTC CV            -19348.237368           -4.829772e+09  0.060186\n",
       "0  DTC test             19451.246515            5.511835e+09  0.068638\n",
       "0     TF CV            -20667.467648           -4.686534e+09  0.094720\n",
       "0   TF test             17489.360555            5.341247e+09  0.097463"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get scores on test data\n",
    "\n",
    "tf_test_scores = get_test_scores('TF test', tf_preds, y_test_array)\n",
    "results = pd.concat([results, tf_test_scores], axis=0)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddea1d9a-ecc2-4875-bff6-f98a2054cb68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "39e265f0-e27d-448d-a2d0-5bcd55309be0",
   "metadata": {},
   "source": [
    "# Selecting the appropriate model\n",
    "\n",
    "Looking at the scores above it is clear that the Tensorflow model has the best fit/predictions against both the training and test sets. As such, the object is to predict the prices using this Tensorflow model. Below is the code to do just that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fab33ad-3b9d-4edf-a3e0-5a2200c7e232",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e391a5e4-8934-4c00-ba75-3562d7217549",
   "metadata": {},
   "source": [
    "# Now re-run to get a new prediction on the test data set\n",
    "- previously we used predicted on the train data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "55e89c2f-09fe-46fe-8584-85bedf8f4e0f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Convert the test data to a dense tensor for processing\n",
    "\n",
    "test_final_array = test_data_final.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "2ce7e6f7-adf6-4432-9170-d257ed88ae2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1131/1131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 398us/step\n",
      "CPU times: user 1.54 s, sys: 437 ms, total: 1.98 s\n",
      "Wall time: 1.54 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Running Tensorflow model on the final dataset \n",
    "final_tf_prediction = tf_model1.predict(test_final_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "546d3919-6f90-41bd-b3db-8243b39ca940",
   "metadata": {},
   "source": [
    "# Output File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "bb37cc33-653b-4eee-9c04-888a3b9091ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "submission = test_df_copy[['id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "511c59ef-07ea-43c4-b5e8-105962742fc8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_129276/2994288854.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  submission[\"price\"] = final_tf_prediction\n"
     ]
    }
   ],
   "source": [
    "submission[\"price\"] = final_tf_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "15263e4a-13d6-4af4-8b5b-daefb0fcd1b7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 36183 entries, 0 to 36182\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   id      36183 non-null  int64  \n",
      " 1   price   36183 non-null  float32\n",
      "dtypes: float32(1), int64(1)\n",
      "memory usage: 424.1 KB\n"
     ]
    }
   ],
   "source": [
    "submission.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "3c1e17f2-1bc1-4350-a99e-c14462efa0eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Format the output\n",
    "\n",
    "pd.options.display.float_format = '{:.3f}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "bcf825f1-10c3-4619-9b02-3c4878a3e62e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>54273</td>\n",
       "      <td>30676.840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>54274</td>\n",
       "      <td>19012.117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>54275</td>\n",
       "      <td>42983.664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>54276</td>\n",
       "      <td>55154.234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>54277</td>\n",
       "      <td>23065.941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36178</th>\n",
       "      <td>90451</td>\n",
       "      <td>88641.492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36179</th>\n",
       "      <td>90452</td>\n",
       "      <td>12851.711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36180</th>\n",
       "      <td>90453</td>\n",
       "      <td>12501.518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36181</th>\n",
       "      <td>90454</td>\n",
       "      <td>56224.906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36182</th>\n",
       "      <td>90455</td>\n",
       "      <td>12193.868</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>36183 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id     price\n",
       "0      54273 30676.840\n",
       "1      54274 19012.117\n",
       "2      54275 42983.664\n",
       "3      54276 55154.234\n",
       "4      54277 23065.941\n",
       "...      ...       ...\n",
       "36178  90451 88641.492\n",
       "36179  90452 12851.711\n",
       "36180  90453 12501.518\n",
       "36181  90454 56224.906\n",
       "36182  90455 12193.868\n",
       "\n",
       "[36183 rows x 2 columns]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "f92db38a-ead8-4289-8a2b-accda77f66c5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "submission.to_csv(\"./modelSubmission1.csv\", index=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
